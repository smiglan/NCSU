{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "project3face/nonface.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bb6m2HBY9g4F",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e36166f5-0483-44f2-b79d-e36889d34830"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive', force_remount=True)\n",
        "path = '/content/gdrive/My Drive/ECE763P3/'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RW_OfV8oUMaw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "e9876495-6dc7-45c3-8582-f4ed786fc7aa"
      },
      "source": [
        "\n",
        "from __future__ import print_function\n",
        "import keras\n",
        "from keras.datasets import cifar10\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D, BatchNormalization\n",
        "import os\n",
        "import numpy as np\n",
        "batch_size = 64\n",
        "num_classes = 2\n",
        "x_train = np.load(path+'x_train1.npy')\n",
        "y_train = np.load(path+'y_train1.npy')\n",
        "x_test = np.load(path+'x_test1.npy')\n",
        "y_test = np.load(path+'y_test1.npy')\n",
        "print('x_train shape:', x_train.shape)\n",
        "print(x_train.shape[0], 'train samples')\n",
        "\n",
        "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x_train shape: (2444, 32, 32, 3)\n",
            "2444 train samples\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NST4fw5cUSra",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "x_train /= 255\n",
        "x_test /= 255\n",
        "\n",
        "datagen = ImageDataGenerator(\n",
        "  )\n",
        "\n",
        "datagen.fit(x_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qDtmfNRCYR2o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Dense(50,input_shape=x_train.shape[1:]))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Flatten())\n",
        "\n",
        "model.add(Dense(num_classes))\n",
        "model.add(Activation('softmax'))\n",
        "\n",
        "opt = keras.optimizers.SGD(learning_rate=0.0001, decay=1e-6)\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=opt,\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a1lsqay1bYa3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        },
        "outputId": "4722cded-5265-492f-ae73-207240402a70"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_1 (Dense)              (None, 32, 32, 50)        200       \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 32, 32, 50)        0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 51200)             0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 2)                 102402    \n",
            "_________________________________________________________________\n",
            "activation_2 (Activation)    (None, 2)                 0         \n",
            "=================================================================\n",
            "Total params: 102,602\n",
            "Trainable params: 102,602\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LO_QS-J3UjuO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "9ea59167-280f-4daa-cc55-155ae049ba16"
      },
      "source": [
        "\n",
        "epochs = 1\n",
        "\n",
        "model.fit_generator(datagen.flow(x_train, y_train,\n",
        "                                  batch_size=batch_size),\n",
        "                    epochs=epochs,\n",
        "                    validation_data=(x_test, y_test),\n",
        "                    workers=4)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/1\n",
            "39/39 [==============================] - 1s 38ms/step - loss: 0.6991 - accuracy: 0.4640 - val_loss: 0.6913 - val_accuracy: 0.5184\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.callbacks.History at 0x7f736c451f98>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1WF4jkDpcw6z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras import regularizers\n",
        "weight_decay = 1e3\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PoActpAFdhRS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Dense(50,input_shape=x_train.shape[1:],kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Flatten())\n",
        "\n",
        "model.add(Dense(num_classes))\n",
        "model.add(Activation('softmax'))\n",
        "\n",
        "opt = keras.optimizers.SGD(learning_rate=0.0001, decay=1e-6)\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=opt,\n",
        "              metrics=['accuracy'])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ooWEJt5fdrOe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "eaedd73e-f365-46d1-b162-12f223320804"
      },
      "source": [
        "epochs = 1\n",
        "\n",
        "model.fit_generator(datagen.flow(x_train, y_train,\n",
        "                                  batch_size=batch_size),\n",
        "                    epochs=epochs,\n",
        "                    validation_data=(x_test, y_test),\n",
        "                    workers=4)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/1\n",
            "39/39 [==============================] - 1s 33ms/step - loss: 418.6697 - accuracy: 0.5360 - val_loss: 0.6933 - val_accuracy: 0.6801\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.callbacks.History at 0x7f73660e52e8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oYSFgduZhYwP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "datagen_n = ImageDataGenerator()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MzY9EIDHcduJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_tiny = x_train[:32]\n",
        "y_tiny = y_train[:32]\n",
        "datagen_n.fit(x_tiny)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lN3hRHI-ernF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Dense(50,input_shape=x_tiny.shape[1:]))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Flatten())\n",
        "\n",
        "model.add(Dense(num_classes))\n",
        "model.add(Activation('softmax'))\n",
        "\n",
        "opt = keras.optimizers.SGD(learning_rate=0.01)\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=opt,\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hJdnBZFKe2xm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "3c701079-e239-41af-bca2-4d807ca39caa"
      },
      "source": [
        "epochs = 200\n",
        "\n",
        "model.fit_generator(datagen_n.flow(x_tiny, y_tiny,\n",
        "                                  batch_size=batch_size),\n",
        "                    epochs=epochs,\n",
        "                    workers=4)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 0.6844 - accuracy: 0.6562\n",
            "Epoch 2/200\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.7542 - accuracy: 0.6250\n",
            "Epoch 3/200\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.6856 - accuracy: 0.4062\n",
            "Epoch 4/200\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.8080 - accuracy: 0.6250\n",
            "Epoch 5/200\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.5842 - accuracy: 0.8125\n",
            "Epoch 6/200\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.6427 - accuracy: 0.6250\n",
            "Epoch 7/200\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.5375 - accuracy: 0.8438\n",
            "Epoch 8/200\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.5791 - accuracy: 0.6562\n",
            "Epoch 9/200\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.4846 - accuracy: 0.9062\n",
            "Epoch 10/200\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.5048 - accuracy: 0.6875\n",
            "Epoch 11/200\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.4392 - accuracy: 0.9688\n",
            "Epoch 12/200\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.4453 - accuracy: 0.7812\n",
            "Epoch 13/200\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.3996 - accuracy: 1.0000\n",
            "Epoch 14/200\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.3969 - accuracy: 0.8125\n",
            "Epoch 15/200\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.3653 - accuracy: 1.0000\n",
            "Epoch 16/200\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.3578 - accuracy: 0.8125\n",
            "Epoch 17/200\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.3359 - accuracy: 1.0000\n",
            "Epoch 18/200\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.3266 - accuracy: 0.8750\n",
            "Epoch 19/200\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.3111 - accuracy: 1.0000\n",
            "Epoch 20/200\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.3017 - accuracy: 0.8750\n",
            "Epoch 21/200\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.2904 - accuracy: 0.9688\n",
            "Epoch 22/200\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.2818 - accuracy: 0.8750\n",
            "Epoch 23/200\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.2730 - accuracy: 0.9688\n",
            "Epoch 24/200\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.2655 - accuracy: 0.9375\n",
            "Epoch 25/200\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.2583 - accuracy: 0.9688\n",
            "Epoch 26/200\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.2518 - accuracy: 0.9688\n",
            "Epoch 27/200\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.2455 - accuracy: 0.9688\n",
            "Epoch 28/200\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.2397 - accuracy: 0.9688\n",
            "Epoch 29/200\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.2341 - accuracy: 0.9688\n",
            "Epoch 30/200\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.2288 - accuracy: 0.9688\n",
            "Epoch 31/200\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.2237 - accuracy: 0.9688\n",
            "Epoch 32/200\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.2189 - accuracy: 0.9688\n",
            "Epoch 33/200\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.2142 - accuracy: 1.0000\n",
            "Epoch 34/200\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.2097 - accuracy: 1.0000\n",
            "Epoch 35/200\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.2054 - accuracy: 1.0000\n",
            "Epoch 36/200\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.2012 - accuracy: 1.0000\n",
            "Epoch 37/200\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.1972 - accuracy: 1.0000\n",
            "Epoch 38/200\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.1933 - accuracy: 1.0000\n",
            "Epoch 39/200\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.1895 - accuracy: 1.0000\n",
            "Epoch 40/200\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.1859 - accuracy: 1.0000\n",
            "Epoch 41/200\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.1824 - accuracy: 1.0000\n",
            "Epoch 42/200\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.1790 - accuracy: 1.0000\n",
            "Epoch 43/200\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.1757 - accuracy: 1.0000\n",
            "Epoch 44/200\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.1726 - accuracy: 1.0000\n",
            "Epoch 45/200\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.1695 - accuracy: 1.0000\n",
            "Epoch 46/200\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.1665 - accuracy: 1.0000\n",
            "Epoch 47/200\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.1636 - accuracy: 1.0000\n",
            "Epoch 48/200\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.1608 - accuracy: 1.0000\n",
            "Epoch 49/200\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.1580 - accuracy: 1.0000\n",
            "Epoch 50/200\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.1554 - accuracy: 1.0000\n",
            "Epoch 51/200\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.1528 - accuracy: 1.0000\n",
            "Epoch 52/200\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.1503 - accuracy: 1.0000\n",
            "Epoch 53/200\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.1479 - accuracy: 1.0000\n",
            "Epoch 54/200\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.1455 - accuracy: 1.0000\n",
            "Epoch 55/200\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.1432 - accuracy: 1.0000\n",
            "Epoch 56/200\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.1410 - accuracy: 1.0000\n",
            "Epoch 57/200\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.1388 - accuracy: 1.0000\n",
            "Epoch 58/200\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.1367 - accuracy: 1.0000\n",
            "Epoch 59/200\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.1346 - accuracy: 1.0000\n",
            "Epoch 60/200\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.1326 - accuracy: 1.0000\n",
            "Epoch 61/200\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.1306 - accuracy: 1.0000\n",
            "Epoch 62/200\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.1287 - accuracy: 1.0000\n",
            "Epoch 63/200\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.1268 - accuracy: 1.0000\n",
            "Epoch 64/200\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.1250 - accuracy: 1.0000\n",
            "Epoch 65/200\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.1232 - accuracy: 1.0000\n",
            "Epoch 66/200\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.1215 - accuracy: 1.0000\n",
            "Epoch 67/200\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.1198 - accuracy: 1.0000\n",
            "Epoch 68/200\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.1181 - accuracy: 1.0000\n",
            "Epoch 69/200\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.1165 - accuracy: 1.0000\n",
            "Epoch 70/200\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.1149 - accuracy: 1.0000\n",
            "Epoch 71/200\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.1133 - accuracy: 1.0000\n",
            "Epoch 72/200\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.1118 - accuracy: 1.0000\n",
            "Epoch 73/200\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.1104 - accuracy: 1.0000\n",
            "Epoch 74/200\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.1089 - accuracy: 1.0000\n",
            "Epoch 75/200\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.1075 - accuracy: 1.0000\n",
            "Epoch 76/200\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.1061 - accuracy: 1.0000\n",
            "Epoch 77/200\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.1047 - accuracy: 1.0000\n",
            "Epoch 78/200\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.1034 - accuracy: 1.0000\n",
            "Epoch 79/200\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.1021 - accuracy: 1.0000\n",
            "Epoch 80/200\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.1009 - accuracy: 1.0000\n",
            "Epoch 81/200\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.0996 - accuracy: 1.0000\n",
            "Epoch 82/200\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0984 - accuracy: 1.0000\n",
            "Epoch 83/200\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.0972 - accuracy: 1.0000\n",
            "Epoch 84/200\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0960 - accuracy: 1.0000\n",
            "Epoch 85/200\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0949 - accuracy: 1.0000\n",
            "Epoch 86/200\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.0938 - accuracy: 1.0000\n",
            "Epoch 87/200\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0927 - accuracy: 1.0000\n",
            "Epoch 88/200\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0916 - accuracy: 1.0000\n",
            "Epoch 89/200\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0905 - accuracy: 1.0000\n",
            "Epoch 90/200\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0895 - accuracy: 1.0000\n",
            "Epoch 91/200\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0885 - accuracy: 1.0000\n",
            "Epoch 92/200\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0875 - accuracy: 1.0000\n",
            "Epoch 93/200\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0865 - accuracy: 1.0000\n",
            "Epoch 94/200\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0855 - accuracy: 1.0000\n",
            "Epoch 95/200\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0846 - accuracy: 1.0000\n",
            "Epoch 96/200\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0837 - accuracy: 1.0000\n",
            "Epoch 97/200\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0828 - accuracy: 1.0000\n",
            "Epoch 98/200\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0819 - accuracy: 1.0000\n",
            "Epoch 99/200\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0810 - accuracy: 1.0000\n",
            "Epoch 100/200\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0801 - accuracy: 1.0000\n",
            "Epoch 101/200\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0793 - accuracy: 1.0000\n",
            "Epoch 102/200\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0785 - accuracy: 1.0000\n",
            "Epoch 103/200\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.0777 - accuracy: 1.0000\n",
            "Epoch 104/200\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.0769 - accuracy: 1.0000\n",
            "Epoch 105/200\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0761 - accuracy: 1.0000\n",
            "Epoch 106/200\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0753 - accuracy: 1.0000\n",
            "Epoch 107/200\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0745 - accuracy: 1.0000\n",
            "Epoch 108/200\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.0738 - accuracy: 1.0000\n",
            "Epoch 109/200\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0731 - accuracy: 1.0000\n",
            "Epoch 110/200\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.0723 - accuracy: 1.0000\n",
            "Epoch 111/200\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0716 - accuracy: 1.0000\n",
            "Epoch 112/200\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.0709 - accuracy: 1.0000\n",
            "Epoch 113/200\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0703 - accuracy: 1.0000\n",
            "Epoch 114/200\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0696 - accuracy: 1.0000\n",
            "Epoch 115/200\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0689 - accuracy: 1.0000\n",
            "Epoch 116/200\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0683 - accuracy: 1.0000\n",
            "Epoch 117/200\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0676 - accuracy: 1.0000\n",
            "Epoch 118/200\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0670 - accuracy: 1.0000\n",
            "Epoch 119/200\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0664 - accuracy: 1.0000\n",
            "Epoch 120/200\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0658 - accuracy: 1.0000\n",
            "Epoch 121/200\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0652 - accuracy: 1.0000\n",
            "Epoch 122/200\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0646 - accuracy: 1.0000\n",
            "Epoch 123/200\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0640 - accuracy: 1.0000\n",
            "Epoch 124/200\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0634 - accuracy: 1.0000\n",
            "Epoch 125/200\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0628 - accuracy: 1.0000\n",
            "Epoch 126/200\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0623 - accuracy: 1.0000\n",
            "Epoch 127/200\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0617 - accuracy: 1.0000\n",
            "Epoch 128/200\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.0612 - accuracy: 1.0000\n",
            "Epoch 129/200\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.0607 - accuracy: 1.0000\n",
            "Epoch 130/200\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.0601 - accuracy: 1.0000\n",
            "Epoch 131/200\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0596 - accuracy: 1.0000\n",
            "Epoch 132/200\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.0591 - accuracy: 1.0000\n",
            "Epoch 133/200\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.0586 - accuracy: 1.0000\n",
            "Epoch 134/200\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0581 - accuracy: 1.0000\n",
            "Epoch 135/200\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0576 - accuracy: 1.0000\n",
            "Epoch 136/200\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.0572 - accuracy: 1.0000\n",
            "Epoch 137/200\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0567 - accuracy: 1.0000\n",
            "Epoch 138/200\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0562 - accuracy: 1.0000\n",
            "Epoch 139/200\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.0558 - accuracy: 1.0000\n",
            "Epoch 140/200\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0553 - accuracy: 1.0000\n",
            "Epoch 141/200\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.0549 - accuracy: 1.0000\n",
            "Epoch 142/200\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.0544 - accuracy: 1.0000\n",
            "Epoch 143/200\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0540 - accuracy: 1.0000\n",
            "Epoch 144/200\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.0536 - accuracy: 1.0000\n",
            "Epoch 145/200\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.0531 - accuracy: 1.0000\n",
            "Epoch 146/200\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0527 - accuracy: 1.0000\n",
            "Epoch 147/200\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0523 - accuracy: 1.0000\n",
            "Epoch 148/200\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.0519 - accuracy: 1.0000\n",
            "Epoch 149/200\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.0515 - accuracy: 1.0000\n",
            "Epoch 150/200\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0511 - accuracy: 1.0000\n",
            "Epoch 151/200\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0507 - accuracy: 1.0000\n",
            "Epoch 152/200\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0503 - accuracy: 1.0000\n",
            "Epoch 153/200\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0499 - accuracy: 1.0000\n",
            "Epoch 154/200\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0496 - accuracy: 1.0000\n",
            "Epoch 155/200\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.0492 - accuracy: 1.0000\n",
            "Epoch 156/200\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0488 - accuracy: 1.0000\n",
            "Epoch 157/200\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0485 - accuracy: 1.0000\n",
            "Epoch 158/200\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.0481 - accuracy: 1.0000\n",
            "Epoch 159/200\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.0478 - accuracy: 1.0000\n",
            "Epoch 160/200\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.0474 - accuracy: 1.0000\n",
            "Epoch 161/200\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0471 - accuracy: 1.0000\n",
            "Epoch 162/200\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0467 - accuracy: 1.0000\n",
            "Epoch 163/200\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0464 - accuracy: 1.0000\n",
            "Epoch 164/200\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0461 - accuracy: 1.0000\n",
            "Epoch 165/200\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.0458 - accuracy: 1.0000\n",
            "Epoch 166/200\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0454 - accuracy: 1.0000\n",
            "Epoch 167/200\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.0451 - accuracy: 1.0000\n",
            "Epoch 168/200\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.0448 - accuracy: 1.0000\n",
            "Epoch 169/200\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0445 - accuracy: 1.0000\n",
            "Epoch 170/200\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0442 - accuracy: 1.0000\n",
            "Epoch 171/200\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0439 - accuracy: 1.0000\n",
            "Epoch 172/200\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0436 - accuracy: 1.0000\n",
            "Epoch 173/200\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0433 - accuracy: 1.0000\n",
            "Epoch 174/200\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0430 - accuracy: 1.0000\n",
            "Epoch 175/200\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.0427 - accuracy: 1.0000\n",
            "Epoch 176/200\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0424 - accuracy: 1.0000\n",
            "Epoch 177/200\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.0421 - accuracy: 1.0000\n",
            "Epoch 178/200\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0419 - accuracy: 1.0000\n",
            "Epoch 179/200\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0416 - accuracy: 1.0000\n",
            "Epoch 180/200\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.0413 - accuracy: 1.0000\n",
            "Epoch 181/200\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0410 - accuracy: 1.0000\n",
            "Epoch 182/200\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0408 - accuracy: 1.0000\n",
            "Epoch 183/200\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0405 - accuracy: 1.0000\n",
            "Epoch 184/200\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.0403 - accuracy: 1.0000\n",
            "Epoch 185/200\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0400 - accuracy: 1.0000\n",
            "Epoch 186/200\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0397 - accuracy: 1.0000\n",
            "Epoch 187/200\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0395 - accuracy: 1.0000\n",
            "Epoch 188/200\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0392 - accuracy: 1.0000\n",
            "Epoch 189/200\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0390 - accuracy: 1.0000\n",
            "Epoch 190/200\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0387 - accuracy: 1.0000\n",
            "Epoch 191/200\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0385 - accuracy: 1.0000\n",
            "Epoch 192/200\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0383 - accuracy: 1.0000\n",
            "Epoch 193/200\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0380 - accuracy: 1.0000\n",
            "Epoch 194/200\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0378 - accuracy: 1.0000\n",
            "Epoch 195/200\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0376 - accuracy: 1.0000\n",
            "Epoch 196/200\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0373 - accuracy: 1.0000\n",
            "Epoch 197/200\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0371 - accuracy: 1.0000\n",
            "Epoch 198/200\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0369 - accuracy: 1.0000\n",
            "Epoch 199/200\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0367 - accuracy: 1.0000\n",
            "Epoch 200/200\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.0365 - accuracy: 1.0000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.callbacks.History at 0x7f736602e908>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7X62I9iEjg3S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "weight_decay = 1e-6\n",
        "model = Sequential()\n",
        "model.add(Dense(50,input_shape=x_train.shape[1:],kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Flatten())\n",
        "\n",
        "model.add(Dense(num_classes))\n",
        "model.add(Activation('softmax'))\n",
        "\n",
        "opt = keras.optimizers.SGD(learning_rate=0.000001)\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=opt,\n",
        "              metrics=['accuracy'])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kTqyf-SOjmAW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "outputId": "09c47428-f4c8-434b-b457-aee13882122b"
      },
      "source": [
        "epochs = 10\n",
        "\n",
        "model.fit_generator(datagen.flow(x_train, y_train,\n",
        "                                  batch_size=batch_size),\n",
        "                    epochs=epochs,\n",
        "                    validation_data=(x_test, y_test),\n",
        "                    workers=4)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "39/39 [==============================] - 1s 33ms/step - loss: 0.6904 - accuracy: 0.5000 - val_loss: 0.7029 - val_accuracy: 0.5184\n",
            "Epoch 2/10\n",
            "39/39 [==============================] - 1s 33ms/step - loss: 0.6931 - accuracy: 0.5012 - val_loss: 0.7026 - val_accuracy: 0.5184\n",
            "Epoch 3/10\n",
            "39/39 [==============================] - 1s 36ms/step - loss: 0.6910 - accuracy: 0.5012 - val_loss: 0.7024 - val_accuracy: 0.5184\n",
            "Epoch 4/10\n",
            "39/39 [==============================] - 1s 36ms/step - loss: 0.6931 - accuracy: 0.5012 - val_loss: 0.7022 - val_accuracy: 0.5184\n",
            "Epoch 5/10\n",
            "39/39 [==============================] - 1s 32ms/step - loss: 0.6901 - accuracy: 0.5012 - val_loss: 0.7020 - val_accuracy: 0.5184\n",
            "Epoch 6/10\n",
            "39/39 [==============================] - 1s 32ms/step - loss: 0.6906 - accuracy: 0.5012 - val_loss: 0.7018 - val_accuracy: 0.5184\n",
            "Epoch 7/10\n",
            "39/39 [==============================] - 1s 32ms/step - loss: 0.6900 - accuracy: 0.5012 - val_loss: 0.7016 - val_accuracy: 0.5184\n",
            "Epoch 8/10\n",
            "39/39 [==============================] - 1s 31ms/step - loss: 0.6890 - accuracy: 0.5012 - val_loss: 0.7014 - val_accuracy: 0.5184\n",
            "Epoch 9/10\n",
            "39/39 [==============================] - 1s 31ms/step - loss: 0.6910 - accuracy: 0.5012 - val_loss: 0.7011 - val_accuracy: 0.5184\n",
            "Epoch 10/10\n",
            "39/39 [==============================] - 1s 32ms/step - loss: 0.6887 - accuracy: 0.5012 - val_loss: 0.7010 - val_accuracy: 0.5184\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.callbacks.History at 0x7f7365ec7eb8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MG03acTqmEcs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "weight_decay = 1e-6\n",
        "model = Sequential()\n",
        "model.add(Dense(50,input_shape=x_train.shape[1:],kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Flatten())\n",
        "\n",
        "model.add(Dense(num_classes))\n",
        "model.add(Activation('softmax'))\n",
        "\n",
        "opt = keras.optimizers.SGD(learning_rate=1e6)\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=opt,\n",
        "              metrics=['accuracy'])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "osLJ4FPpmGnZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "e22d390f-227a-4962-efd6-2b6b0c1a4518"
      },
      "source": [
        "epochs = 2\n",
        "\n",
        "model.fit_generator(datagen.flow(x_train, y_train,\n",
        "                                  batch_size=batch_size),\n",
        "                    epochs=epochs,\n",
        "                    validation_data=(x_test, y_test),\n",
        "                    workers=4)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/2\n",
            "39/39 [==============================] - 1s 33ms/step - loss: nan - accuracy: 0.5074 - val_loss: nan - val_accuracy: 0.4853\n",
            "Epoch 2/2\n",
            "39/39 [==============================] - 1s 31ms/step - loss: nan - accuracy: 0.5016 - val_loss: nan - val_accuracy: 0.4853\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.callbacks.History at 0x7f7365d4eeb8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OZ69YRDbrUYY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hkKffhmgrP4K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "weight_decay = 1e-6\n",
        "model = Sequential()\n",
        "model.add(Dense(50,input_shape=x_train.shape[1:],kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Flatten())\n",
        "\n",
        "model.add(Dense(num_classes))\n",
        "model.add(Activation('softmax'))\n",
        "\n",
        "opt = keras.optimizers.SGD(learning_rate=1e-1)\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=opt,\n",
        "              metrics=['accuracy'])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oy1c2fAosYnS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "outputId": "acfcf58c-83f1-41ab-b2bd-4b91bb3d9748"
      },
      "source": [
        "epochs = 10\n",
        "\n",
        "History = model.fit_generator(datagen.flow(x_train, y_train,\n",
        "                                  batch_size=batch_size),\n",
        "                    epochs=epochs,\n",
        "                    validation_data=(x_test, y_test),\n",
        "                    workers=4)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "39/39 [==============================] - 1s 33ms/step - loss: 1.1214 - accuracy: 0.6911 - val_loss: 0.3329 - val_accuracy: 0.8971\n",
            "Epoch 2/10\n",
            "39/39 [==============================] - 1s 32ms/step - loss: 0.2715 - accuracy: 0.8916 - val_loss: 0.3495 - val_accuracy: 0.8272\n",
            "Epoch 3/10\n",
            "39/39 [==============================] - 1s 32ms/step - loss: 0.1769 - accuracy: 0.9362 - val_loss: 0.1754 - val_accuracy: 0.9412\n",
            "Epoch 4/10\n",
            "39/39 [==============================] - 1s 32ms/step - loss: 0.1432 - accuracy: 0.9509 - val_loss: 0.1511 - val_accuracy: 0.9449\n",
            "Epoch 5/10\n",
            "39/39 [==============================] - 1s 31ms/step - loss: 0.1256 - accuracy: 0.9525 - val_loss: 0.1265 - val_accuracy: 0.9559\n",
            "Epoch 6/10\n",
            "39/39 [==============================] - 1s 32ms/step - loss: 0.1063 - accuracy: 0.9611 - val_loss: 0.1256 - val_accuracy: 0.9559\n",
            "Epoch 7/10\n",
            "39/39 [==============================] - 1s 33ms/step - loss: 0.0986 - accuracy: 0.9664 - val_loss: 0.1195 - val_accuracy: 0.9559\n",
            "Epoch 8/10\n",
            "39/39 [==============================] - 1s 33ms/step - loss: 0.0938 - accuracy: 0.9640 - val_loss: 0.1127 - val_accuracy: 0.9669\n",
            "Epoch 9/10\n",
            "39/39 [==============================] - 1s 32ms/step - loss: 0.0846 - accuracy: 0.9693 - val_loss: 0.1328 - val_accuracy: 0.9412\n",
            "Epoch 10/10\n",
            "39/39 [==============================] - 1s 33ms/step - loss: 0.0869 - accuracy: 0.9693 - val_loss: 0.1247 - val_accuracy: 0.9522\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kv7xPXbUuqvs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import random"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L1DSQ4qosp8A",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "c216ebd7-d583-4db8-cc22-e4a67f6f8e12"
      },
      "source": [
        "#Course\n",
        "\n",
        "max_count = 100\n",
        "epochs = 5\n",
        "lr_list,reg_list,batch_list,val_loss,val_acc = [],[],[],[],[]\n",
        "for count in range(max_count):\n",
        "  reg = 10**np.random.uniform(-6,3)\n",
        "  lr = 10**np.random.uniform(-1,-6)\n",
        "  batch_size_list = [32,64,128,256]\n",
        "  batch_size = random.choice(batch_size_list)\n",
        "  print(lr,reg)\n",
        "  weight_decay = reg\n",
        "  model = Sequential()\n",
        "  model.add(Dense(50,input_shape=x_train.shape[1:],kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "  model.add(Activation('relu'))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(Flatten())\n",
        "\n",
        "  model.add(Dense(num_classes))\n",
        "  model.add(Activation('softmax'))\n",
        "\n",
        "  opt = keras.optimizers.SGD(learning_rate=lr)\n",
        "\n",
        "  model.compile(loss='categorical_crossentropy',\n",
        "                optimizer=opt,\n",
        "                metrics=['accuracy'])\n",
        "  History = model.fit_generator(datagen.flow(x_train, y_train,\n",
        "                                  batch_size=batch_size),\n",
        "                    epochs=epochs,\n",
        "                    validation_data=(x_test, y_test),\n",
        "                    workers=4)\n",
        "  lr_list.append(lr)\n",
        "  reg_list.append(reg)\n",
        "  batch_list.append(batch_size)\n",
        "\n",
        "  val_loss.append(History.history['val_loss'][-1])\n",
        "  val_acc.append(History.history['val_accuracy'][-1])\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.012798672924442965 251.30363192139828\n",
            "Epoch 1/5\n",
            "39/39 [==============================] - 3s 85ms/step - loss: inf - accuracy: 0.6878 - val_loss: nan - val_accuracy: 0.4853\n",
            "Epoch 2/5\n",
            "39/39 [==============================] - 3s 80ms/step - loss: nan - accuracy: 0.5065 - val_loss: nan - val_accuracy: 0.4853\n",
            "Epoch 3/5\n",
            "39/39 [==============================] - 3s 81ms/step - loss: nan - accuracy: 0.5016 - val_loss: nan - val_accuracy: 0.4853\n",
            "Epoch 4/5\n",
            "39/39 [==============================] - 3s 80ms/step - loss: nan - accuracy: 0.5016 - val_loss: nan - val_accuracy: 0.4853\n",
            "Epoch 5/5\n",
            "39/39 [==============================] - 3s 80ms/step - loss: nan - accuracy: 0.5016 - val_loss: nan - val_accuracy: 0.4853\n",
            "3.428307644115509e-05 410.2940382386389\n",
            "Epoch 1/5\n",
            "20/20 [==============================] - 3s 168ms/step - loss: 1325.7344 - accuracy: 0.7152 - val_loss: 689.8729 - val_accuracy: 0.6912\n",
            "Epoch 2/5\n",
            "20/20 [==============================] - 3s 161ms/step - loss: 423.3524 - accuracy: 0.7823 - val_loss: 220.8004 - val_accuracy: 0.7647\n",
            "Epoch 3/5\n",
            "20/20 [==============================] - 3s 159ms/step - loss: 135.6571 - accuracy: 0.7995 - val_loss: 71.0101 - val_accuracy: 0.8015\n",
            "Epoch 4/5\n",
            "20/20 [==============================] - 3s 163ms/step - loss: 43.6614 - accuracy: 0.8061 - val_loss: 23.1779 - val_accuracy: 0.7022\n",
            "Epoch 5/5\n",
            "20/20 [==============================] - 3s 163ms/step - loss: 14.3929 - accuracy: 0.8056 - val_loss: 7.9017 - val_accuracy: 0.4890\n",
            "3.0817904838686134e-06 3.5341050430845207\n",
            "Epoch 1/5\n",
            "39/39 [==============================] - 3s 88ms/step - loss: 20.1250 - accuracy: 0.6833 - val_loss: 20.1395 - val_accuracy: 0.6434\n",
            "Epoch 2/5\n",
            "39/39 [==============================] - 3s 84ms/step - loss: 20.0353 - accuracy: 0.7300 - val_loss: 20.0954 - val_accuracy: 0.6728\n",
            "Epoch 3/5\n",
            "39/39 [==============================] - 3s 84ms/step - loss: 19.9679 - accuracy: 0.7553 - val_loss: 20.0496 - val_accuracy: 0.6875\n",
            "Epoch 4/5\n",
            "39/39 [==============================] - 3s 84ms/step - loss: 19.8980 - accuracy: 0.7700 - val_loss: 20.0020 - val_accuracy: 0.7096\n",
            "Epoch 5/5\n",
            "39/39 [==============================] - 3s 85ms/step - loss: 19.8518 - accuracy: 0.7807 - val_loss: 19.9524 - val_accuracy: 0.7390\n",
            "1.4222595991242691e-05 1.3918168849355136e-06\n",
            "Epoch 1/5\n",
            "10/10 [==============================] - 4s 363ms/step - loss: 0.8973 - accuracy: 0.4100 - val_loss: 0.6956 - val_accuracy: 0.4596\n",
            "Epoch 2/5\n",
            "10/10 [==============================] - 3s 329ms/step - loss: 0.7999 - accuracy: 0.4820 - val_loss: 0.6902 - val_accuracy: 0.5515\n",
            "Epoch 3/5\n",
            "10/10 [==============================] - 3s 328ms/step - loss: 0.7272 - accuracy: 0.5483 - val_loss: 0.6854 - val_accuracy: 0.5993\n",
            "Epoch 4/5\n",
            "10/10 [==============================] - 3s 334ms/step - loss: 0.6743 - accuracy: 0.6076 - val_loss: 0.6808 - val_accuracy: 0.6434\n",
            "Epoch 5/5\n",
            "10/10 [==============================] - 3s 328ms/step - loss: 0.6323 - accuracy: 0.6596 - val_loss: 0.6764 - val_accuracy: 0.6691\n",
            "3.389698051278209e-05 1.2407006825967597e-05\n",
            "Epoch 1/5\n",
            "20/20 [==============================] - 3s 173ms/step - loss: 0.6106 - accuracy: 0.7128 - val_loss: 0.6762 - val_accuracy: 0.5515\n",
            "Epoch 2/5\n",
            "20/20 [==============================] - 3s 165ms/step - loss: 0.5172 - accuracy: 0.7680 - val_loss: 0.6631 - val_accuracy: 0.6140\n",
            "Epoch 3/5\n",
            "20/20 [==============================] - 3s 167ms/step - loss: 0.4660 - accuracy: 0.8073 - val_loss: 0.6520 - val_accuracy: 0.6618\n",
            "Epoch 4/5\n",
            "20/20 [==============================] - 3s 167ms/step - loss: 0.4427 - accuracy: 0.8228 - val_loss: 0.6416 - val_accuracy: 0.6875\n",
            "Epoch 5/5\n",
            "20/20 [==============================] - 3s 167ms/step - loss: 0.4231 - accuracy: 0.8351 - val_loss: 0.6311 - val_accuracy: 0.6949\n",
            "1.0694653664966817e-06 3.5972682400648063e-06\n",
            "Epoch 1/5\n",
            "10/10 [==============================] - 4s 352ms/step - loss: 1.2046 - accuracy: 0.3576 - val_loss: 0.7228 - val_accuracy: 0.4779\n",
            "Epoch 2/5\n",
            "10/10 [==============================] - 3s 332ms/step - loss: 1.1658 - accuracy: 0.3773 - val_loss: 0.7204 - val_accuracy: 0.4375\n",
            "Epoch 3/5\n",
            "10/10 [==============================] - 3s 331ms/step - loss: 1.1477 - accuracy: 0.3826 - val_loss: 0.7183 - val_accuracy: 0.4118\n",
            "Epoch 4/5\n",
            "10/10 [==============================] - 3s 330ms/step - loss: 1.1233 - accuracy: 0.3809 - val_loss: 0.7164 - val_accuracy: 0.3824\n",
            "Epoch 5/5\n",
            "10/10 [==============================] - 3s 328ms/step - loss: 1.1082 - accuracy: 0.3850 - val_loss: 0.7148 - val_accuracy: 0.3676\n",
            "0.0005120307128431775 0.0024691289850358364\n",
            "Epoch 1/5\n",
            "77/77 [==============================] - 4s 50ms/step - loss: 0.3920 - accuracy: 0.8445 - val_loss: 0.5957 - val_accuracy: 0.7647\n",
            "Epoch 2/5\n",
            "77/77 [==============================] - 4s 47ms/step - loss: 0.2757 - accuracy: 0.8998 - val_loss: 0.5383 - val_accuracy: 0.8088\n",
            "Epoch 3/5\n",
            "77/77 [==============================] - 4s 48ms/step - loss: 0.2375 - accuracy: 0.9194 - val_loss: 0.4664 - val_accuracy: 0.8309\n",
            "Epoch 4/5\n",
            "77/77 [==============================] - 4s 48ms/step - loss: 0.2156 - accuracy: 0.9264 - val_loss: 0.4256 - val_accuracy: 0.8272\n",
            "Epoch 5/5\n",
            "77/77 [==============================] - 4s 47ms/step - loss: 0.1912 - accuracy: 0.9394 - val_loss: 0.3461 - val_accuracy: 0.8456\n",
            "0.018966500912006568 0.0022430487954523694\n",
            "Epoch 1/5\n",
            "10/10 [==============================] - 4s 350ms/step - loss: 8.2210 - accuracy: 0.7136 - val_loss: 2.7731 - val_accuracy: 0.4853\n",
            "Epoch 2/5\n",
            "10/10 [==============================] - 3s 331ms/step - loss: 2.1014 - accuracy: 0.8773 - val_loss: 0.5983 - val_accuracy: 0.6838\n",
            "Epoch 3/5\n",
            "10/10 [==============================] - 3s 328ms/step - loss: 0.5095 - accuracy: 0.9313 - val_loss: 3.5566 - val_accuracy: 0.4853\n",
            "Epoch 4/5\n",
            "10/10 [==============================] - 3s 330ms/step - loss: 1.7346 - accuracy: 0.8707 - val_loss: 2.6220 - val_accuracy: 0.4853\n",
            "Epoch 5/5\n",
            "10/10 [==============================] - 3s 329ms/step - loss: 0.1383 - accuracy: 0.9677 - val_loss: 2.6218 - val_accuracy: 0.4853\n",
            "0.00035622389030313034 25.818586722983433\n",
            "Epoch 1/5\n",
            "39/39 [==============================] - 3s 89ms/step - loss: 82.8851 - accuracy: 0.8486 - val_loss: 36.6813 - val_accuracy: 0.7500\n",
            "Epoch 2/5\n",
            "39/39 [==============================] - 3s 85ms/step - loss: 19.7260 - accuracy: 0.8846 - val_loss: 9.1401 - val_accuracy: 0.9007\n",
            "Epoch 3/5\n",
            "39/39 [==============================] - 3s 87ms/step - loss: 4.9226 - accuracy: 0.8887 - val_loss: 2.6930 - val_accuracy: 0.7059\n",
            "Epoch 4/5\n",
            "39/39 [==============================] - 3s 86ms/step - loss: 1.4892 - accuracy: 0.8719 - val_loss: 1.1956 - val_accuracy: 0.4963\n",
            "Epoch 5/5\n",
            "39/39 [==============================] - 3s 85ms/step - loss: 0.7255 - accuracy: 0.8572 - val_loss: 0.8500 - val_accuracy: 0.4853\n",
            "1.13482214152269e-06 22.16136821064544\n",
            "Epoch 1/5\n",
            "10/10 [==============================] - 3s 347ms/step - loss: 107.8366 - accuracy: 0.3261 - val_loss: 107.5568 - val_accuracy: 0.3897\n",
            "Epoch 2/5\n",
            "10/10 [==============================] - 3s 332ms/step - loss: 107.7165 - accuracy: 0.3412 - val_loss: 107.4495 - val_accuracy: 0.3713\n",
            "Epoch 3/5\n",
            "10/10 [==============================] - 3s 329ms/step - loss: 107.6023 - accuracy: 0.3564 - val_loss: 107.3423 - val_accuracy: 0.3713\n",
            "Epoch 4/5\n",
            "10/10 [==============================] - 3s 327ms/step - loss: 107.4825 - accuracy: 0.3662 - val_loss: 107.2352 - val_accuracy: 0.3529\n",
            "Epoch 5/5\n",
            "10/10 [==============================] - 3s 329ms/step - loss: 107.3680 - accuracy: 0.3822 - val_loss: 107.1283 - val_accuracy: 0.3566\n",
            "0.0013104383049520783 0.0011165682675835212\n",
            "Epoch 1/5\n",
            "77/77 [==============================] - 4s 49ms/step - loss: 0.4790 - accuracy: 0.8331 - val_loss: 0.5348 - val_accuracy: 0.8051\n",
            "Epoch 2/5\n",
            "77/77 [==============================] - 4s 47ms/step - loss: 0.2973 - accuracy: 0.8912 - val_loss: 0.4947 - val_accuracy: 0.8235\n",
            "Epoch 3/5\n",
            "77/77 [==============================] - 4s 47ms/step - loss: 0.1858 - accuracy: 0.9341 - val_loss: 0.4249 - val_accuracy: 0.8309\n",
            "Epoch 4/5\n",
            "77/77 [==============================] - 4s 47ms/step - loss: 0.1411 - accuracy: 0.9484 - val_loss: 0.3317 - val_accuracy: 0.8934\n",
            "Epoch 5/5\n",
            "77/77 [==============================] - 4s 47ms/step - loss: 0.1195 - accuracy: 0.9615 - val_loss: 0.3007 - val_accuracy: 0.8897\n",
            "8.767958137811632e-06 1.312458442073099\n",
            "Epoch 1/5\n",
            "39/39 [==============================] - 3s 88ms/step - loss: 8.6109 - accuracy: 0.7156 - val_loss: 8.7023 - val_accuracy: 0.7353\n",
            "Epoch 2/5\n",
            "39/39 [==============================] - 3s 84ms/step - loss: 8.5248 - accuracy: 0.7860 - val_loss: 8.6737 - val_accuracy: 0.7390\n",
            "Epoch 3/5\n",
            "39/39 [==============================] - 3s 84ms/step - loss: 8.4841 - accuracy: 0.8024 - val_loss: 8.6445 - val_accuracy: 0.7721\n",
            "Epoch 4/5\n",
            "39/39 [==============================] - 3s 86ms/step - loss: 8.4516 - accuracy: 0.8118 - val_loss: 8.6139 - val_accuracy: 0.7831\n",
            "Epoch 5/5\n",
            "39/39 [==============================] - 3s 85ms/step - loss: 8.4223 - accuracy: 0.8228 - val_loss: 8.5815 - val_accuracy: 0.7978\n",
            "0.00211618932692069 0.1593022347104578\n",
            "Epoch 1/5\n",
            "10/10 [==============================] - 3s 345ms/step - loss: 1.7559 - accuracy: 0.7786 - val_loss: 1.8018 - val_accuracy: 0.5368\n",
            "Epoch 2/5\n",
            "10/10 [==============================] - 3s 329ms/step - loss: 1.5834 - accuracy: 0.8273 - val_loss: 1.9503 - val_accuracy: 0.5699\n",
            "Epoch 3/5\n",
            "10/10 [==============================] - 3s 330ms/step - loss: 1.5296 - accuracy: 0.8388 - val_loss: 1.8892 - val_accuracy: 0.5919\n",
            "Epoch 4/5\n",
            "10/10 [==============================] - 3s 326ms/step - loss: 1.4773 - accuracy: 0.8625 - val_loss: 1.5065 - val_accuracy: 0.9081\n",
            "Epoch 5/5\n",
            "10/10 [==============================] - 3s 329ms/step - loss: 1.3115 - accuracy: 0.8764 - val_loss: 1.7690 - val_accuracy: 0.6654\n",
            "0.007313643563067671 0.022494382078465793\n",
            "Epoch 1/5\n",
            "39/39 [==============================] - 4s 90ms/step - loss: 1.8235 - accuracy: 0.8232 - val_loss: 1.2650 - val_accuracy: 0.4853\n",
            "Epoch 2/5\n",
            "39/39 [==============================] - 3s 84ms/step - loss: 0.3707 - accuracy: 0.9337 - val_loss: 1.6295 - val_accuracy: 0.4853\n",
            "Epoch 3/5\n",
            "39/39 [==============================] - 3s 85ms/step - loss: 0.2105 - accuracy: 0.9685 - val_loss: 1.9442 - val_accuracy: 0.4853\n",
            "Epoch 4/5\n",
            "39/39 [==============================] - 3s 85ms/step - loss: 0.1798 - accuracy: 0.9755 - val_loss: 1.7511 - val_accuracy: 0.4853\n",
            "Epoch 5/5\n",
            "39/39 [==============================] - 3s 87ms/step - loss: 0.1569 - accuracy: 0.9828 - val_loss: 1.6067 - val_accuracy: 0.4853\n",
            "0.019604171936828275 0.621092628194791\n",
            "Epoch 1/5\n",
            "20/20 [==============================] - 3s 172ms/step - loss: 5.2891 - accuracy: 0.7971 - val_loss: 3.2552 - val_accuracy: 0.4853\n",
            "Epoch 2/5\n",
            "20/20 [==============================] - 3s 160ms/step - loss: 1.4745 - accuracy: 0.8748 - val_loss: 2.0528 - val_accuracy: 0.4853\n",
            "Epoch 3/5\n",
            "20/20 [==============================] - 3s 163ms/step - loss: 0.7608 - accuracy: 0.9210 - val_loss: 1.6079 - val_accuracy: 0.4853\n",
            "Epoch 4/5\n",
            "20/20 [==============================] - 3s 164ms/step - loss: 0.3467 - accuracy: 0.9386 - val_loss: 1.0736 - val_accuracy: 0.4853\n",
            "Epoch 5/5\n",
            "20/20 [==============================] - 3s 161ms/step - loss: 0.2215 - accuracy: 0.9574 - val_loss: 1.4269 - val_accuracy: 0.4853\n",
            "2.8931145447055283e-05 4.027932173228817e-06\n",
            "Epoch 1/5\n",
            "39/39 [==============================] - 4s 90ms/step - loss: 0.6201 - accuracy: 0.6682 - val_loss: 0.6640 - val_accuracy: 0.6544\n",
            "Epoch 2/5\n",
            "39/39 [==============================] - 3s 86ms/step - loss: 0.4554 - accuracy: 0.8073 - val_loss: 0.6395 - val_accuracy: 0.6949\n",
            "Epoch 3/5\n",
            "39/39 [==============================] - 3s 84ms/step - loss: 0.4023 - accuracy: 0.8384 - val_loss: 0.6169 - val_accuracy: 0.7059\n",
            "Epoch 4/5\n",
            "39/39 [==============================] - 3s 83ms/step - loss: 0.3857 - accuracy: 0.8490 - val_loss: 0.5934 - val_accuracy: 0.7463\n",
            "Epoch 5/5\n",
            "39/39 [==============================] - 3s 84ms/step - loss: 0.3675 - accuracy: 0.8531 - val_loss: 0.5686 - val_accuracy: 0.7684\n",
            "0.04296915632618949 0.030093282245371514\n",
            "Epoch 1/5\n",
            "20/20 [==============================] - 3s 167ms/step - loss: 6.3180 - accuracy: 0.8159 - val_loss: 3.6790 - val_accuracy: 0.4853\n",
            "Epoch 2/5\n",
            "20/20 [==============================] - 3s 159ms/step - loss: 0.5133 - accuracy: 0.9464 - val_loss: 3.4359 - val_accuracy: 0.4853\n",
            "Epoch 3/5\n",
            "20/20 [==============================] - 3s 160ms/step - loss: 1.8482 - accuracy: 0.8912 - val_loss: 3.2117 - val_accuracy: 0.4853\n",
            "Epoch 4/5\n",
            "20/20 [==============================] - 3s 160ms/step - loss: 0.4688 - accuracy: 0.9542 - val_loss: 4.4854 - val_accuracy: 0.4853\n",
            "Epoch 5/5\n",
            "20/20 [==============================] - 3s 161ms/step - loss: 0.4101 - accuracy: 0.9558 - val_loss: 6.5635 - val_accuracy: 0.4853\n",
            "2.378291822173271e-06 1.0646129564835294e-05\n",
            "Epoch 1/5\n",
            "39/39 [==============================] - 3s 90ms/step - loss: 0.6132 - accuracy: 0.6543 - val_loss: 0.6659 - val_accuracy: 0.6471\n",
            "Epoch 2/5\n",
            "39/39 [==============================] - 3s 87ms/step - loss: 0.5584 - accuracy: 0.6948 - val_loss: 0.6567 - val_accuracy: 0.6912\n",
            "Epoch 3/5\n",
            "39/39 [==============================] - 3s 83ms/step - loss: 0.5330 - accuracy: 0.7565 - val_loss: 0.6471 - val_accuracy: 0.6875\n",
            "Epoch 4/5\n",
            "39/39 [==============================] - 3s 83ms/step - loss: 0.5121 - accuracy: 0.7836 - val_loss: 0.6366 - val_accuracy: 0.7059\n",
            "Epoch 5/5\n",
            "39/39 [==============================] - 3s 80ms/step - loss: 0.4991 - accuracy: 0.7926 - val_loss: 0.6250 - val_accuracy: 0.7022\n",
            "0.0930000965411884 2.043574259535878e-05\n",
            "Epoch 1/5\n",
            "20/20 [==============================] - 3s 170ms/step - loss: 20867101.1162 - accuracy: 0.5479 - val_loss: 3560135288.4706 - val_accuracy: 0.4853\n",
            "Epoch 2/5\n",
            "20/20 [==============================] - 3s 160ms/step - loss: 2929677522497750016.0000 - accuracy: 0.4877 - val_loss: 391977445484184862720.0000 - val_accuracy: 0.4853\n",
            "Epoch 3/5\n",
            "20/20 [==============================] - 3s 161ms/step - loss: 117092831761559815700405551104.0000 - accuracy: 0.4984 - val_loss: 10709876680497339466143655526400.0000 - val_accuracy: 0.4853\n",
            "Epoch 4/5\n",
            "20/20 [==============================] - 3s 160ms/step - loss: nan - accuracy: 0.5082 - val_loss: nan - val_accuracy: 0.4853\n",
            "Epoch 5/5\n",
            "20/20 [==============================] - 3s 159ms/step - loss: nan - accuracy: 0.5016 - val_loss: nan - val_accuracy: 0.4853\n",
            "3.0974543805016765e-06 6.586205047429152e-05\n",
            "Epoch 1/5\n",
            "20/20 [==============================] - 3s 171ms/step - loss: 0.5381 - accuracy: 0.7627 - val_loss: 0.6714 - val_accuracy: 0.6507\n",
            "Epoch 2/5\n",
            "20/20 [==============================] - 3s 161ms/step - loss: 0.5323 - accuracy: 0.7655 - val_loss: 0.6681 - val_accuracy: 0.6581\n",
            "Epoch 3/5\n",
            "20/20 [==============================] - 3s 157ms/step - loss: 0.5262 - accuracy: 0.7684 - val_loss: 0.6645 - val_accuracy: 0.6691\n",
            "Epoch 4/5\n",
            "20/20 [==============================] - 3s 161ms/step - loss: 0.5148 - accuracy: 0.7774 - val_loss: 0.6606 - val_accuracy: 0.6801\n",
            "Epoch 5/5\n",
            "20/20 [==============================] - 3s 160ms/step - loss: 0.5313 - accuracy: 0.7750 - val_loss: 0.6563 - val_accuracy: 0.6985\n",
            "0.005485005234409067 9.308738140429488\n",
            "Epoch 1/5\n",
            "20/20 [==============================] - 3s 171ms/step - loss: 15.0321 - accuracy: 0.7602 - val_loss: 1.3477 - val_accuracy: 0.4853\n",
            "Epoch 2/5\n",
            "20/20 [==============================] - 3s 161ms/step - loss: 0.5820 - accuracy: 0.8748 - val_loss: 0.7761 - val_accuracy: 0.4853\n",
            "Epoch 3/5\n",
            "20/20 [==============================] - 3s 162ms/step - loss: 0.3730 - accuracy: 0.8908 - val_loss: 0.8403 - val_accuracy: 0.4853\n",
            "Epoch 4/5\n",
            "20/20 [==============================] - 3s 160ms/step - loss: 0.4321 - accuracy: 0.8613 - val_loss: 0.8260 - val_accuracy: 0.4853\n",
            "Epoch 5/5\n",
            "20/20 [==============================] - 3s 161ms/step - loss: 0.3602 - accuracy: 0.9034 - val_loss: 0.8885 - val_accuracy: 0.4853\n",
            "6.582710311298122e-06 0.05156704155478945\n",
            "Epoch 1/5\n",
            "39/39 [==============================] - 3s 86ms/step - loss: 1.3068 - accuracy: 0.3048 - val_loss: 0.9670 - val_accuracy: 0.4743\n",
            "Epoch 2/5\n",
            "39/39 [==============================] - 3s 80ms/step - loss: 1.0505 - accuracy: 0.4808 - val_loss: 0.9551 - val_accuracy: 0.6324\n",
            "Epoch 3/5\n",
            "39/39 [==============================] - 3s 81ms/step - loss: 0.9309 - accuracy: 0.6326 - val_loss: 0.9429 - val_accuracy: 0.6765\n",
            "Epoch 4/5\n",
            "39/39 [==============================] - 3s 81ms/step - loss: 0.8633 - accuracy: 0.7083 - val_loss: 0.9292 - val_accuracy: 0.6838\n",
            "Epoch 5/5\n",
            "39/39 [==============================] - 3s 80ms/step - loss: 0.8126 - accuracy: 0.7525 - val_loss: 0.9140 - val_accuracy: 0.6912\n",
            "0.016371773087835363 1.4954942796728862e-06\n",
            "Epoch 1/5\n",
            "77/77 [==============================] - 3s 42ms/step - loss: 1.3707 - accuracy: 0.8899 - val_loss: 2.4414 - val_accuracy: 0.4853\n",
            "Epoch 2/5\n",
            "77/77 [==============================] - 3s 40ms/step - loss: 0.1292 - accuracy: 0.9615 - val_loss: 2.1530 - val_accuracy: 0.4853\n",
            "Epoch 3/5\n",
            "77/77 [==============================] - 3s 40ms/step - loss: 0.0890 - accuracy: 0.9697 - val_loss: 2.6536 - val_accuracy: 0.4853\n",
            "Epoch 4/5\n",
            "77/77 [==============================] - 3s 40ms/step - loss: 0.1012 - accuracy: 0.9689 - val_loss: 1.2072 - val_accuracy: 0.5993\n",
            "Epoch 5/5\n",
            "77/77 [==============================] - 3s 41ms/step - loss: 0.0486 - accuracy: 0.9820 - val_loss: 0.7216 - val_accuracy: 0.7353\n",
            "1.2740525569913064e-06 2.839057521588019\n",
            "Epoch 1/5\n",
            "20/20 [==============================] - 3s 166ms/step - loss: 17.5306 - accuracy: 0.3576 - val_loss: 17.2907 - val_accuracy: 0.4118\n",
            "Epoch 2/5\n",
            "20/20 [==============================] - 3s 156ms/step - loss: 17.4779 - accuracy: 0.3940 - val_loss: 17.2846 - val_accuracy: 0.4338\n",
            "Epoch 3/5\n",
            "20/20 [==============================] - 3s 156ms/step - loss: 17.4438 - accuracy: 0.4284 - val_loss: 17.2783 - val_accuracy: 0.4669\n",
            "Epoch 4/5\n",
            "20/20 [==============================] - 3s 153ms/step - loss: 17.4235 - accuracy: 0.4595 - val_loss: 17.2719 - val_accuracy: 0.4853\n",
            "Epoch 5/5\n",
            "20/20 [==============================] - 3s 155ms/step - loss: 17.3693 - accuracy: 0.4877 - val_loss: 17.2652 - val_accuracy: 0.5110\n",
            "0.0001495897199189532 60.11280495977497\n",
            "Epoch 1/5\n",
            "77/77 [==============================] - 3s 42ms/step - loss: 101.2721 - accuracy: 0.8212 - val_loss: 18.7135 - val_accuracy: 0.8713\n",
            "Epoch 2/5\n",
            "77/77 [==============================] - 3s 41ms/step - loss: 6.6432 - accuracy: 0.8429 - val_loss: 1.8352 - val_accuracy: 0.5000\n",
            "Epoch 3/5\n",
            "77/77 [==============================] - 3s 41ms/step - loss: 0.9520 - accuracy: 0.8163 - val_loss: 0.8023 - val_accuracy: 0.5037\n",
            "Epoch 4/5\n",
            "77/77 [==============================] - 3s 41ms/step - loss: 0.6149 - accuracy: 0.7975 - val_loss: 0.7251 - val_accuracy: 0.6029\n",
            "Epoch 5/5\n",
            "77/77 [==============================] - 3s 40ms/step - loss: 0.5886 - accuracy: 0.7991 - val_loss: 0.7072 - val_accuracy: 0.7316\n",
            "9.894961927238196e-06 228.53709173492962\n",
            "Epoch 1/5\n",
            "10/10 [==============================] - 3s 342ms/step - loss: 1222.0402 - accuracy: 0.6313 - val_loss: 1162.4012 - val_accuracy: 0.5699\n",
            "Epoch 2/5\n",
            "10/10 [==============================] - 3s 322ms/step - loss: 1116.2872 - accuracy: 0.6616 - val_loss: 1061.7115 - val_accuracy: 0.5882\n",
            "Epoch 3/5\n",
            "10/10 [==============================] - 3s 316ms/step - loss: 1019.5268 - accuracy: 0.6809 - val_loss: 969.7489 - val_accuracy: 0.6176\n",
            "Epoch 4/5\n",
            "10/10 [==============================] - 3s 317ms/step - loss: 931.4134 - accuracy: 0.7001 - val_loss: 885.7572 - val_accuracy: 0.6360\n",
            "Epoch 5/5\n",
            "10/10 [==============================] - 3s 316ms/step - loss: 850.6261 - accuracy: 0.7144 - val_loss: 809.0452 - val_accuracy: 0.6581\n",
            "0.005110405188945623 2.4667584414228006e-05\n",
            "Epoch 1/5\n",
            "77/77 [==============================] - 3s 44ms/step - loss: 1.0387 - accuracy: 0.8617 - val_loss: 1.6614 - val_accuracy: 0.4853\n",
            "Epoch 2/5\n",
            "77/77 [==============================] - 3s 42ms/step - loss: 0.2005 - accuracy: 0.9382 - val_loss: 1.6724 - val_accuracy: 0.4853\n",
            "Epoch 3/5\n",
            "77/77 [==============================] - 3s 42ms/step - loss: 0.0928 - accuracy: 0.9664 - val_loss: 1.4207 - val_accuracy: 0.4926\n",
            "Epoch 4/5\n",
            "77/77 [==============================] - 3s 42ms/step - loss: 0.0618 - accuracy: 0.9795 - val_loss: 0.9033 - val_accuracy: 0.6066\n",
            "Epoch 5/5\n",
            "77/77 [==============================] - 3s 42ms/step - loss: 0.0594 - accuracy: 0.9787 - val_loss: 0.9176 - val_accuracy: 0.6728\n",
            "0.06823922138161892 2.4239193449679347e-06\n",
            "Epoch 1/5\n",
            "77/77 [==============================] - 3s 45ms/step - loss: 4.5945 - accuracy: 0.8290 - val_loss: 1.6797 - val_accuracy: 0.4853\n",
            "Epoch 2/5\n",
            "77/77 [==============================] - 3s 43ms/step - loss: 0.1876 - accuracy: 0.9341 - val_loss: 0.5664 - val_accuracy: 0.6765\n",
            "Epoch 3/5\n",
            "77/77 [==============================] - 3s 44ms/step - loss: 0.1577 - accuracy: 0.9448 - val_loss: 0.2865 - val_accuracy: 0.8934\n",
            "Epoch 4/5\n",
            "77/77 [==============================] - 3s 43ms/step - loss: 0.1306 - accuracy: 0.9525 - val_loss: 0.2248 - val_accuracy: 0.9265\n",
            "Epoch 5/5\n",
            "77/77 [==============================] - 3s 44ms/step - loss: 0.1191 - accuracy: 0.9554 - val_loss: 0.1736 - val_accuracy: 0.9412\n",
            "0.00011733791451882245 0.00017655850336334038\n",
            "Epoch 1/5\n",
            "20/20 [==============================] - 3s 162ms/step - loss: 0.6187 - accuracy: 0.6661 - val_loss: 0.6615 - val_accuracy: 0.6581\n",
            "Epoch 2/5\n",
            "20/20 [==============================] - 3s 153ms/step - loss: 0.4146 - accuracy: 0.8277 - val_loss: 0.6423 - val_accuracy: 0.7316\n",
            "Epoch 3/5\n",
            "20/20 [==============================] - 3s 156ms/step - loss: 0.3644 - accuracy: 0.8515 - val_loss: 0.6270 - val_accuracy: 0.7426\n",
            "Epoch 4/5\n",
            "20/20 [==============================] - 3s 154ms/step - loss: 0.3441 - accuracy: 0.8601 - val_loss: 0.6141 - val_accuracy: 0.7868\n",
            "Epoch 5/5\n",
            "20/20 [==============================] - 3s 157ms/step - loss: 0.3286 - accuracy: 0.8732 - val_loss: 0.6011 - val_accuracy: 0.8272\n",
            "0.0002604286215611087 2.238355066513844e-06\n",
            "Epoch 1/5\n",
            "77/77 [==============================] - 4s 48ms/step - loss: 0.3818 - accuracy: 0.8433 - val_loss: 0.6171 - val_accuracy: 0.8456\n",
            "Epoch 2/5\n",
            "77/77 [==============================] - 3s 44ms/step - loss: 0.2930 - accuracy: 0.8883 - val_loss: 0.5667 - val_accuracy: 0.8897\n",
            "Epoch 3/5\n",
            "77/77 [==============================] - 3s 45ms/step - loss: 0.2669 - accuracy: 0.8985 - val_loss: 0.5069 - val_accuracy: 0.9118\n",
            "Epoch 4/5\n",
            "77/77 [==============================] - 3s 44ms/step - loss: 0.2510 - accuracy: 0.9075 - val_loss: 0.4241 - val_accuracy: 0.9044\n",
            "Epoch 5/5\n",
            "77/77 [==============================] - 3s 45ms/step - loss: 0.2360 - accuracy: 0.9128 - val_loss: 0.3596 - val_accuracy: 0.9154\n",
            "0.0002894740302128779 5.508377485813129\n",
            "Epoch 1/5\n",
            "77/77 [==============================] - 4s 47ms/step - loss: 27.4836 - accuracy: 0.8723 - val_loss: 21.5443 - val_accuracy: 0.8676\n",
            "Epoch 2/5\n",
            "77/77 [==============================] - 3s 45ms/step - loss: 16.8770 - accuracy: 0.8977 - val_loss: 13.3871 - val_accuracy: 0.9007\n",
            "Epoch 3/5\n",
            "77/77 [==============================] - 3s 44ms/step - loss: 10.4129 - accuracy: 0.9071 - val_loss: 8.3803 - val_accuracy: 0.9118\n",
            "Epoch 4/5\n",
            "77/77 [==============================] - 3s 45ms/step - loss: 6.4541 - accuracy: 0.9133 - val_loss: 5.3083 - val_accuracy: 0.9191\n",
            "Epoch 5/5\n",
            "77/77 [==============================] - 3s 44ms/step - loss: 4.0454 - accuracy: 0.9190 - val_loss: 3.4064 - val_accuracy: 0.9081\n",
            "0.00040978733995319873 2.659877315009591e-05\n",
            "Epoch 1/5\n",
            "77/77 [==============================] - 4s 46ms/step - loss: 0.3378 - accuracy: 0.8797 - val_loss: 0.5962 - val_accuracy: 0.8162\n",
            "Epoch 2/5\n",
            "77/77 [==============================] - 3s 45ms/step - loss: 0.2610 - accuracy: 0.9022 - val_loss: 0.5363 - val_accuracy: 0.8897\n",
            "Epoch 3/5\n",
            "77/77 [==============================] - 3s 45ms/step - loss: 0.2348 - accuracy: 0.9063 - val_loss: 0.4555 - val_accuracy: 0.9154\n",
            "Epoch 4/5\n",
            "77/77 [==============================] - 3s 44ms/step - loss: 0.2178 - accuracy: 0.9198 - val_loss: 0.3885 - val_accuracy: 0.9228\n",
            "Epoch 5/5\n",
            "77/77 [==============================] - 3s 44ms/step - loss: 0.1997 - accuracy: 0.9268 - val_loss: 0.3111 - val_accuracy: 0.9191\n",
            "1.2521742859511585e-05 4.956919008438613e-06\n",
            "Epoch 1/5\n",
            "20/20 [==============================] - 3s 169ms/step - loss: 0.5869 - accuracy: 0.7115 - val_loss: 0.6640 - val_accuracy: 0.6434\n",
            "Epoch 2/5\n",
            "20/20 [==============================] - 3s 156ms/step - loss: 0.5134 - accuracy: 0.7844 - val_loss: 0.6555 - val_accuracy: 0.6544\n",
            "Epoch 3/5\n",
            "20/20 [==============================] - 3s 156ms/step - loss: 0.4778 - accuracy: 0.7930 - val_loss: 0.6473 - val_accuracy: 0.6875\n",
            "Epoch 4/5\n",
            "20/20 [==============================] - 3s 156ms/step - loss: 0.4632 - accuracy: 0.8003 - val_loss: 0.6388 - val_accuracy: 0.6949\n",
            "Epoch 5/5\n",
            "20/20 [==============================] - 3s 159ms/step - loss: 0.4554 - accuracy: 0.8106 - val_loss: 0.6301 - val_accuracy: 0.7022\n",
            "2.8172440023004288e-05 1.5992646979340682e-06\n",
            "Epoch 1/5\n",
            "39/39 [==============================] - 4s 90ms/step - loss: 0.5924 - accuracy: 0.7029 - val_loss: 0.6657 - val_accuracy: 0.5993\n",
            "Epoch 2/5\n",
            "39/39 [==============================] - 3s 83ms/step - loss: 0.4549 - accuracy: 0.8142 - val_loss: 0.6441 - val_accuracy: 0.6875\n",
            "Epoch 3/5\n",
            "39/39 [==============================] - 3s 83ms/step - loss: 0.4124 - accuracy: 0.8494 - val_loss: 0.6237 - val_accuracy: 0.7316\n",
            "Epoch 4/5\n",
            "39/39 [==============================] - 3s 82ms/step - loss: 0.3931 - accuracy: 0.8625 - val_loss: 0.6028 - val_accuracy: 0.7610\n",
            "Epoch 5/5\n",
            "39/39 [==============================] - 3s 84ms/step - loss: 0.3823 - accuracy: 0.8682 - val_loss: 0.5805 - val_accuracy: 0.7757\n",
            "0.00024515069498787603 0.0025872650145720164\n",
            "Epoch 1/5\n",
            "39/39 [==============================] - 3s 86ms/step - loss: 0.4321 - accuracy: 0.8302 - val_loss: 0.6309 - val_accuracy: 0.6875\n",
            "Epoch 2/5\n",
            "39/39 [==============================] - 3s 83ms/step - loss: 0.3342 - accuracy: 0.8834 - val_loss: 0.6001 - val_accuracy: 0.7316\n",
            "Epoch 3/5\n",
            "39/39 [==============================] - 3s 82ms/step - loss: 0.3080 - accuracy: 0.8977 - val_loss: 0.5722 - val_accuracy: 0.7647\n",
            "Epoch 4/5\n",
            "39/39 [==============================] - 3s 79ms/step - loss: 0.2847 - accuracy: 0.9002 - val_loss: 0.5426 - val_accuracy: 0.8051\n",
            "Epoch 5/5\n",
            "39/39 [==============================] - 3s 82ms/step - loss: 0.2698 - accuracy: 0.9034 - val_loss: 0.5069 - val_accuracy: 0.8382\n",
            "0.002630738369447698 172.40064361926085\n",
            "Epoch 1/5\n",
            "77/77 [==============================] - 4s 47ms/step - loss: 14.8003 - accuracy: 0.7144 - val_loss: 0.7777 - val_accuracy: 0.7316\n",
            "Epoch 2/5\n",
            "77/77 [==============================] - 3s 45ms/step - loss: 0.6692 - accuracy: 0.7426 - val_loss: 0.7366 - val_accuracy: 0.4853\n",
            "Epoch 3/5\n",
            "77/77 [==============================] - 4s 47ms/step - loss: 0.6511 - accuracy: 0.7336 - val_loss: 0.8252 - val_accuracy: 0.6691\n",
            "Epoch 4/5\n",
            "77/77 [==============================] - 4s 47ms/step - loss: 0.6802 - accuracy: 0.7263 - val_loss: 0.7500 - val_accuracy: 0.5294\n",
            "Epoch 5/5\n",
            "77/77 [==============================] - 4s 46ms/step - loss: 0.6885 - accuracy: 0.7279 - val_loss: 0.7229 - val_accuracy: 0.7610\n",
            "7.100252505517118e-05 94.04344062603474\n",
            "Epoch 1/5\n",
            "10/10 [==============================] - 3s 350ms/step - loss: 456.8476 - accuracy: 0.6665 - val_loss: 393.0658 - val_accuracy: 0.6250\n",
            "Epoch 2/5\n",
            "10/10 [==============================] - 3s 325ms/step - loss: 349.3551 - accuracy: 0.7758 - val_loss: 300.5461 - val_accuracy: 0.6838\n",
            "Epoch 3/5\n",
            "10/10 [==============================] - 3s 328ms/step - loss: 266.9169 - accuracy: 0.8146 - val_loss: 229.8430 - val_accuracy: 0.7096\n",
            "Epoch 4/5\n",
            "10/10 [==============================] - 3s 331ms/step - loss: 203.9980 - accuracy: 0.8273 - val_loss: 175.8112 - val_accuracy: 0.7463\n",
            "Epoch 5/5\n",
            "10/10 [==============================] - 3s 329ms/step - loss: 156.1409 - accuracy: 0.8376 - val_loss: 134.5196 - val_accuracy: 0.7537\n",
            "1.363161689868161e-06 717.544347837351\n",
            "Epoch 1/5\n",
            "20/20 [==============================] - 3s 168ms/step - loss: 3707.8620 - accuracy: 0.4067 - val_loss: 3557.5362 - val_accuracy: 0.4485\n",
            "Epoch 2/5\n",
            "20/20 [==============================] - 3s 158ms/step - loss: 3428.7736 - accuracy: 0.4083 - val_loss: 3289.5625 - val_accuracy: 0.4706\n",
            "Epoch 3/5\n",
            "20/20 [==============================] - 3s 158ms/step - loss: 3170.4248 - accuracy: 0.4231 - val_loss: 3041.7774 - val_accuracy: 0.5221\n",
            "Epoch 4/5\n",
            "20/20 [==============================] - 3s 155ms/step - loss: 2931.4724 - accuracy: 0.4480 - val_loss: 2812.6609 - val_accuracy: 0.5184\n",
            "Epoch 5/5\n",
            "20/20 [==============================] - 3s 156ms/step - loss: 2710.9652 - accuracy: 0.4693 - val_loss: 2600.8053 - val_accuracy: 0.5294\n",
            "2.910688143660302e-05 2.8834319279847327e-05\n",
            "Epoch 1/5\n",
            "20/20 [==============================] - 3s 162ms/step - loss: 0.7044 - accuracy: 0.6244 - val_loss: 0.6782 - val_accuracy: 0.5772\n",
            "Epoch 2/5\n",
            "20/20 [==============================] - 3s 154ms/step - loss: 0.4749 - accuracy: 0.8032 - val_loss: 0.6614 - val_accuracy: 0.6213\n",
            "Epoch 3/5\n",
            "20/20 [==============================] - 3s 158ms/step - loss: 0.4277 - accuracy: 0.8417 - val_loss: 0.6480 - val_accuracy: 0.6801\n",
            "Epoch 4/5\n",
            "20/20 [==============================] - 3s 155ms/step - loss: 0.4028 - accuracy: 0.8568 - val_loss: 0.6363 - val_accuracy: 0.6985\n",
            "Epoch 5/5\n",
            "20/20 [==============================] - 3s 157ms/step - loss: 0.3884 - accuracy: 0.8642 - val_loss: 0.6244 - val_accuracy: 0.7132\n",
            "0.007027531360049336 0.46854777043683987\n",
            "Epoch 1/5\n",
            "39/39 [==============================] - 3s 82ms/step - loss: 2.8268 - accuracy: 0.8314 - val_loss: 2.8673 - val_accuracy: 0.4853\n",
            "Epoch 2/5\n",
            "39/39 [==============================] - 3s 80ms/step - loss: 1.3601 - accuracy: 0.9268 - val_loss: 2.0130 - val_accuracy: 0.4853\n",
            "Epoch 3/5\n",
            "39/39 [==============================] - 3s 78ms/step - loss: 0.7446 - accuracy: 0.9660 - val_loss: 1.7271 - val_accuracy: 0.4853\n",
            "Epoch 4/5\n",
            "39/39 [==============================] - 3s 78ms/step - loss: 0.4791 - accuracy: 0.9693 - val_loss: 1.5844 - val_accuracy: 0.4853\n",
            "Epoch 5/5\n",
            "39/39 [==============================] - 3s 78ms/step - loss: 0.3236 - accuracy: 0.9750 - val_loss: 1.6945 - val_accuracy: 0.4853\n",
            "0.01155231625043052 2.806630544396993e-05\n",
            "Epoch 1/5\n",
            "77/77 [==============================] - 3s 43ms/step - loss: 1.6054 - accuracy: 0.8715 - val_loss: 3.0518 - val_accuracy: 0.4853\n",
            "Epoch 2/5\n",
            "77/77 [==============================] - 3s 42ms/step - loss: 0.1514 - accuracy: 0.9591 - val_loss: 3.0878 - val_accuracy: 0.4853\n",
            "Epoch 3/5\n",
            "77/77 [==============================] - 3s 40ms/step - loss: 0.0911 - accuracy: 0.9714 - val_loss: 2.1775 - val_accuracy: 0.5000\n",
            "Epoch 4/5\n",
            "77/77 [==============================] - 3s 42ms/step - loss: 0.0499 - accuracy: 0.9845 - val_loss: 1.5594 - val_accuracy: 0.5588\n",
            "Epoch 5/5\n",
            "77/77 [==============================] - 3s 42ms/step - loss: 0.0377 - accuracy: 0.9885 - val_loss: 0.7752 - val_accuracy: 0.7757\n",
            "2.3774850786738736e-06 0.00017330572732585908\n",
            "Epoch 1/5\n",
            "10/10 [==============================] - 4s 355ms/step - loss: 0.6913 - accuracy: 0.5896 - val_loss: 0.6915 - val_accuracy: 0.5441\n",
            "Epoch 2/5\n",
            "10/10 [==============================] - 3s 325ms/step - loss: 0.6754 - accuracy: 0.6203 - val_loss: 0.6900 - val_accuracy: 0.5699\n",
            "Epoch 3/5\n",
            "10/10 [==============================] - 3s 320ms/step - loss: 0.6629 - accuracy: 0.6420 - val_loss: 0.6884 - val_accuracy: 0.5625\n",
            "Epoch 4/5\n",
            "10/10 [==============================] - 3s 319ms/step - loss: 0.6481 - accuracy: 0.6702 - val_loss: 0.6869 - val_accuracy: 0.5625\n",
            "Epoch 5/5\n",
            "10/10 [==============================] - 3s 324ms/step - loss: 0.6379 - accuracy: 0.6866 - val_loss: 0.6853 - val_accuracy: 0.5772\n",
            "0.020772522865707917 26.236974149051044\n",
            "Epoch 1/5\n",
            "77/77 [==============================] - 3s 43ms/step - loss: 11.0884 - accuracy: 0.5381 - val_loss: 1.0095 - val_accuracy: 0.7316\n",
            "Epoch 2/5\n",
            "77/77 [==============================] - 3s 41ms/step - loss: 1.1679 - accuracy: 0.6121 - val_loss: 1.2559 - val_accuracy: 0.6324\n",
            "Epoch 3/5\n",
            "77/77 [==============================] - 3s 41ms/step - loss: 0.9150 - accuracy: 0.6399 - val_loss: 0.7425 - val_accuracy: 0.4853\n",
            "Epoch 4/5\n",
            "77/77 [==============================] - 3s 40ms/step - loss: 0.9146 - accuracy: 0.6436 - val_loss: 0.9786 - val_accuracy: 0.7941\n",
            "Epoch 5/5\n",
            "77/77 [==============================] - 3s 40ms/step - loss: 0.9102 - accuracy: 0.6776 - val_loss: 0.7845 - val_accuracy: 0.5147\n",
            "0.00572866786747167 0.020056464520598085\n",
            "Epoch 1/5\n",
            "39/39 [==============================] - 3s 84ms/step - loss: 1.1809 - accuracy: 0.8208 - val_loss: 0.9699 - val_accuracy: 0.4853\n",
            "Epoch 2/5\n",
            "39/39 [==============================] - 3s 78ms/step - loss: 0.3762 - accuracy: 0.9247 - val_loss: 1.7017 - val_accuracy: 0.4853\n",
            "Epoch 3/5\n",
            "39/39 [==============================] - 3s 78ms/step - loss: 0.2179 - accuracy: 0.9624 - val_loss: 1.9401 - val_accuracy: 0.4853\n",
            "Epoch 4/5\n",
            "39/39 [==============================] - 3s 79ms/step - loss: 0.2695 - accuracy: 0.9509 - val_loss: 1.7873 - val_accuracy: 0.4853\n",
            "Epoch 5/5\n",
            "39/39 [==============================] - 3s 78ms/step - loss: 0.1695 - accuracy: 0.9750 - val_loss: 1.5797 - val_accuracy: 0.4853\n",
            "0.005264670464255857 0.015045890053886787\n",
            "Epoch 1/5\n",
            "20/20 [==============================] - 3s 161ms/step - loss: 1.0382 - accuracy: 0.8122 - val_loss: 0.6423 - val_accuracy: 0.8493\n",
            "Epoch 2/5\n",
            "20/20 [==============================] - 3s 152ms/step - loss: 0.4219 - accuracy: 0.8973 - val_loss: 0.7223 - val_accuracy: 0.5037\n",
            "Epoch 3/5\n",
            "20/20 [==============================] - 3s 155ms/step - loss: 0.3354 - accuracy: 0.9153 - val_loss: 0.7025 - val_accuracy: 0.5074\n",
            "Epoch 4/5\n",
            "20/20 [==============================] - 3s 154ms/step - loss: 0.2306 - accuracy: 0.9456 - val_loss: 0.7607 - val_accuracy: 0.4890\n",
            "Epoch 5/5\n",
            "20/20 [==============================] - 3s 153ms/step - loss: 0.2170 - accuracy: 0.9480 - val_loss: 0.8372 - val_accuracy: 0.4853\n",
            "2.142971812438172e-05 0.013431414667355111\n",
            "Epoch 1/5\n",
            "39/39 [==============================] - 3s 81ms/step - loss: 0.6567 - accuracy: 0.7255 - val_loss: 0.7440 - val_accuracy: 0.6250\n",
            "Epoch 2/5\n",
            "39/39 [==============================] - 3s 77ms/step - loss: 0.5406 - accuracy: 0.8146 - val_loss: 0.7224 - val_accuracy: 0.6912\n",
            "Epoch 3/5\n",
            "39/39 [==============================] - 3s 77ms/step - loss: 0.5019 - accuracy: 0.8490 - val_loss: 0.7011 - val_accuracy: 0.7463\n",
            "Epoch 4/5\n",
            "39/39 [==============================] - 3s 77ms/step - loss: 0.4803 - accuracy: 0.8523 - val_loss: 0.6793 - val_accuracy: 0.7500\n",
            "Epoch 5/5\n",
            "39/39 [==============================] - 3s 79ms/step - loss: 0.4689 - accuracy: 0.8601 - val_loss: 0.6565 - val_accuracy: 0.7610\n",
            "3.2517971280312804e-05 0.1180072845391285\n",
            "Epoch 1/5\n",
            "39/39 [==============================] - 3s 81ms/step - loss: 1.4396 - accuracy: 0.6502 - val_loss: 1.4451 - val_accuracy: 0.6360\n",
            "Epoch 2/5\n",
            "39/39 [==============================] - 3s 77ms/step - loss: 1.2287 - accuracy: 0.8220 - val_loss: 1.4189 - val_accuracy: 0.7096\n",
            "Epoch 3/5\n",
            "39/39 [==============================] - 3s 78ms/step - loss: 1.1770 - accuracy: 0.8457 - val_loss: 1.3945 - val_accuracy: 0.7426\n",
            "Epoch 4/5\n",
            "39/39 [==============================] - 3s 78ms/step - loss: 1.1544 - accuracy: 0.8572 - val_loss: 1.3698 - val_accuracy: 0.7721\n",
            "Epoch 5/5\n",
            "39/39 [==============================] - 3s 78ms/step - loss: 1.1243 - accuracy: 0.8650 - val_loss: 1.3427 - val_accuracy: 0.7868\n",
            "1.7126570301167812e-06 0.0003481727396889091\n",
            "Epoch 1/5\n",
            "10/10 [==============================] - 3s 341ms/step - loss: 0.8558 - accuracy: 0.3621 - val_loss: 0.6929 - val_accuracy: 0.4963\n",
            "Epoch 2/5\n",
            "10/10 [==============================] - 3s 321ms/step - loss: 0.8502 - accuracy: 0.3707 - val_loss: 0.6917 - val_accuracy: 0.5257\n",
            "Epoch 3/5\n",
            "10/10 [==============================] - 3s 320ms/step - loss: 0.8321 - accuracy: 0.3842 - val_loss: 0.6905 - val_accuracy: 0.5588\n",
            "Epoch 4/5\n",
            "10/10 [==============================] - 3s 323ms/step - loss: 0.8186 - accuracy: 0.3989 - val_loss: 0.6892 - val_accuracy: 0.5662\n",
            "Epoch 5/5\n",
            "10/10 [==============================] - 3s 322ms/step - loss: 0.8044 - accuracy: 0.4178 - val_loss: 0.6879 - val_accuracy: 0.5809\n",
            "2.600146943243313e-06 0.8863467066476497\n",
            "Epoch 1/5\n",
            "10/10 [==============================] - 3s 343ms/step - loss: 5.6716 - accuracy: 0.4268 - val_loss: 5.4802 - val_accuracy: 0.3934\n",
            "Epoch 2/5\n",
            "10/10 [==============================] - 3s 322ms/step - loss: 5.6475 - accuracy: 0.4435 - val_loss: 5.4791 - val_accuracy: 0.4007\n",
            "Epoch 3/5\n",
            "10/10 [==============================] - 3s 319ms/step - loss: 5.6275 - accuracy: 0.4664 - val_loss: 5.4780 - val_accuracy: 0.4044\n",
            "Epoch 4/5\n",
            "10/10 [==============================] - 3s 322ms/step - loss: 5.6076 - accuracy: 0.4877 - val_loss: 5.4768 - val_accuracy: 0.4338\n",
            "Epoch 5/5\n",
            "10/10 [==============================] - 3s 318ms/step - loss: 5.5872 - accuracy: 0.5061 - val_loss: 5.4756 - val_accuracy: 0.4596\n",
            "0.0003783158212840578 0.11694890110892844\n",
            "Epoch 1/5\n",
            "77/77 [==============================] - 3s 42ms/step - loss: 1.0530 - accuracy: 0.8552 - val_loss: 1.2698 - val_accuracy: 0.7132\n",
            "Epoch 2/5\n",
            "77/77 [==============================] - 3s 40ms/step - loss: 0.9523 - accuracy: 0.8965 - val_loss: 1.1958 - val_accuracy: 0.7610\n",
            "Epoch 3/5\n",
            "77/77 [==============================] - 3s 40ms/step - loss: 0.9156 - accuracy: 0.9100 - val_loss: 1.1144 - val_accuracy: 0.8309\n",
            "Epoch 4/5\n",
            "77/77 [==============================] - 3s 40ms/step - loss: 0.8862 - accuracy: 0.9157 - val_loss: 1.0347 - val_accuracy: 0.8529\n",
            "Epoch 5/5\n",
            "77/77 [==============================] - 3s 40ms/step - loss: 0.8611 - accuracy: 0.9235 - val_loss: 0.9729 - val_accuracy: 0.8750\n",
            "9.411150572514867e-05 0.0032625147078927425\n",
            "Epoch 1/5\n",
            "10/10 [==============================] - 3s 338ms/step - loss: 0.6840 - accuracy: 0.6178 - val_loss: 0.6966 - val_accuracy: 0.5699\n",
            "Epoch 2/5\n",
            "10/10 [==============================] - 3s 320ms/step - loss: 0.5267 - accuracy: 0.7901 - val_loss: 0.6849 - val_accuracy: 0.6176\n",
            "Epoch 3/5\n",
            "10/10 [==============================] - 3s 318ms/step - loss: 0.4729 - accuracy: 0.8331 - val_loss: 0.6769 - val_accuracy: 0.6691\n",
            "Epoch 4/5\n",
            "10/10 [==============================] - 3s 321ms/step - loss: 0.4351 - accuracy: 0.8523 - val_loss: 0.6699 - val_accuracy: 0.6912\n",
            "Epoch 5/5\n",
            "10/10 [==============================] - 3s 320ms/step - loss: 0.4184 - accuracy: 0.8601 - val_loss: 0.6640 - val_accuracy: 0.7169\n",
            "0.027468630327551185 4.893753444216898e-06\n",
            "Epoch 1/5\n",
            "10/10 [==============================] - 3s 338ms/step - loss: 6.0919 - accuracy: 0.7209 - val_loss: 5.7761 - val_accuracy: 0.4853\n",
            "Epoch 2/5\n",
            "10/10 [==============================] - 3s 326ms/step - loss: 0.3000 - accuracy: 0.9415 - val_loss: 3.2560 - val_accuracy: 0.4853\n",
            "Epoch 3/5\n",
            "10/10 [==============================] - 3s 324ms/step - loss: 1.6479 - accuracy: 0.8985 - val_loss: 4.3217 - val_accuracy: 0.4853\n",
            "Epoch 4/5\n",
            "10/10 [==============================] - 3s 323ms/step - loss: 0.4811 - accuracy: 0.9194 - val_loss: 3.5970 - val_accuracy: 0.4853\n",
            "Epoch 5/5\n",
            "10/10 [==============================] - 3s 319ms/step - loss: 0.1067 - accuracy: 0.9697 - val_loss: 3.3970 - val_accuracy: 0.4853\n",
            "0.01110072476347387 0.00010058017638717954\n",
            "Epoch 1/5\n",
            "39/39 [==============================] - 3s 82ms/step - loss: 1.8175 - accuracy: 0.8355 - val_loss: 1.9270 - val_accuracy: 0.7279\n",
            "Epoch 2/5\n",
            "39/39 [==============================] - 3s 79ms/step - loss: 0.6356 - accuracy: 0.9276 - val_loss: 2.1565 - val_accuracy: 0.4853\n",
            "Epoch 3/5\n",
            "39/39 [==============================] - 3s 79ms/step - loss: 0.1621 - accuracy: 0.9603 - val_loss: 2.4512 - val_accuracy: 0.4853\n",
            "Epoch 4/5\n",
            "39/39 [==============================] - 3s 78ms/step - loss: 0.0925 - accuracy: 0.9730 - val_loss: 2.1802 - val_accuracy: 0.4853\n",
            "Epoch 5/5\n",
            "39/39 [==============================] - 3s 77ms/step - loss: 0.0571 - accuracy: 0.9812 - val_loss: 2.0181 - val_accuracy: 0.4926\n",
            "5.917461412803899e-06 0.08210873395074687\n",
            "Epoch 1/5\n",
            "20/20 [==============================] - 3s 165ms/step - loss: 1.2843 - accuracy: 0.5986 - val_loss: 1.1350 - val_accuracy: 0.5735\n",
            "Epoch 2/5\n",
            "20/20 [==============================] - 3s 156ms/step - loss: 1.1997 - accuracy: 0.6440 - val_loss: 1.1266 - val_accuracy: 0.6250\n",
            "Epoch 3/5\n",
            "20/20 [==============================] - 3s 155ms/step - loss: 1.1241 - accuracy: 0.6698 - val_loss: 1.1195 - val_accuracy: 0.6507\n",
            "Epoch 4/5\n",
            "20/20 [==============================] - 3s 155ms/step - loss: 1.0717 - accuracy: 0.6911 - val_loss: 1.1128 - val_accuracy: 0.6618\n",
            "Epoch 5/5\n",
            "20/20 [==============================] - 3s 157ms/step - loss: 1.0518 - accuracy: 0.7132 - val_loss: 1.1059 - val_accuracy: 0.6654\n",
            "0.00012347469001959478 5.595131674507475e-06\n",
            "Epoch 1/5\n",
            "77/77 [==============================] - 3s 44ms/step - loss: 0.4620 - accuracy: 0.8040 - val_loss: 0.6248 - val_accuracy: 0.7243\n",
            "Epoch 2/5\n",
            "77/77 [==============================] - 3s 42ms/step - loss: 0.3549 - accuracy: 0.8691 - val_loss: 0.5803 - val_accuracy: 0.8015\n",
            "Epoch 3/5\n",
            "77/77 [==============================] - 3s 42ms/step - loss: 0.3141 - accuracy: 0.8818 - val_loss: 0.5231 - val_accuracy: 0.8272\n",
            "Epoch 4/5\n",
            "77/77 [==============================] - 3s 42ms/step - loss: 0.2955 - accuracy: 0.8903 - val_loss: 0.4619 - val_accuracy: 0.8382\n",
            "Epoch 5/5\n",
            "77/77 [==============================] - 3s 41ms/step - loss: 0.2772 - accuracy: 0.9034 - val_loss: 0.4023 - val_accuracy: 0.8456\n",
            "8.962789020065325e-05 41.767430283738236\n",
            "Epoch 1/5\n",
            "20/20 [==============================] - 3s 168ms/step - loss: 209.0586 - accuracy: 0.7729 - val_loss: 178.1402 - val_accuracy: 0.6397\n",
            "Epoch 2/5\n",
            "20/20 [==============================] - 3s 160ms/step - loss: 154.8418 - accuracy: 0.8343 - val_loss: 132.0592 - val_accuracy: 0.7316\n",
            "Epoch 3/5\n",
            "20/20 [==============================] - 3s 159ms/step - loss: 114.7535 - accuracy: 0.8482 - val_loss: 97.9439 - val_accuracy: 0.7684\n",
            "Epoch 4/5\n",
            "20/20 [==============================] - 3s 158ms/step - loss: 85.0072 - accuracy: 0.8576 - val_loss: 72.6870 - val_accuracy: 0.8088\n",
            "Epoch 5/5\n",
            "20/20 [==============================] - 3s 156ms/step - loss: 63.0340 - accuracy: 0.8625 - val_loss: 53.9885 - val_accuracy: 0.8235\n",
            "0.014633691605617808 2.207896829299548e-06\n",
            "Epoch 1/5\n",
            "39/39 [==============================] - 3s 83ms/step - loss: 2.5108 - accuracy: 0.8204 - val_loss: 2.5657 - val_accuracy: 0.4853\n",
            "Epoch 2/5\n",
            "39/39 [==============================] - 3s 79ms/step - loss: 0.1939 - accuracy: 0.9534 - val_loss: 3.0384 - val_accuracy: 0.4853\n",
            "Epoch 3/5\n",
            "39/39 [==============================] - 3s 77ms/step - loss: 0.1008 - accuracy: 0.9685 - val_loss: 2.9304 - val_accuracy: 0.4853\n",
            "Epoch 4/5\n",
            "39/39 [==============================] - 3s 78ms/step - loss: 0.0730 - accuracy: 0.9771 - val_loss: 2.3839 - val_accuracy: 0.4853\n",
            "Epoch 5/5\n",
            "39/39 [==============================] - 3s 78ms/step - loss: 0.0526 - accuracy: 0.9795 - val_loss: 2.2846 - val_accuracy: 0.4853\n",
            "5.595007551352353e-06 4.455944813949866\n",
            "Epoch 1/5\n",
            "10/10 [==============================] - 3s 349ms/step - loss: 28.2187 - accuracy: 0.5147 - val_loss: 28.1083 - val_accuracy: 0.5368\n",
            "Epoch 2/5\n",
            "10/10 [==============================] - 3s 321ms/step - loss: 28.1606 - accuracy: 0.5241 - val_loss: 28.0788 - val_accuracy: 0.5588\n",
            "Epoch 3/5\n",
            "10/10 [==============================] - 3s 321ms/step - loss: 28.1076 - accuracy: 0.5503 - val_loss: 28.0492 - val_accuracy: 0.5919\n",
            "Epoch 4/5\n",
            "10/10 [==============================] - 3s 323ms/step - loss: 28.0608 - accuracy: 0.5712 - val_loss: 28.0197 - val_accuracy: 0.6324\n",
            "Epoch 5/5\n",
            "10/10 [==============================] - 3s 320ms/step - loss: 28.0123 - accuracy: 0.5933 - val_loss: 27.9901 - val_accuracy: 0.6544\n",
            "9.81237059589691e-06 1.6035411926555865e-05\n",
            "Epoch 1/5\n",
            "20/20 [==============================] - 3s 164ms/step - loss: 0.6235 - accuracy: 0.6399 - val_loss: 0.6814 - val_accuracy: 0.6066\n",
            "Epoch 2/5\n",
            "20/20 [==============================] - 3s 155ms/step - loss: 0.5814 - accuracy: 0.7312 - val_loss: 0.6748 - val_accuracy: 0.6838\n",
            "Epoch 3/5\n",
            "20/20 [==============================] - 3s 154ms/step - loss: 0.5405 - accuracy: 0.7557 - val_loss: 0.6690 - val_accuracy: 0.7132\n",
            "Epoch 4/5\n",
            "20/20 [==============================] - 3s 155ms/step - loss: 0.5166 - accuracy: 0.7672 - val_loss: 0.6631 - val_accuracy: 0.7279\n",
            "Epoch 5/5\n",
            "20/20 [==============================] - 3s 154ms/step - loss: 0.4962 - accuracy: 0.7750 - val_loss: 0.6569 - val_accuracy: 0.7316\n",
            "0.0006079648543150342 2.643413371549512\n",
            "Epoch 1/5\n",
            "10/10 [==============================] - 3s 341ms/step - loss: 14.1457 - accuracy: 0.7259 - val_loss: 13.7328 - val_accuracy: 0.6176\n",
            "Epoch 2/5\n",
            "10/10 [==============================] - 3s 324ms/step - loss: 13.0972 - accuracy: 0.8466 - val_loss: 12.9043 - val_accuracy: 0.6581\n",
            "Epoch 3/5\n",
            "10/10 [==============================] - 3s 322ms/step - loss: 12.2566 - accuracy: 0.8752 - val_loss: 12.1315 - val_accuracy: 0.6949\n",
            "Epoch 4/5\n",
            "10/10 [==============================] - 3s 322ms/step - loss: 11.4840 - accuracy: 0.8895 - val_loss: 11.4099 - val_accuracy: 0.6801\n",
            "Epoch 5/5\n",
            "10/10 [==============================] - 3s 323ms/step - loss: 10.7719 - accuracy: 0.8965 - val_loss: 10.7327 - val_accuracy: 0.7022\n",
            "0.00362320796093486 0.00010734151861140347\n",
            "Epoch 1/5\n",
            "39/39 [==============================] - 3s 82ms/step - loss: 0.8465 - accuracy: 0.8134 - val_loss: 0.4927 - val_accuracy: 0.8199\n",
            "Epoch 2/5\n",
            "39/39 [==============================] - 3s 77ms/step - loss: 0.3206 - accuracy: 0.9149 - val_loss: 0.5588 - val_accuracy: 0.6176\n",
            "Epoch 3/5\n",
            "39/39 [==============================] - 3s 79ms/step - loss: 0.2392 - accuracy: 0.9309 - val_loss: 0.6380 - val_accuracy: 0.5478\n",
            "Epoch 4/5\n",
            "39/39 [==============================] - 3s 78ms/step - loss: 0.1580 - accuracy: 0.9472 - val_loss: 0.7377 - val_accuracy: 0.5184\n",
            "Epoch 5/5\n",
            "39/39 [==============================] - 3s 79ms/step - loss: 0.0846 - accuracy: 0.9709 - val_loss: 0.8392 - val_accuracy: 0.5074\n",
            "0.019040875950140507 1.8844671133085595\n",
            "Epoch 1/5\n",
            "39/39 [==============================] - 3s 82ms/step - loss: 3.7805 - accuracy: 0.8171 - val_loss: 1.7535 - val_accuracy: 0.4853\n",
            "Epoch 2/5\n",
            "39/39 [==============================] - 3s 79ms/step - loss: 0.3281 - accuracy: 0.9047 - val_loss: 1.7180 - val_accuracy: 0.4853\n",
            "Epoch 3/5\n",
            "39/39 [==============================] - 3s 80ms/step - loss: 0.4196 - accuracy: 0.9047 - val_loss: 1.8649 - val_accuracy: 0.4853\n",
            "Epoch 4/5\n",
            "39/39 [==============================] - 3s 80ms/step - loss: 0.6204 - accuracy: 0.8875 - val_loss: 1.7029 - val_accuracy: 0.4853\n",
            "Epoch 5/5\n",
            "39/39 [==============================] - 3s 81ms/step - loss: 0.2012 - accuracy: 0.9468 - val_loss: 1.2101 - val_accuracy: 0.4853\n",
            "0.0009571754774389329 841.8797661170224\n",
            "Epoch 1/5\n",
            "10/10 [==============================] - 4s 350ms/step - loss: 748.1593 - accuracy: 0.7181 - val_loss: 0.9144 - val_accuracy: 0.4853\n",
            "Epoch 2/5\n",
            "10/10 [==============================] - 3s 332ms/step - loss: 0.7250 - accuracy: 0.7705 - val_loss: 0.7015 - val_accuracy: 0.4853\n",
            "Epoch 3/5\n",
            "10/10 [==============================] - 3s 336ms/step - loss: 0.6887 - accuracy: 0.7672 - val_loss: 0.7011 - val_accuracy: 0.4853\n",
            "Epoch 4/5\n",
            "10/10 [==============================] - 3s 333ms/step - loss: 0.6887 - accuracy: 0.7688 - val_loss: 0.7007 - val_accuracy: 0.4853\n",
            "Epoch 5/5\n",
            "10/10 [==============================] - 3s 336ms/step - loss: 0.6878 - accuracy: 0.7713 - val_loss: 0.7017 - val_accuracy: 0.4632\n",
            "0.009706363203111319 0.00083609545580548\n",
            "Epoch 1/5\n",
            "77/77 [==============================] - 4s 46ms/step - loss: 1.6869 - accuracy: 0.8572 - val_loss: 4.5134 - val_accuracy: 0.4853\n",
            "Epoch 2/5\n",
            "77/77 [==============================] - 3s 42ms/step - loss: 0.3300 - accuracy: 0.9439 - val_loss: 3.3930 - val_accuracy: 0.4853\n",
            "Epoch 3/5\n",
            "77/77 [==============================] - 3s 42ms/step - loss: 0.1207 - accuracy: 0.9673 - val_loss: 1.9993 - val_accuracy: 0.4963\n",
            "Epoch 4/5\n",
            "77/77 [==============================] - 3s 43ms/step - loss: 0.0739 - accuracy: 0.9783 - val_loss: 1.5251 - val_accuracy: 0.5441\n",
            "Epoch 5/5\n",
            "77/77 [==============================] - 3s 42ms/step - loss: 0.0427 - accuracy: 0.9869 - val_loss: 0.6754 - val_accuracy: 0.7904\n",
            "0.07918716686966588 6.929587544534332e-06\n",
            "Epoch 1/5\n",
            "77/77 [==============================] - 3s 45ms/step - loss: 14.8390 - accuracy: 0.8159 - val_loss: 0.5409 - val_accuracy: 0.9154\n",
            "Epoch 2/5\n",
            "77/77 [==============================] - 3s 43ms/step - loss: 5.0708 - accuracy: 0.8985 - val_loss: 6.1625 - val_accuracy: 0.8199\n",
            "Epoch 3/5\n",
            "77/77 [==============================] - 3s 42ms/step - loss: 1.4674 - accuracy: 0.9194 - val_loss: 0.9292 - val_accuracy: 0.9301\n",
            "Epoch 4/5\n",
            "77/77 [==============================] - 3s 42ms/step - loss: 0.6457 - accuracy: 0.9264 - val_loss: 13.4047 - val_accuracy: 0.7757\n",
            "Epoch 5/5\n",
            "77/77 [==============================] - 3s 42ms/step - loss: 0.8490 - accuracy: 0.9374 - val_loss: 0.4926 - val_accuracy: 0.9412\n",
            "0.018299997863033258 0.9739901250136133\n",
            "Epoch 1/5\n",
            "20/20 [==============================] - 3s 175ms/step - loss: 5.8857 - accuracy: 0.7762 - val_loss: 2.9133 - val_accuracy: 0.4853\n",
            "Epoch 2/5\n",
            "20/20 [==============================] - 3s 165ms/step - loss: 2.0674 - accuracy: 0.8363 - val_loss: 2.5876 - val_accuracy: 0.4853\n",
            "Epoch 3/5\n",
            "20/20 [==============================] - 3s 166ms/step - loss: 0.4945 - accuracy: 0.9214 - val_loss: 1.8386 - val_accuracy: 0.4853\n",
            "Epoch 4/5\n",
            "20/20 [==============================] - 3s 163ms/step - loss: 0.2410 - accuracy: 0.9489 - val_loss: 1.4563 - val_accuracy: 0.4853\n",
            "Epoch 5/5\n",
            "20/20 [==============================] - 3s 163ms/step - loss: 0.2361 - accuracy: 0.9366 - val_loss: 1.3800 - val_accuracy: 0.4853\n",
            "8.745715839498763e-06 1.5180197904087993\n",
            "Epoch 1/5\n",
            "10/10 [==============================] - 4s 351ms/step - loss: 9.0697 - accuracy: 0.3474 - val_loss: 8.8681 - val_accuracy: 0.4338\n",
            "Epoch 2/5\n",
            "10/10 [==============================] - 3s 333ms/step - loss: 8.9651 - accuracy: 0.4644 - val_loss: 8.8557 - val_accuracy: 0.3971\n",
            "Epoch 3/5\n",
            "10/10 [==============================] - 3s 331ms/step - loss: 8.8927 - accuracy: 0.5393 - val_loss: 8.8457 - val_accuracy: 0.4118\n",
            "Epoch 4/5\n",
            "10/10 [==============================] - 3s 325ms/step - loss: 8.8376 - accuracy: 0.5822 - val_loss: 8.8368 - val_accuracy: 0.4632\n",
            "Epoch 5/5\n",
            "10/10 [==============================] - 3s 334ms/step - loss: 8.7992 - accuracy: 0.6260 - val_loss: 8.8284 - val_accuracy: 0.4890\n",
            "7.1459422024076965e-06 10.592772415272593\n",
            "Epoch 1/5\n",
            "10/10 [==============================] - 4s 357ms/step - loss: 65.7685 - accuracy: 0.6101 - val_loss: 65.6259 - val_accuracy: 0.5625\n",
            "Epoch 2/5\n",
            "10/10 [==============================] - 3s 331ms/step - loss: 65.5342 - accuracy: 0.6395 - val_loss: 65.4269 - val_accuracy: 0.5993\n",
            "Epoch 3/5\n",
            "10/10 [==============================] - 3s 336ms/step - loss: 65.3092 - accuracy: 0.6645 - val_loss: 65.2284 - val_accuracy: 0.6213\n",
            "Epoch 4/5\n",
            "10/10 [==============================] - 3s 333ms/step - loss: 65.0900 - accuracy: 0.6764 - val_loss: 65.0303 - val_accuracy: 0.6360\n",
            "Epoch 5/5\n",
            "10/10 [==============================] - 3s 333ms/step - loss: 64.8740 - accuracy: 0.6984 - val_loss: 64.8328 - val_accuracy: 0.6507\n",
            "0.023927653333723854 374.53718967121154\n",
            "Epoch 1/5\n",
            "20/20 [==============================] - 3s 173ms/step - loss: inf - accuracy: 0.6972 - val_loss: nan - val_accuracy: 0.4853\n",
            "Epoch 2/5\n",
            "20/20 [==============================] - 3s 163ms/step - loss: nan - accuracy: 0.4959 - val_loss: nan - val_accuracy: 0.4853\n",
            "Epoch 3/5\n",
            "20/20 [==============================] - 3s 163ms/step - loss: nan - accuracy: 0.5016 - val_loss: nan - val_accuracy: 0.4853\n",
            "Epoch 4/5\n",
            "20/20 [==============================] - 3s 166ms/step - loss: nan - accuracy: 0.5016 - val_loss: nan - val_accuracy: 0.4853\n",
            "Epoch 5/5\n",
            "20/20 [==============================] - 3s 165ms/step - loss: nan - accuracy: 0.5016 - val_loss: nan - val_accuracy: 0.4853\n",
            "0.005321723704798202 1.9751364803909701\n",
            "Epoch 1/5\n",
            "10/10 [==============================] - 4s 351ms/step - loss: 13.1248 - accuracy: 0.7651 - val_loss: 9.1357 - val_accuracy: 0.4853\n",
            "Epoch 2/5\n",
            "10/10 [==============================] - 3s 335ms/step - loss: 8.9100 - accuracy: 0.7905 - val_loss: 7.1331 - val_accuracy: 0.6287\n",
            "Epoch 3/5\n",
            "10/10 [==============================] - 3s 334ms/step - loss: 5.7686 - accuracy: 0.8331 - val_loss: 4.3984 - val_accuracy: 0.4853\n",
            "Epoch 4/5\n",
            "10/10 [==============================] - 3s 329ms/step - loss: 3.7772 - accuracy: 0.8736 - val_loss: 3.0042 - val_accuracy: 0.6912\n",
            "Epoch 5/5\n",
            "10/10 [==============================] - 3s 329ms/step - loss: 2.7215 - accuracy: 0.8719 - val_loss: 2.3971 - val_accuracy: 0.4853\n",
            "4.188399464706223e-06 0.7169605755122741\n",
            "Epoch 1/5\n",
            "10/10 [==============================] - 3s 347ms/step - loss: 4.7314 - accuracy: 0.3928 - val_loss: 4.4742 - val_accuracy: 0.5221\n",
            "Epoch 2/5\n",
            "10/10 [==============================] - 3s 327ms/step - loss: 4.6597 - accuracy: 0.4214 - val_loss: 4.4705 - val_accuracy: 0.4816\n",
            "Epoch 3/5\n",
            "10/10 [==============================] - 3s 332ms/step - loss: 4.6037 - accuracy: 0.4505 - val_loss: 4.4672 - val_accuracy: 0.5110\n",
            "Epoch 4/5\n",
            "10/10 [==============================] - 3s 328ms/step - loss: 4.5581 - accuracy: 0.4812 - val_loss: 4.4641 - val_accuracy: 0.5331\n",
            "Epoch 5/5\n",
            "10/10 [==============================] - 3s 331ms/step - loss: 4.5167 - accuracy: 0.5176 - val_loss: 4.4611 - val_accuracy: 0.5662\n",
            "0.00038780215925192287 0.00035367473904520893\n",
            "Epoch 1/5\n",
            "20/20 [==============================] - 3s 167ms/step - loss: 0.4086 - accuracy: 0.8482 - val_loss: 0.6285 - val_accuracy: 0.6507\n",
            "Epoch 2/5\n",
            "20/20 [==============================] - 3s 164ms/step - loss: 0.3225 - accuracy: 0.8801 - val_loss: 0.6081 - val_accuracy: 0.7353\n",
            "Epoch 3/5\n",
            "20/20 [==============================] - 3s 159ms/step - loss: 0.2799 - accuracy: 0.8989 - val_loss: 0.5932 - val_accuracy: 0.8015\n",
            "Epoch 4/5\n",
            "20/20 [==============================] - 3s 160ms/step - loss: 0.2657 - accuracy: 0.9043 - val_loss: 0.5811 - val_accuracy: 0.7721\n",
            "Epoch 5/5\n",
            "20/20 [==============================] - 3s 162ms/step - loss: 0.2448 - accuracy: 0.9092 - val_loss: 0.5599 - val_accuracy: 0.8162\n",
            "0.01657337911431039 5.736227420322919e-06\n",
            "Epoch 1/5\n",
            "77/77 [==============================] - 3s 44ms/step - loss: 1.5825 - accuracy: 0.8727 - val_loss: 3.8926 - val_accuracy: 0.4853\n",
            "Epoch 2/5\n",
            "77/77 [==============================] - 3s 43ms/step - loss: 0.4130 - accuracy: 0.9317 - val_loss: 3.0427 - val_accuracy: 0.4853\n",
            "Epoch 3/5\n",
            "77/77 [==============================] - 3s 43ms/step - loss: 0.1575 - accuracy: 0.9607 - val_loss: 2.5959 - val_accuracy: 0.4926\n",
            "Epoch 4/5\n",
            "77/77 [==============================] - 3s 43ms/step - loss: 0.1253 - accuracy: 0.9677 - val_loss: 1.4472 - val_accuracy: 0.5919\n",
            "Epoch 5/5\n",
            "77/77 [==============================] - 3s 43ms/step - loss: 0.0732 - accuracy: 0.9750 - val_loss: 0.7549 - val_accuracy: 0.8088\n",
            "1.1853029601481622e-05 5.26163790181853e-05\n",
            "Epoch 1/5\n",
            "39/39 [==============================] - 3s 86ms/step - loss: 0.4662 - accuracy: 0.8191 - val_loss: 0.6412 - val_accuracy: 0.6434\n",
            "Epoch 2/5\n",
            "39/39 [==============================] - 3s 80ms/step - loss: 0.4372 - accuracy: 0.8412 - val_loss: 0.6237 - val_accuracy: 0.7096\n",
            "Epoch 3/5\n",
            "39/39 [==============================] - 3s 81ms/step - loss: 0.4027 - accuracy: 0.8519 - val_loss: 0.6038 - val_accuracy: 0.7206\n",
            "Epoch 4/5\n",
            "39/39 [==============================] - 3s 79ms/step - loss: 0.3891 - accuracy: 0.8547 - val_loss: 0.5821 - val_accuracy: 0.7500\n",
            "Epoch 5/5\n",
            "39/39 [==============================] - 3s 80ms/step - loss: 0.3797 - accuracy: 0.8629 - val_loss: 0.5590 - val_accuracy: 0.7684\n",
            "0.00255900705275109 4.607125028049136\n",
            "Epoch 1/5\n",
            "77/77 [==============================] - 3s 42ms/step - loss: 7.6371 - accuracy: 0.8568 - val_loss: 1.3904 - val_accuracy: 0.4853\n",
            "Epoch 2/5\n",
            "77/77 [==============================] - 3s 41ms/step - loss: 0.4812 - accuracy: 0.9255 - val_loss: 0.8955 - val_accuracy: 0.4853\n",
            "Epoch 3/5\n",
            "77/77 [==============================] - 3s 42ms/step - loss: 0.2780 - accuracy: 0.9296 - val_loss: 0.8669 - val_accuracy: 0.4853\n",
            "Epoch 4/5\n",
            "77/77 [==============================] - 3s 41ms/step - loss: 0.2398 - accuracy: 0.9403 - val_loss: 0.7977 - val_accuracy: 0.4853\n",
            "Epoch 5/5\n",
            "77/77 [==============================] - 3s 42ms/step - loss: 0.2300 - accuracy: 0.9435 - val_loss: 0.7935 - val_accuracy: 0.4853\n",
            "0.00016871599129114035 5.345199750409819e-06\n",
            "Epoch 1/5\n",
            "39/39 [==============================] - 3s 84ms/step - loss: 0.4077 - accuracy: 0.8310 - val_loss: 0.6211 - val_accuracy: 0.7316\n",
            "Epoch 2/5\n",
            "39/39 [==============================] - 3s 79ms/step - loss: 0.3108 - accuracy: 0.8822 - val_loss: 0.5927 - val_accuracy: 0.7537\n",
            "Epoch 3/5\n",
            "39/39 [==============================] - 3s 79ms/step - loss: 0.2893 - accuracy: 0.8903 - val_loss: 0.5631 - val_accuracy: 0.7904\n",
            "Epoch 4/5\n",
            "39/39 [==============================] - 3s 80ms/step - loss: 0.2667 - accuracy: 0.8969 - val_loss: 0.5336 - val_accuracy: 0.8309\n",
            "Epoch 5/5\n",
            "39/39 [==============================] - 3s 79ms/step - loss: 0.2640 - accuracy: 0.8981 - val_loss: 0.5077 - val_accuracy: 0.8419\n",
            "0.050829572638792044 2.1616747954145927e-06\n",
            "Epoch 1/5\n",
            "20/20 [==============================] - 3s 165ms/step - loss: 17.5682 - accuracy: 0.7692 - val_loss: 2.0082 - val_accuracy: 0.7316\n",
            "Epoch 2/5\n",
            "20/20 [==============================] - 3s 157ms/step - loss: 0.3645 - accuracy: 0.9497 - val_loss: 2.8597 - val_accuracy: 0.6140\n",
            "Epoch 3/5\n",
            "20/20 [==============================] - 3s 156ms/step - loss: 0.2243 - accuracy: 0.9546 - val_loss: 2.5720 - val_accuracy: 0.6397\n",
            "Epoch 4/5\n",
            "20/20 [==============================] - 3s 157ms/step - loss: 0.1453 - accuracy: 0.9628 - val_loss: 2.3806 - val_accuracy: 0.6140\n",
            "Epoch 5/5\n",
            "20/20 [==============================] - 3s 159ms/step - loss: 0.1036 - accuracy: 0.9709 - val_loss: 2.5854 - val_accuracy: 0.6103\n",
            "0.0032144908739455145 27.715989396674516\n",
            "Epoch 1/5\n",
            "10/10 [==============================] - 3s 343ms/step - loss: 44.2283 - accuracy: 0.7635 - val_loss: 3.4883 - val_accuracy: 0.8603\n",
            "Epoch 2/5\n",
            "10/10 [==============================] - 3s 326ms/step - loss: 1.2931 - accuracy: 0.8621 - val_loss: 0.8039 - val_accuracy: 0.4853\n",
            "Epoch 3/5\n",
            "10/10 [==============================] - 3s 330ms/step - loss: 0.5267 - accuracy: 0.8580 - val_loss: 0.7516 - val_accuracy: 0.4853\n",
            "Epoch 4/5\n",
            "10/10 [==============================] - 3s 327ms/step - loss: 0.4949 - accuracy: 0.8466 - val_loss: 0.7643 - val_accuracy: 0.4853\n",
            "Epoch 5/5\n",
            "10/10 [==============================] - 3s 329ms/step - loss: 0.5294 - accuracy: 0.8327 - val_loss: 0.7632 - val_accuracy: 0.4853\n",
            "1.1875212214823089e-06 0.6014909880543327\n",
            "Epoch 1/5\n",
            "20/20 [==============================] - 3s 170ms/step - loss: 4.0315 - accuracy: 0.6485 - val_loss: 4.1093 - val_accuracy: 0.6176\n",
            "Epoch 2/5\n",
            "20/20 [==============================] - 3s 158ms/step - loss: 4.0193 - accuracy: 0.6649 - val_loss: 4.1071 - val_accuracy: 0.6324\n",
            "Epoch 3/5\n",
            "20/20 [==============================] - 3s 161ms/step - loss: 4.0079 - accuracy: 0.6837 - val_loss: 4.1048 - val_accuracy: 0.6397\n",
            "Epoch 4/5\n",
            "20/20 [==============================] - 3s 160ms/step - loss: 3.9973 - accuracy: 0.7091 - val_loss: 4.1022 - val_accuracy: 0.6581\n",
            "Epoch 5/5\n",
            "20/20 [==============================] - 3s 160ms/step - loss: 3.9900 - accuracy: 0.7230 - val_loss: 4.0994 - val_accuracy: 0.6618\n",
            "0.0014440992373723793 5.6691454075298595e-06\n",
            "Epoch 1/5\n",
            "20/20 [==============================] - 3s 167ms/step - loss: 0.7330 - accuracy: 0.7758 - val_loss: 0.6510 - val_accuracy: 0.5919\n",
            "Epoch 2/5\n",
            "20/20 [==============================] - 3s 160ms/step - loss: 0.3587 - accuracy: 0.8662 - val_loss: 0.5975 - val_accuracy: 0.6875\n",
            "Epoch 3/5\n",
            "20/20 [==============================] - 3s 158ms/step - loss: 0.3263 - accuracy: 0.8858 - val_loss: 0.5878 - val_accuracy: 0.6985\n",
            "Epoch 4/5\n",
            "20/20 [==============================] - 3s 156ms/step - loss: 0.2452 - accuracy: 0.9022 - val_loss: 0.5565 - val_accuracy: 0.7574\n",
            "Epoch 5/5\n",
            "20/20 [==============================] - 3s 156ms/step - loss: 0.2649 - accuracy: 0.9047 - val_loss: 0.5248 - val_accuracy: 0.8419\n",
            "9.960560637072135e-05 0.030888640633422376\n",
            "Epoch 1/5\n",
            "39/39 [==============================] - 3s 84ms/step - loss: 0.6269 - accuracy: 0.8069 - val_loss: 0.8080 - val_accuracy: 0.6912\n",
            "Epoch 2/5\n",
            "39/39 [==============================] - 3s 79ms/step - loss: 0.5305 - accuracy: 0.8736 - val_loss: 0.7837 - val_accuracy: 0.7316\n",
            "Epoch 3/5\n",
            "39/39 [==============================] - 3s 80ms/step - loss: 0.5012 - accuracy: 0.8818 - val_loss: 0.7594 - val_accuracy: 0.7574\n",
            "Epoch 4/5\n",
            "39/39 [==============================] - 3s 81ms/step - loss: 0.4743 - accuracy: 0.8846 - val_loss: 0.7329 - val_accuracy: 0.7721\n",
            "Epoch 5/5\n",
            "39/39 [==============================] - 3s 82ms/step - loss: 0.4646 - accuracy: 0.8858 - val_loss: 0.7055 - val_accuracy: 0.7904\n",
            "0.00028721455097596997 0.1377098757581447\n",
            "Epoch 1/5\n",
            "77/77 [==============================] - 3s 44ms/step - loss: 1.1317 - accuracy: 0.8437 - val_loss: 1.3451 - val_accuracy: 0.8860\n",
            "Epoch 2/5\n",
            "77/77 [==============================] - 3s 42ms/step - loss: 1.0352 - accuracy: 0.9010 - val_loss: 1.2840 - val_accuracy: 0.9007\n",
            "Epoch 3/5\n",
            "77/77 [==============================] - 3s 41ms/step - loss: 0.9967 - accuracy: 0.9047 - val_loss: 1.2070 - val_accuracy: 0.8971\n",
            "Epoch 4/5\n",
            "77/77 [==============================] - 3s 41ms/step - loss: 0.9628 - accuracy: 0.9165 - val_loss: 1.1169 - val_accuracy: 0.9081\n",
            "Epoch 5/5\n",
            "77/77 [==============================] - 3s 42ms/step - loss: 0.9406 - accuracy: 0.9223 - val_loss: 1.0512 - val_accuracy: 0.9081\n",
            "0.0013000951901745808 10.934324536715577\n",
            "Epoch 1/5\n",
            "20/20 [==============================] - 3s 167ms/step - loss: 38.0726 - accuracy: 0.8543 - val_loss: 20.1270 - val_accuracy: 0.7978\n",
            "Epoch 2/5\n",
            "20/20 [==============================] - 3s 160ms/step - loss: 12.1780 - accuracy: 0.8985 - val_loss: 6.8135 - val_accuracy: 0.8934\n",
            "Epoch 3/5\n",
            "20/20 [==============================] - 3s 161ms/step - loss: 4.0613 - accuracy: 0.9038 - val_loss: 2.6328 - val_accuracy: 0.6066\n",
            "Epoch 4/5\n",
            "20/20 [==============================] - 3s 160ms/step - loss: 1.5172 - accuracy: 0.9071 - val_loss: 1.3315 - val_accuracy: 0.4853\n",
            "Epoch 5/5\n",
            "20/20 [==============================] - 3s 161ms/step - loss: 0.7411 - accuracy: 0.9075 - val_loss: 0.9320 - val_accuracy: 0.4853\n",
            "1.8413941356076007e-05 2.738394082689487e-06\n",
            "Epoch 1/5\n",
            "77/77 [==============================] - 3s 43ms/step - loss: 0.5506 - accuracy: 0.7402 - val_loss: 0.6542 - val_accuracy: 0.7096\n",
            "Epoch 2/5\n",
            "77/77 [==============================] - 3s 41ms/step - loss: 0.4075 - accuracy: 0.8343 - val_loss: 0.6149 - val_accuracy: 0.7537\n",
            "Epoch 3/5\n",
            "77/77 [==============================] - 3s 41ms/step - loss: 0.3773 - accuracy: 0.8531 - val_loss: 0.5699 - val_accuracy: 0.7647\n",
            "Epoch 4/5\n",
            "77/77 [==============================] - 3s 41ms/step - loss: 0.3538 - accuracy: 0.8629 - val_loss: 0.5161 - val_accuracy: 0.7978\n",
            "Epoch 5/5\n",
            "77/77 [==============================] - 3s 41ms/step - loss: 0.3386 - accuracy: 0.8748 - val_loss: 0.4578 - val_accuracy: 0.8199\n",
            "4.280984199987233e-05 3.3085913750575852e-06\n",
            "Epoch 1/5\n",
            "39/39 [==============================] - 3s 84ms/step - loss: 0.4960 - accuracy: 0.7950 - val_loss: 0.6475 - val_accuracy: 0.7721\n",
            "Epoch 2/5\n",
            "39/39 [==============================] - 3s 80ms/step - loss: 0.4017 - accuracy: 0.8363 - val_loss: 0.6240 - val_accuracy: 0.7941\n",
            "Epoch 3/5\n",
            "39/39 [==============================] - 3s 79ms/step - loss: 0.3642 - accuracy: 0.8511 - val_loss: 0.6006 - val_accuracy: 0.8125\n",
            "Epoch 4/5\n",
            "39/39 [==============================] - 3s 79ms/step - loss: 0.3436 - accuracy: 0.8609 - val_loss: 0.5756 - val_accuracy: 0.8309\n",
            "Epoch 5/5\n",
            "39/39 [==============================] - 3s 81ms/step - loss: 0.3239 - accuracy: 0.8674 - val_loss: 0.5477 - val_accuracy: 0.8382\n",
            "0.013882392850185101 3.6105028044598275e-06\n",
            "Epoch 1/5\n",
            "20/20 [==============================] - 3s 167ms/step - loss: 3.4478 - accuracy: 0.7647 - val_loss: 2.3929 - val_accuracy: 0.4853\n",
            "Epoch 2/5\n",
            "20/20 [==============================] - 3s 161ms/step - loss: 0.3317 - accuracy: 0.9264 - val_loss: 2.1695 - val_accuracy: 0.4853\n",
            "Epoch 3/5\n",
            "20/20 [==============================] - 3s 163ms/step - loss: 0.0864 - accuracy: 0.9714 - val_loss: 2.6195 - val_accuracy: 0.4853\n",
            "Epoch 4/5\n",
            "20/20 [==============================] - 3s 161ms/step - loss: 0.1308 - accuracy: 0.9632 - val_loss: 1.9692 - val_accuracy: 0.4853\n",
            "Epoch 5/5\n",
            "20/20 [==============================] - 3s 160ms/step - loss: 0.0691 - accuracy: 0.9759 - val_loss: 1.7728 - val_accuracy: 0.4853\n",
            "0.006829601955017991 0.06705793522482192\n",
            "Epoch 1/5\n",
            "10/10 [==============================] - 4s 351ms/step - loss: 3.3433 - accuracy: 0.7328 - val_loss: 0.8494 - val_accuracy: 0.7684\n",
            "Epoch 2/5\n",
            "10/10 [==============================] - 3s 329ms/step - loss: 1.3308 - accuracy: 0.8437 - val_loss: 1.5150 - val_accuracy: 0.6581\n",
            "Epoch 3/5\n",
            "10/10 [==============================] - 3s 330ms/step - loss: 0.8610 - accuracy: 0.9153 - val_loss: 1.0702 - val_accuracy: 0.4853\n",
            "Epoch 4/5\n",
            "10/10 [==============================] - 3s 332ms/step - loss: 0.8536 - accuracy: 0.9141 - val_loss: 1.0126 - val_accuracy: 0.4853\n",
            "Epoch 5/5\n",
            "10/10 [==============================] - 3s 328ms/step - loss: 1.0259 - accuracy: 0.8912 - val_loss: 1.2152 - val_accuracy: 0.4853\n",
            "0.05888741853902915 0.025526698928737747\n",
            "Epoch 1/5\n",
            "39/39 [==============================] - 3s 84ms/step - loss: 5.0075 - accuracy: 0.7987 - val_loss: 1.0064 - val_accuracy: 0.8603\n",
            "Epoch 2/5\n",
            "39/39 [==============================] - 3s 80ms/step - loss: 0.7959 - accuracy: 0.9399 - val_loss: 1.0578 - val_accuracy: 0.7169\n",
            "Epoch 3/5\n",
            "39/39 [==============================] - 3s 80ms/step - loss: 0.6004 - accuracy: 0.9525 - val_loss: 1.1865 - val_accuracy: 0.5699\n",
            "Epoch 4/5\n",
            "39/39 [==============================] - 3s 83ms/step - loss: 0.5096 - accuracy: 0.9489 - val_loss: 1.0480 - val_accuracy: 0.6728\n",
            "Epoch 5/5\n",
            "39/39 [==============================] - 3s 81ms/step - loss: 0.4188 - accuracy: 0.9583 - val_loss: 0.8218 - val_accuracy: 0.6985\n",
            "6.7946613729626e-05 32.88907503818188\n",
            "Epoch 1/5\n",
            "10/10 [==============================] - 3s 345ms/step - loss: 189.7001 - accuracy: 0.4836 - val_loss: 180.4215 - val_accuracy: 0.5919\n",
            "Epoch 2/5\n",
            "10/10 [==============================] - 3s 324ms/step - loss: 173.2592 - accuracy: 0.7647 - val_loss: 165.0062 - val_accuracy: 0.6287\n",
            "Epoch 3/5\n",
            "10/10 [==============================] - 3s 329ms/step - loss: 158.3469 - accuracy: 0.8106 - val_loss: 150.9165 - val_accuracy: 0.6875\n",
            "Epoch 4/5\n",
            "10/10 [==============================] - 3s 328ms/step - loss: 144.8079 - accuracy: 0.8392 - val_loss: 138.0358 - val_accuracy: 0.7059\n",
            "Epoch 5/5\n",
            "10/10 [==============================] - 3s 330ms/step - loss: 132.4069 - accuracy: 0.8519 - val_loss: 126.2597 - val_accuracy: 0.7316\n",
            "2.344102917513824e-06 0.00012746792542730337\n",
            "Epoch 1/5\n",
            "39/39 [==============================] - 3s 85ms/step - loss: 0.5671 - accuracy: 0.7340 - val_loss: 0.6764 - val_accuracy: 0.6728\n",
            "Epoch 2/5\n",
            "39/39 [==============================] - 3s 80ms/step - loss: 0.5453 - accuracy: 0.7541 - val_loss: 0.6697 - val_accuracy: 0.7059\n",
            "Epoch 3/5\n",
            "39/39 [==============================] - 3s 81ms/step - loss: 0.5257 - accuracy: 0.7717 - val_loss: 0.6616 - val_accuracy: 0.7426\n",
            "Epoch 4/5\n",
            "39/39 [==============================] - 3s 81ms/step - loss: 0.5130 - accuracy: 0.7795 - val_loss: 0.6517 - val_accuracy: 0.7684\n",
            "Epoch 5/5\n",
            "39/39 [==============================] - 3s 80ms/step - loss: 0.4967 - accuracy: 0.7930 - val_loss: 0.6398 - val_accuracy: 0.7794\n",
            "0.07904307521707958 0.06250329109248681\n",
            "Epoch 1/5\n",
            "10/10 [==============================] - 3s 348ms/step - loss: 45.5375 - accuracy: 0.6092 - val_loss: 27.1295 - val_accuracy: 0.7206\n",
            "Epoch 2/5\n",
            "10/10 [==============================] - 3s 326ms/step - loss: 71.2757 - accuracy: 0.7185 - val_loss: 115.9371 - val_accuracy: 0.5147\n",
            "Epoch 3/5\n",
            "10/10 [==============================] - 3s 332ms/step - loss: 55.3359 - accuracy: 0.7594 - val_loss: 299.5073 - val_accuracy: 0.4853\n",
            "Epoch 4/5\n",
            "10/10 [==============================] - 3s 324ms/step - loss: 113.6523 - accuracy: 0.7234 - val_loss: 41.0760 - val_accuracy: 0.7243\n",
            "Epoch 5/5\n",
            "10/10 [==============================] - 3s 327ms/step - loss: 13.9733 - accuracy: 0.9362 - val_loss: 14.2370 - val_accuracy: 0.8713\n",
            "2.5695509943870968e-05 0.017505769963252982\n",
            "Epoch 1/5\n",
            "10/10 [==============================] - 3s 347ms/step - loss: 1.1841 - accuracy: 0.3953 - val_loss: 0.7896 - val_accuracy: 0.5809\n",
            "Epoch 2/5\n",
            "10/10 [==============================] - 3s 325ms/step - loss: 0.8227 - accuracy: 0.5606 - val_loss: 0.7788 - val_accuracy: 0.5699\n",
            "Epoch 3/5\n",
            "10/10 [==============================] - 3s 330ms/step - loss: 0.7077 - accuracy: 0.7083 - val_loss: 0.7715 - val_accuracy: 0.5882\n",
            "Epoch 4/5\n",
            "10/10 [==============================] - 3s 326ms/step - loss: 0.6541 - accuracy: 0.7525 - val_loss: 0.7645 - val_accuracy: 0.6140\n",
            "Epoch 5/5\n",
            "10/10 [==============================] - 3s 330ms/step - loss: 0.6150 - accuracy: 0.7811 - val_loss: 0.7580 - val_accuracy: 0.6434\n",
            "0.008453620095363818 588.8883487243611\n",
            "Epoch 1/5\n",
            "77/77 [==============================] - 3s 43ms/step - loss: nan - accuracy: 0.5593 - val_loss: nan - val_accuracy: 0.4853\n",
            "Epoch 2/5\n",
            "77/77 [==============================] - 3s 41ms/step - loss: nan - accuracy: 0.5016 - val_loss: nan - val_accuracy: 0.4853\n",
            "Epoch 3/5\n",
            "77/77 [==============================] - 3s 41ms/step - loss: nan - accuracy: 0.5016 - val_loss: nan - val_accuracy: 0.4853\n",
            "Epoch 4/5\n",
            "77/77 [==============================] - 3s 42ms/step - loss: nan - accuracy: 0.5016 - val_loss: nan - val_accuracy: 0.4853\n",
            "Epoch 5/5\n",
            "77/77 [==============================] - 3s 41ms/step - loss: nan - accuracy: 0.5016 - val_loss: nan - val_accuracy: 0.4853\n",
            "0.00028658504278399597 166.52061202146453\n",
            "Epoch 1/5\n",
            "39/39 [==============================] - 3s 88ms/step - loss: 118.5875 - accuracy: 0.7827 - val_loss: 1.0651 - val_accuracy: 0.4890\n",
            "Epoch 2/5\n",
            "39/39 [==============================] - 3s 84ms/step - loss: 0.7086 - accuracy: 0.7770 - val_loss: 0.7164 - val_accuracy: 0.4853\n",
            "Epoch 3/5\n",
            "39/39 [==============================] - 3s 83ms/step - loss: 0.6591 - accuracy: 0.7574 - val_loss: 0.7182 - val_accuracy: 0.4853\n",
            "Epoch 4/5\n",
            "39/39 [==============================] - 3s 84ms/step - loss: 0.6526 - accuracy: 0.7664 - val_loss: 0.7169 - val_accuracy: 0.4853\n",
            "Epoch 5/5\n",
            "39/39 [==============================] - 3s 84ms/step - loss: 0.6479 - accuracy: 0.7700 - val_loss: 0.7177 - val_accuracy: 0.4706\n",
            "0.0007096037416540657 5.296876603856177\n",
            "Epoch 1/5\n",
            "39/39 [==============================] - 3s 87ms/step - loss: 23.1801 - accuracy: 0.8384 - val_loss: 17.2444 - val_accuracy: 0.7868\n",
            "Epoch 2/5\n",
            "39/39 [==============================] - 3s 84ms/step - loss: 12.9455 - accuracy: 0.8961 - val_loss: 9.8478 - val_accuracy: 0.9118\n",
            "Epoch 3/5\n",
            "39/39 [==============================] - 3s 83ms/step - loss: 7.2868 - accuracy: 0.9071 - val_loss: 5.7474 - val_accuracy: 0.8566\n",
            "Epoch 4/5\n",
            "39/39 [==============================] - 3s 81ms/step - loss: 4.1556 - accuracy: 0.9120 - val_loss: 3.4748 - val_accuracy: 0.7537\n",
            "Epoch 5/5\n",
            "39/39 [==============================] - 3s 82ms/step - loss: 2.4180 - accuracy: 0.9231 - val_loss: 2.2160 - val_accuracy: 0.6360\n",
            "0.00097289107886169 54.89299941866797\n",
            "Epoch 1/5\n",
            "20/20 [==============================] - 4s 176ms/step - loss: 84.6973 - accuracy: 0.8376 - val_loss: 4.4924 - val_accuracy: 0.8676\n",
            "Epoch 2/5\n",
            "20/20 [==============================] - 3s 162ms/step - loss: 1.4573 - accuracy: 0.8408 - val_loss: 0.7864 - val_accuracy: 0.4853\n",
            "Epoch 3/5\n",
            "20/20 [==============================] - 3s 161ms/step - loss: 0.5887 - accuracy: 0.8061 - val_loss: 0.7415 - val_accuracy: 0.4853\n",
            "Epoch 4/5\n",
            "20/20 [==============================] - 3s 166ms/step - loss: 0.5696 - accuracy: 0.8097 - val_loss: 0.7427 - val_accuracy: 0.4853\n",
            "Epoch 5/5\n",
            "20/20 [==============================] - 3s 158ms/step - loss: 0.5538 - accuracy: 0.8130 - val_loss: 0.7397 - val_accuracy: 0.4853\n",
            "0.0006410493644758124 7.458358819698086\n",
            "Epoch 1/5\n",
            "77/77 [==============================] - 3s 44ms/step - loss: 24.8675 - accuracy: 0.8691 - val_loss: 11.2219 - val_accuracy: 0.8934\n",
            "Epoch 2/5\n",
            "77/77 [==============================] - 3s 41ms/step - loss: 5.8562 - accuracy: 0.9071 - val_loss: 3.0605 - val_accuracy: 0.6838\n",
            "Epoch 3/5\n",
            "77/77 [==============================] - 3s 41ms/step - loss: 1.5622 - accuracy: 0.9153 - val_loss: 1.2307 - val_accuracy: 0.4890\n",
            "Epoch 4/5\n",
            "77/77 [==============================] - 3s 42ms/step - loss: 0.6055 - accuracy: 0.9214 - val_loss: 0.8061 - val_accuracy: 0.4963\n",
            "Epoch 5/5\n",
            "77/77 [==============================] - 3s 42ms/step - loss: 0.3963 - accuracy: 0.9173 - val_loss: 0.6807 - val_accuracy: 0.5699\n",
            "0.001374017005161002 134.90049223414292\n",
            "Epoch 1/5\n",
            "39/39 [==============================] - 3s 89ms/step - loss: 34.0145 - accuracy: 0.7700 - val_loss: 0.7209 - val_accuracy: 0.4779\n",
            "Epoch 2/5\n",
            "39/39 [==============================] - 3s 82ms/step - loss: 0.6228 - accuracy: 0.7811 - val_loss: 0.7302 - val_accuracy: 0.4816\n",
            "Epoch 3/5\n",
            "39/39 [==============================] - 3s 83ms/step - loss: 0.6012 - accuracy: 0.7950 - val_loss: 0.7342 - val_accuracy: 0.4853\n",
            "Epoch 4/5\n",
            "39/39 [==============================] - 3s 81ms/step - loss: 0.6013 - accuracy: 0.8028 - val_loss: 0.7399 - val_accuracy: 0.4853\n",
            "Epoch 5/5\n",
            "39/39 [==============================] - 3s 82ms/step - loss: 0.5760 - accuracy: 0.8077 - val_loss: 0.7384 - val_accuracy: 0.4853\n",
            "4.225206698784032e-06 528.0221589533883\n",
            "Epoch 1/5\n",
            "77/77 [==============================] - 3s 44ms/step - loss: 2266.1644 - accuracy: 0.7467 - val_loss: 1567.9628 - val_accuracy: 0.7059\n",
            "Epoch 2/5\n",
            "77/77 [==============================] - 3s 42ms/step - loss: 1138.3882 - accuracy: 0.7660 - val_loss: 787.8219 - val_accuracy: 0.7353\n",
            "Epoch 3/5\n",
            "77/77 [==============================] - 3s 42ms/step - loss: 572.0222 - accuracy: 0.7754 - val_loss: 396.0096 - val_accuracy: 0.7169\n",
            "Epoch 4/5\n",
            "77/77 [==============================] - 3s 41ms/step - loss: 287.5582 - accuracy: 0.7864 - val_loss: 199.2283 - val_accuracy: 0.7169\n",
            "Epoch 5/5\n",
            "77/77 [==============================] - 3s 42ms/step - loss: 144.7045 - accuracy: 0.7893 - val_loss: 100.3987 - val_accuracy: 0.7096\n",
            "0.051136831218785886 21.951560433069865\n",
            "Epoch 1/5\n",
            "10/10 [==============================] - 3s 348ms/step - loss: 6262.8556 - accuracy: 0.5847 - val_loss: 35909.0546 - val_accuracy: 0.5147\n",
            "Epoch 2/5\n",
            "10/10 [==============================] - 3s 332ms/step - loss: 507605.5626 - accuracy: 0.7291 - val_loss: 2860115.6176 - val_accuracy: 0.5772\n",
            "Epoch 3/5\n",
            "10/10 [==============================] - 3s 325ms/step - loss: 41144238.7760 - accuracy: 0.8699 - val_loss: 229197376.0000 - val_accuracy: 0.8787\n",
            "Epoch 4/5\n",
            "10/10 [==============================] - 3s 330ms/step - loss: 3302187693.6432 - accuracy: 0.9300 - val_loss: 18367975424.0000 - val_accuracy: 0.6801\n",
            "Epoch 5/5\n",
            "10/10 [==============================] - 3s 324ms/step - loss: 261251027518.6954 - accuracy: 0.9366 - val_loss: 1472017727488.0000 - val_accuracy: 0.8860\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jUjXo7SJtQ6H",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "65a798f6-9bc9-45e7-adca-76e2c892fdf1"
      },
      "source": [
        "for i in range(100):\n",
        "  print('learning rate = ',lr_list[i],'regularization = ',reg_list[i],'batch_size = ',batch_list[i],'val_loss = ',val_loss[i],'val_acc = ',val_acc[i])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "learning rate =  0.012798672924442965 regularization =  251.30363192139828 batch_size =  64 val_loss =  nan val_acc =  0.4852941036224365\n",
            "learning rate =  3.428307644115509e-05 regularization =  410.2940382386389 batch_size =  128 val_loss =  7.9016853500815 val_acc =  0.4889705777168274\n",
            "learning rate =  3.0817904838686134e-06 regularization =  3.5341050430845207 batch_size =  64 val_loss =  19.952437681310318 val_acc =  0.7389705777168274\n",
            "learning rate =  1.4222595991242691e-05 regularization =  1.3918168849355136e-06 batch_size =  256 val_loss =  0.6764251914094476 val_acc =  0.6691176295280457\n",
            "learning rate =  3.389698051278209e-05 regularization =  1.2407006825967597e-05 batch_size =  128 val_loss =  0.6311467395109289 val_acc =  0.6948529481887817\n",
            "learning rate =  1.0694653664966817e-06 regularization =  3.5972682400648063e-06 batch_size =  256 val_loss =  0.7147830023485071 val_acc =  0.36764705181121826\n",
            "learning rate =  0.0005120307128431775 regularization =  0.0024691289850358364 batch_size =  32 val_loss =  0.3461246192455292 val_acc =  0.845588207244873\n",
            "learning rate =  0.018966500912006568 regularization =  0.0022430487954523694 batch_size =  256 val_loss =  2.6218036343069637 val_acc =  0.4852941036224365\n",
            "learning rate =  0.00035622389030313034 regularization =  25.818586722983433 batch_size =  64 val_loss =  0.85002842019586 val_acc =  0.4852941036224365\n",
            "learning rate =  1.13482214152269e-06 regularization =  22.16136821064544 batch_size =  256 val_loss =  107.12826313691981 val_acc =  0.35661765933036804\n",
            "learning rate =  0.0013104383049520783 regularization =  0.0011165682675835212 batch_size =  32 val_loss =  0.3006809564197765 val_acc =  0.8897058963775635\n",
            "learning rate =  8.767958137811632e-06 regularization =  1.312458442073099 batch_size =  64 val_loss =  8.581514330471263 val_acc =  0.7977941036224365\n",
            "learning rate =  0.00211618932692069 regularization =  0.1593022347104578 batch_size =  256 val_loss =  1.7689607231055988 val_acc =  0.6654411554336548\n",
            "learning rate =  0.007313643563067671 regularization =  0.022494382078465793 batch_size =  64 val_loss =  1.6067098659627579 val_acc =  0.4852941036224365\n",
            "learning rate =  0.019604171936828275 regularization =  0.621092628194791 batch_size =  128 val_loss =  1.426919235902674 val_acc =  0.4852941036224365\n",
            "learning rate =  2.8931145447055283e-05 regularization =  4.027932173228817e-06 batch_size =  64 val_loss =  0.5686323642730713 val_acc =  0.7683823704719543\n",
            "learning rate =  0.04296915632618949 regularization =  0.030093282245371514 batch_size =  128 val_loss =  6.5634944859673 val_acc =  0.4852941036224365\n",
            "learning rate =  2.378291822173271e-06 regularization =  1.0646129564835294e-05 batch_size =  64 val_loss =  0.6250453871839187 val_acc =  0.7022058963775635\n",
            "learning rate =  0.0930000965411884 regularization =  2.043574259535878e-05 batch_size =  128 val_loss =  nan val_acc =  0.4852941036224365\n",
            "learning rate =  3.0974543805016765e-06 regularization =  6.586205047429152e-05 batch_size =  128 val_loss =  0.6563003063201904 val_acc =  0.6985294222831726\n",
            "learning rate =  0.005485005234409067 regularization =  9.308738140429488 batch_size =  128 val_loss =  0.888450843446395 val_acc =  0.4852941036224365\n",
            "learning rate =  6.582710311298122e-06 regularization =  0.05156704155478945 batch_size =  64 val_loss =  0.913974362261155 val_acc =  0.6911764740943909\n",
            "learning rate =  0.016371773087835363 regularization =  1.4954942796728862e-06 batch_size =  32 val_loss =  0.7216062335407033 val_acc =  0.7352941036224365\n",
            "learning rate =  1.2740525569913064e-06 regularization =  2.839057521588019 batch_size =  128 val_loss =  17.265191358678482 val_acc =  0.5110294222831726\n",
            "learning rate =  0.0001495897199189532 regularization =  60.11280495977497 batch_size =  32 val_loss =  0.7071574856253231 val_acc =  0.7316176295280457\n",
            "learning rate =  9.894961927238196e-06 regularization =  228.53709173492962 batch_size =  256 val_loss =  809.0452019186581 val_acc =  0.658088207244873\n",
            "learning rate =  0.005110405188945623 regularization =  2.4667584414228006e-05 batch_size =  32 val_loss =  0.9175643605344436 val_acc =  0.6727941036224365\n",
            "learning rate =  0.06823922138161892 regularization =  2.4239193449679347e-06 batch_size =  32 val_loss =  0.17364965532632434 val_acc =  0.9411764740943909\n",
            "learning rate =  0.00011733791451882245 regularization =  0.00017655850336334038 batch_size =  128 val_loss =  0.60112924786175 val_acc =  0.8272058963775635\n",
            "learning rate =  0.0002604286215611087 regularization =  2.238355066513844e-06 batch_size =  32 val_loss =  0.3595990573658663 val_acc =  0.9154411554336548\n",
            "learning rate =  0.0002894740302128779 regularization =  5.508377485813129 batch_size =  32 val_loss =  3.406427355373607 val_acc =  0.908088207244873\n",
            "learning rate =  0.00040978733995319873 regularization =  2.659877315009591e-05 batch_size =  32 val_loss =  0.3110570416730993 val_acc =  0.9191176295280457\n",
            "learning rate =  1.2521742859511585e-05 regularization =  4.956919008438613e-06 batch_size =  128 val_loss =  0.6300999662455391 val_acc =  0.7022058963775635\n",
            "learning rate =  2.8172440023004288e-05 regularization =  1.5992646979340682e-06 batch_size =  64 val_loss =  0.5805136315962848 val_acc =  0.7757353186607361\n",
            "learning rate =  0.00024515069498787603 regularization =  0.0025872650145720164 batch_size =  64 val_loss =  0.5068776186774758 val_acc =  0.8382353186607361\n",
            "learning rate =  0.002630738369447698 regularization =  172.40064361926085 batch_size =  32 val_loss =  0.72293621301651 val_acc =  0.7610294222831726\n",
            "learning rate =  7.100252505517118e-05 regularization =  94.04344062603474 batch_size =  256 val_loss =  134.519603953642 val_acc =  0.7536764740943909\n",
            "learning rate =  1.363161689868161e-06 regularization =  717.544347837351 batch_size =  128 val_loss =  2600.805290670956 val_acc =  0.529411792755127\n",
            "learning rate =  2.910688143660302e-05 regularization =  2.8834319279847327e-05 batch_size =  128 val_loss =  0.6244429420022404 val_acc =  0.7132353186607361\n",
            "learning rate =  0.007027531360049336 regularization =  0.46854777043683987 batch_size =  64 val_loss =  1.6945370786330278 val_acc =  0.4852941036224365\n",
            "learning rate =  0.01155231625043052 regularization =  2.806630544396993e-05 batch_size =  32 val_loss =  0.7752154346774606 val_acc =  0.7757353186607361\n",
            "learning rate =  2.3774850786738736e-06 regularization =  0.00017330572732585908 batch_size =  256 val_loss =  0.6852889166158789 val_acc =  0.5772058963775635\n",
            "learning rate =  0.020772522865707917 regularization =  26.236974149051044 batch_size =  32 val_loss =  0.784482009270612 val_acc =  0.5147058963775635\n",
            "learning rate =  0.00572866786747167 regularization =  0.020056464520598085 batch_size =  64 val_loss =  1.5797059886595781 val_acc =  0.4852941036224365\n",
            "learning rate =  0.005264670464255857 regularization =  0.015045890053886787 batch_size =  128 val_loss =  0.8372260542476878 val_acc =  0.4852941036224365\n",
            "learning rate =  2.142971812438172e-05 regularization =  0.013431414667355111 batch_size =  64 val_loss =  0.6565094590187073 val_acc =  0.7610294222831726\n",
            "learning rate =  3.2517971280312804e-05 regularization =  0.1180072845391285 batch_size =  64 val_loss =  1.3426514302983004 val_acc =  0.7867646813392639\n",
            "learning rate =  1.7126570301167812e-06 regularization =  0.0003481727396889091 batch_size =  256 val_loss =  0.6879077168071971 val_acc =  0.5808823704719543\n",
            "learning rate =  2.600146943243313e-06 regularization =  0.8863467066476497 batch_size =  256 val_loss =  5.475626524756937 val_acc =  0.4595588147640228\n",
            "learning rate =  0.0003783158212840578 regularization =  0.11694890110892844 batch_size =  32 val_loss =  0.9728768993826473 val_acc =  0.875\n",
            "learning rate =  9.411150572514867e-05 regularization =  0.0032625147078927425 batch_size =  256 val_loss =  0.6640408004031462 val_acc =  0.716911792755127\n",
            "learning rate =  0.027468630327551185 regularization =  4.893753444216898e-06 batch_size =  256 val_loss =  3.3970161395914413 val_acc =  0.4852941036224365\n",
            "learning rate =  0.01110072476347387 regularization =  0.00010058017638717954 batch_size =  64 val_loss =  2.018080508007723 val_acc =  0.49264705181121826\n",
            "learning rate =  5.917461412803899e-06 regularization =  0.08210873395074687 batch_size =  128 val_loss =  1.1058798607657938 val_acc =  0.6654411554336548\n",
            "learning rate =  0.00012347469001959478 regularization =  5.595131674507475e-06 batch_size =  32 val_loss =  0.4023418969967786 val_acc =  0.845588207244873\n",
            "learning rate =  8.962789020065325e-05 regularization =  41.767430283738236 batch_size =  128 val_loss =  53.98852180032169 val_acc =  0.8235294222831726\n",
            "learning rate =  0.014633691605617808 regularization =  2.207896829299548e-06 batch_size =  64 val_loss =  2.284608041538912 val_acc =  0.4852941036224365\n",
            "learning rate =  5.595007551352353e-06 regularization =  4.455944813949866 batch_size =  256 val_loss =  27.990068996653836 val_acc =  0.654411792755127\n",
            "learning rate =  9.81237059589691e-06 regularization =  1.6035411926555865e-05 batch_size =  128 val_loss =  0.656858412658467 val_acc =  0.7316176295280457\n",
            "learning rate =  0.0006079648543150342 regularization =  2.643413371549512 batch_size =  256 val_loss =  10.732676113353056 val_acc =  0.7022058963775635\n",
            "learning rate =  0.00362320796093486 regularization =  0.00010734151861140347 batch_size =  64 val_loss =  0.8391789899152868 val_acc =  0.5073529481887817\n",
            "learning rate =  0.019040875950140507 regularization =  1.8844671133085595 batch_size =  64 val_loss =  1.2101324165568632 val_acc =  0.4852941036224365\n",
            "learning rate =  0.0009571754774389329 regularization =  841.8797661170224 batch_size =  256 val_loss =  0.7017451700042275 val_acc =  0.4632352888584137\n",
            "learning rate =  0.009706363203111319 regularization =  0.00083609545580548 batch_size =  32 val_loss =  0.6754114566480413 val_acc =  0.7904411554336548\n",
            "learning rate =  0.07918716686966588 regularization =  6.929587544534332e-06 batch_size =  32 val_loss =  0.4925687361289473 val_acc =  0.9411764740943909\n",
            "learning rate =  0.018299997863033258 regularization =  0.9739901250136133 batch_size =  128 val_loss =  1.3800261581645292 val_acc =  0.4852941036224365\n",
            "learning rate =  8.745715839498763e-06 regularization =  1.5180197904087993 batch_size =  256 val_loss =  8.828419124378877 val_acc =  0.4889705777168274\n",
            "learning rate =  7.1459422024076965e-06 regularization =  10.592772415272593 batch_size =  256 val_loss =  64.83284849279067 val_acc =  0.6507353186607361\n",
            "learning rate =  0.023927653333723854 regularization =  374.53718967121154 batch_size =  128 val_loss =  nan val_acc =  0.4852941036224365\n",
            "learning rate =  0.005321723704798202 regularization =  1.9751364803909701 batch_size =  256 val_loss =  2.397123841678395 val_acc =  0.4852941036224365\n",
            "learning rate =  4.188399464706223e-06 regularization =  0.7169605755122741 batch_size =  256 val_loss =  4.461141053368063 val_acc =  0.5661764740943909\n",
            "learning rate =  0.00038780215925192287 regularization =  0.00035367473904520893 batch_size =  128 val_loss =  0.5598713334868936 val_acc =  0.8161764740943909\n",
            "learning rate =  0.01657337911431039 regularization =  5.736227420322919e-06 batch_size =  32 val_loss =  0.7548939638278064 val_acc =  0.8088235259056091\n",
            "learning rate =  1.1853029601481622e-05 regularization =  5.26163790181853e-05 batch_size =  64 val_loss =  0.5589581727981567 val_acc =  0.7683823704719543\n",
            "learning rate =  0.00255900705275109 regularization =  4.607125028049136 batch_size =  32 val_loss =  0.7934947715086096 val_acc =  0.4852941036224365\n",
            "learning rate =  0.00016871599129114035 regularization =  5.345199750409819e-06 batch_size =  64 val_loss =  0.507715502206017 val_acc =  0.841911792755127\n",
            "learning rate =  0.050829572638792044 regularization =  2.1616747954145927e-06 batch_size =  128 val_loss =  2.58542379210977 val_acc =  0.6102941036224365\n",
            "learning rate =  0.0032144908739455145 regularization =  27.715989396674516 batch_size =  256 val_loss =  0.7632386999971726 val_acc =  0.4852941036224365\n",
            "learning rate =  1.1875212214823089e-06 regularization =  0.6014909880543327 batch_size =  128 val_loss =  4.099448512582218 val_acc =  0.6617646813392639\n",
            "learning rate =  0.0014440992373723793 regularization =  5.6691454075298595e-06 batch_size =  128 val_loss =  0.5248469114303589 val_acc =  0.841911792755127\n",
            "learning rate =  9.960560637072135e-05 regularization =  0.030888640633422376 batch_size =  64 val_loss =  0.7054967459510354 val_acc =  0.7904411554336548\n",
            "learning rate =  0.00028721455097596997 regularization =  0.1377098757581447 batch_size =  32 val_loss =  1.0512164761038387 val_acc =  0.908088207244873\n",
            "learning rate =  0.0013000951901745808 regularization =  10.934324536715577 batch_size =  128 val_loss =  0.9319691167158239 val_acc =  0.4852941036224365\n",
            "learning rate =  1.8413941356076007e-05 regularization =  2.738394082689487e-06 batch_size =  32 val_loss =  0.45778487710391774 val_acc =  0.8198529481887817\n",
            "learning rate =  4.280984199987233e-05 regularization =  3.3085913750575852e-06 batch_size =  64 val_loss =  0.5476628331577077 val_acc =  0.8382353186607361\n",
            "learning rate =  0.013882392850185101 regularization =  3.6105028044598275e-06 batch_size =  128 val_loss =  1.7727629647535437 val_acc =  0.4852941036224365\n",
            "learning rate =  0.006829601955017991 regularization =  0.06705793522482192 batch_size =  256 val_loss =  1.2151519691242891 val_acc =  0.4852941036224365\n",
            "learning rate =  0.05888741853902915 regularization =  0.025526698928737747 batch_size =  64 val_loss =  0.8218090183594647 val_acc =  0.6985294222831726\n",
            "learning rate =  6.7946613729626e-05 regularization =  32.88907503818188 batch_size =  256 val_loss =  126.25972433651195 val_acc =  0.7316176295280457\n",
            "learning rate =  2.344102917513824e-06 regularization =  0.00012746792542730337 batch_size =  64 val_loss =  0.6398284610579995 val_acc =  0.779411792755127\n",
            "learning rate =  0.07904307521707958 regularization =  0.06250329109248681 batch_size =  256 val_loss =  14.237040968502269 val_acc =  0.8713235259056091\n",
            "learning rate =  2.5695509943870968e-05 regularization =  0.017505769963252982 batch_size =  256 val_loss =  0.7580120458322412 val_acc =  0.6433823704719543\n",
            "learning rate =  0.008453620095363818 regularization =  588.8883487243611 batch_size =  32 val_loss =  nan val_acc =  0.4852941036224365\n",
            "learning rate =  0.00028658504278399597 regularization =  166.52061202146453 batch_size =  64 val_loss =  0.7177352765027214 val_acc =  0.47058823704719543\n",
            "learning rate =  0.0007096037416540657 regularization =  5.296876603856177 batch_size =  64 val_loss =  2.215983334709616 val_acc =  0.6360294222831726\n",
            "learning rate =  0.00097289107886169 regularization =  54.89299941866797 batch_size =  128 val_loss =  0.7396667985355153 val_acc =  0.4852941036224365\n",
            "learning rate =  0.0006410493644758124 regularization =  7.458358819698086 batch_size =  32 val_loss =  0.6806742584004122 val_acc =  0.5698529481887817\n",
            "learning rate =  0.001374017005161002 regularization =  134.90049223414292 batch_size =  64 val_loss =  0.7384093403816223 val_acc =  0.4852941036224365\n",
            "learning rate =  4.225206698784032e-06 regularization =  528.0221589533883 batch_size =  32 val_loss =  100.39867311365464 val_acc =  0.7095588445663452\n",
            "learning rate =  0.051136831218785886 regularization =  21.951560433069865 batch_size =  256 val_loss =  1472017727488.0 val_acc =  0.8860294222831726\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nxtvZsZjD03w",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "1eea2e6b-7b9f-4c50-8cb6-8861217da6f3"
      },
      "source": [
        "#finetune\n",
        "\n",
        "max_count = 100\n",
        "epochs = 5\n",
        "lr_list,reg_list,batch_list,val_loss,val_acc = [],[],[],[],[]\n",
        "for count in range(max_count):\n",
        "  reg = 10**np.random.uniform(-6,-2)\n",
        "  lr = 10**np.random.uniform(-3,-6)\n",
        "  batch_size_list = [32,64,128]\n",
        "  batch_size = random.choice(batch_size_list)\n",
        "  print(lr,reg)\n",
        "  weight_decay = reg\n",
        "  model = Sequential()\n",
        "  model.add(Dense(50,input_shape=x_train.shape[1:],kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "  model.add(Activation('relu'))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(Flatten())\n",
        "\n",
        "  model.add(Dense(num_classes))\n",
        "  model.add(Activation('softmax'))\n",
        "\n",
        "  opt = keras.optimizers.SGD(learning_rate=lr)\n",
        "\n",
        "  model.compile(loss='categorical_crossentropy',\n",
        "                optimizer=opt,\n",
        "                metrics=['accuracy'])\n",
        "  History = model.fit_generator(datagen.flow(x_train, y_train,\n",
        "                                  batch_size=batch_size),\n",
        "                    epochs=epochs,\n",
        "                    validation_data=(x_test, y_test),\n",
        "                    workers=4)\n",
        "  lr_list.append(lr)\n",
        "  reg_list.append(reg)\n",
        "  batch_list.append(batch_size)\n",
        "\n",
        "  val_loss.append(History.history['val_loss'][-1])\n",
        "  val_acc.append(History.history['val_accuracy'][-1])\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.8898016998022086e-06 3.992904866907762e-06\n",
            "Epoch 1/5\n",
            "39/39 [==============================] - 3s 84ms/step - loss: 0.8169 - accuracy: 0.4955 - val_loss: 0.6898 - val_accuracy: 0.5000\n",
            "Epoch 2/5\n",
            "39/39 [==============================] - 3s 79ms/step - loss: 0.7252 - accuracy: 0.5417 - val_loss: 0.6792 - val_accuracy: 0.5588\n",
            "Epoch 3/5\n",
            "39/39 [==============================] - 3s 81ms/step - loss: 0.6599 - accuracy: 0.5974 - val_loss: 0.6691 - val_accuracy: 0.6140\n",
            "Epoch 4/5\n",
            "39/39 [==============================] - 3s 83ms/step - loss: 0.6089 - accuracy: 0.6686 - val_loss: 0.6580 - val_accuracy: 0.6618\n",
            "Epoch 5/5\n",
            "39/39 [==============================] - 3s 80ms/step - loss: 0.5806 - accuracy: 0.7189 - val_loss: 0.6456 - val_accuracy: 0.7096\n",
            "5.2903970618390755e-06 0.00021102421646554262\n",
            "Epoch 1/5\n",
            "77/77 [==============================] - 3s 44ms/step - loss: 0.7412 - accuracy: 0.5585 - val_loss: 0.6776 - val_accuracy: 0.5956\n",
            "Epoch 2/5\n",
            "77/77 [==============================] - 3s 42ms/step - loss: 0.5699 - accuracy: 0.7275 - val_loss: 0.6499 - val_accuracy: 0.6912\n",
            "Epoch 3/5\n",
            "77/77 [==============================] - 3s 42ms/step - loss: 0.4983 - accuracy: 0.7836 - val_loss: 0.6161 - val_accuracy: 0.7353\n",
            "Epoch 4/5\n",
            "77/77 [==============================] - 3s 42ms/step - loss: 0.4619 - accuracy: 0.8040 - val_loss: 0.5754 - val_accuracy: 0.7721\n",
            "Epoch 5/5\n",
            "77/77 [==============================] - 3s 41ms/step - loss: 0.4405 - accuracy: 0.8290 - val_loss: 0.5315 - val_accuracy: 0.7941\n",
            "0.0005591712028316839 0.00019822251481817741\n",
            "Epoch 1/5\n",
            "20/20 [==============================] - 4s 176ms/step - loss: 0.4218 - accuracy: 0.8220 - val_loss: 0.6376 - val_accuracy: 0.6691\n",
            "Epoch 2/5\n",
            "20/20 [==============================] - 3s 161ms/step - loss: 0.3256 - accuracy: 0.8695 - val_loss: 0.6235 - val_accuracy: 0.7316\n",
            "Epoch 3/5\n",
            "20/20 [==============================] - 3s 159ms/step - loss: 0.3009 - accuracy: 0.8822 - val_loss: 0.6106 - val_accuracy: 0.7243\n",
            "Epoch 4/5\n",
            "20/20 [==============================] - 3s 162ms/step - loss: 0.2801 - accuracy: 0.8912 - val_loss: 0.5978 - val_accuracy: 0.7647\n",
            "Epoch 5/5\n",
            "20/20 [==============================] - 3s 160ms/step - loss: 0.2631 - accuracy: 0.8965 - val_loss: 0.5801 - val_accuracy: 0.7757\n",
            "1.0250306811939426e-05 3.2936980699089447e-06\n",
            "Epoch 1/5\n",
            "20/20 [==============================] - 3s 170ms/step - loss: 0.8753 - accuracy: 0.4374 - val_loss: 0.6952 - val_accuracy: 0.5551\n",
            "Epoch 2/5\n",
            "20/20 [==============================] - 3s 164ms/step - loss: 0.7508 - accuracy: 0.5487 - val_loss: 0.6872 - val_accuracy: 0.6103\n",
            "Epoch 3/5\n",
            "20/20 [==============================] - 3s 166ms/step - loss: 0.6594 - accuracy: 0.6334 - val_loss: 0.6790 - val_accuracy: 0.6544\n",
            "Epoch 4/5\n",
            "20/20 [==============================] - 3s 160ms/step - loss: 0.6057 - accuracy: 0.7021 - val_loss: 0.6707 - val_accuracy: 0.6765\n",
            "Epoch 5/5\n",
            "20/20 [==============================] - 3s 163ms/step - loss: 0.5608 - accuracy: 0.7426 - val_loss: 0.6623 - val_accuracy: 0.7022\n",
            "0.0005945193822826684 0.0021324263714795973\n",
            "Epoch 1/5\n",
            "39/39 [==============================] - 3s 87ms/step - loss: 0.3642 - accuracy: 0.8552 - val_loss: 0.6354 - val_accuracy: 0.7206\n",
            "Epoch 2/5\n",
            "39/39 [==============================] - 3s 85ms/step - loss: 0.2844 - accuracy: 0.8887 - val_loss: 0.6056 - val_accuracy: 0.8566\n",
            "Epoch 3/5\n",
            "39/39 [==============================] - 3s 83ms/step - loss: 0.2587 - accuracy: 0.9059 - val_loss: 0.5787 - val_accuracy: 0.9044\n",
            "Epoch 4/5\n",
            "39/39 [==============================] - 3s 83ms/step - loss: 0.2449 - accuracy: 0.9083 - val_loss: 0.5418 - val_accuracy: 0.8529\n",
            "Epoch 5/5\n",
            "39/39 [==============================] - 3s 84ms/step - loss: 0.2303 - accuracy: 0.9218 - val_loss: 0.5159 - val_accuracy: 0.8787\n",
            "9.117349644590024e-06 0.0014741861344500142\n",
            "Epoch 1/5\n",
            "39/39 [==============================] - 3s 86ms/step - loss: 0.6555 - accuracy: 0.6727 - val_loss: 0.6875 - val_accuracy: 0.6103\n",
            "Epoch 2/5\n",
            "39/39 [==============================] - 3s 83ms/step - loss: 0.5535 - accuracy: 0.7676 - val_loss: 0.6737 - val_accuracy: 0.6654\n",
            "Epoch 3/5\n",
            "39/39 [==============================] - 3s 84ms/step - loss: 0.4955 - accuracy: 0.7966 - val_loss: 0.6588 - val_accuracy: 0.7022\n",
            "Epoch 4/5\n",
            "39/39 [==============================] - 3s 86ms/step - loss: 0.4679 - accuracy: 0.8208 - val_loss: 0.6425 - val_accuracy: 0.7206\n",
            "Epoch 5/5\n",
            "39/39 [==============================] - 3s 82ms/step - loss: 0.4512 - accuracy: 0.8380 - val_loss: 0.6247 - val_accuracy: 0.7390\n",
            "7.099113978525928e-05 1.163591207319732e-05\n",
            "Epoch 1/5\n",
            "20/20 [==============================] - 3s 170ms/step - loss: 0.5141 - accuracy: 0.7692 - val_loss: 0.6588 - val_accuracy: 0.5956\n",
            "Epoch 2/5\n",
            "20/20 [==============================] - 3s 159ms/step - loss: 0.4260 - accuracy: 0.8294 - val_loss: 0.6440 - val_accuracy: 0.6507\n",
            "Epoch 3/5\n",
            "20/20 [==============================] - 3s 159ms/step - loss: 0.3835 - accuracy: 0.8490 - val_loss: 0.6314 - val_accuracy: 0.6875\n",
            "Epoch 4/5\n",
            "20/20 [==============================] - 3s 158ms/step - loss: 0.3679 - accuracy: 0.8609 - val_loss: 0.6191 - val_accuracy: 0.7169\n",
            "Epoch 5/5\n",
            "20/20 [==============================] - 3s 159ms/step - loss: 0.3593 - accuracy: 0.8605 - val_loss: 0.6074 - val_accuracy: 0.7463\n",
            "2.043818937958818e-06 1.7393678768865614e-06\n",
            "Epoch 1/5\n",
            "77/77 [==============================] - 3s 44ms/step - loss: 0.9113 - accuracy: 0.4014 - val_loss: 0.7059 - val_accuracy: 0.4081\n",
            "Epoch 2/5\n",
            "77/77 [==============================] - 3s 43ms/step - loss: 0.7726 - accuracy: 0.5376 - val_loss: 0.6973 - val_accuracy: 0.5221\n",
            "Epoch 3/5\n",
            "77/77 [==============================] - 3s 42ms/step - loss: 0.6752 - accuracy: 0.6363 - val_loss: 0.6837 - val_accuracy: 0.6029\n",
            "Epoch 4/5\n",
            "77/77 [==============================] - 3s 42ms/step - loss: 0.6152 - accuracy: 0.6911 - val_loss: 0.6637 - val_accuracy: 0.6434\n",
            "Epoch 5/5\n",
            "77/77 [==============================] - 3s 42ms/step - loss: 0.5685 - accuracy: 0.7255 - val_loss: 0.6361 - val_accuracy: 0.6765\n",
            "2.218086001210683e-06 7.303696810720234e-05\n",
            "Epoch 1/5\n",
            "20/20 [==============================] - 3s 173ms/step - loss: 0.8254 - accuracy: 0.4628 - val_loss: 0.6974 - val_accuracy: 0.4485\n",
            "Epoch 2/5\n",
            "20/20 [==============================] - 3s 159ms/step - loss: 0.7874 - accuracy: 0.4980 - val_loss: 0.6952 - val_accuracy: 0.4559\n",
            "Epoch 3/5\n",
            "20/20 [==============================] - 3s 160ms/step - loss: 0.7621 - accuracy: 0.5389 - val_loss: 0.6927 - val_accuracy: 0.4926\n",
            "Epoch 4/5\n",
            "20/20 [==============================] - 3s 156ms/step - loss: 0.7324 - accuracy: 0.5716 - val_loss: 0.6899 - val_accuracy: 0.5257\n",
            "Epoch 5/5\n",
            "20/20 [==============================] - 3s 162ms/step - loss: 0.7100 - accuracy: 0.6056 - val_loss: 0.6867 - val_accuracy: 0.5404\n",
            "6.872938386606285e-05 5.715722292671221e-06\n",
            "Epoch 1/5\n",
            "20/20 [==============================] - 3s 171ms/step - loss: 0.5013 - accuracy: 0.7745 - val_loss: 0.6659 - val_accuracy: 0.6691\n",
            "Epoch 2/5\n",
            "20/20 [==============================] - 3s 162ms/step - loss: 0.4231 - accuracy: 0.8269 - val_loss: 0.6519 - val_accuracy: 0.7574\n",
            "Epoch 3/5\n",
            "20/20 [==============================] - 3s 161ms/step - loss: 0.4071 - accuracy: 0.8457 - val_loss: 0.6410 - val_accuracy: 0.7537\n",
            "Epoch 4/5\n",
            "20/20 [==============================] - 3s 163ms/step - loss: 0.3784 - accuracy: 0.8556 - val_loss: 0.6291 - val_accuracy: 0.7941\n",
            "Epoch 5/5\n",
            "20/20 [==============================] - 3s 158ms/step - loss: 0.3651 - accuracy: 0.8662 - val_loss: 0.6186 - val_accuracy: 0.8051\n",
            "0.0005392361986559832 4.690984478614728e-05\n",
            "Epoch 1/5\n",
            "77/77 [==============================] - 3s 43ms/step - loss: 0.3917 - accuracy: 0.8425 - val_loss: 0.5851 - val_accuracy: 0.7243\n",
            "Epoch 2/5\n",
            "77/77 [==============================] - 3s 42ms/step - loss: 0.2855 - accuracy: 0.8838 - val_loss: 0.5055 - val_accuracy: 0.7831\n",
            "Epoch 3/5\n",
            "77/77 [==============================] - 3s 40ms/step - loss: 0.2376 - accuracy: 0.9010 - val_loss: 0.4715 - val_accuracy: 0.8162\n",
            "Epoch 4/5\n",
            "77/77 [==============================] - 3s 42ms/step - loss: 0.1936 - accuracy: 0.9300 - val_loss: 0.3701 - val_accuracy: 0.8529\n",
            "Epoch 5/5\n",
            "77/77 [==============================] - 3s 41ms/step - loss: 0.1778 - accuracy: 0.9358 - val_loss: 0.3012 - val_accuracy: 0.9118\n",
            "4.865500379965463e-06 0.005132605062355772\n",
            "Epoch 1/5\n",
            "77/77 [==============================] - 3s 43ms/step - loss: 0.6984 - accuracy: 0.6330 - val_loss: 0.7154 - val_accuracy: 0.6029\n",
            "Epoch 2/5\n",
            "77/77 [==============================] - 3s 41ms/step - loss: 0.6017 - accuracy: 0.7169 - val_loss: 0.6989 - val_accuracy: 0.6801\n",
            "Epoch 3/5\n",
            "77/77 [==============================] - 3s 40ms/step - loss: 0.5404 - accuracy: 0.7627 - val_loss: 0.6738 - val_accuracy: 0.7059\n",
            "Epoch 4/5\n",
            "77/77 [==============================] - 3s 41ms/step - loss: 0.5042 - accuracy: 0.7983 - val_loss: 0.6382 - val_accuracy: 0.7684\n",
            "Epoch 5/5\n",
            "77/77 [==============================] - 3s 41ms/step - loss: 0.4745 - accuracy: 0.8126 - val_loss: 0.5916 - val_accuracy: 0.8015\n",
            "0.00037154228289365304 0.0001489882237442482\n",
            "Epoch 1/5\n",
            "39/39 [==============================] - 3s 82ms/step - loss: 0.3633 - accuracy: 0.8494 - val_loss: 0.6070 - val_accuracy: 0.6691\n",
            "Epoch 2/5\n",
            "39/39 [==============================] - 3s 77ms/step - loss: 0.2910 - accuracy: 0.8944 - val_loss: 0.5767 - val_accuracy: 0.7096\n",
            "Epoch 3/5\n",
            "39/39 [==============================] - 3s 79ms/step - loss: 0.2616 - accuracy: 0.9043 - val_loss: 0.5435 - val_accuracy: 0.7537\n",
            "Epoch 4/5\n",
            "39/39 [==============================] - 3s 77ms/step - loss: 0.2471 - accuracy: 0.9108 - val_loss: 0.5030 - val_accuracy: 0.8051\n",
            "Epoch 5/5\n",
            "39/39 [==============================] - 3s 77ms/step - loss: 0.2439 - accuracy: 0.9120 - val_loss: 0.4732 - val_accuracy: 0.8088\n",
            "0.00023064186770426138 0.0004171602956692113\n",
            "Epoch 1/5\n",
            "20/20 [==============================] - 3s 165ms/step - loss: 0.4779 - accuracy: 0.8085 - val_loss: 0.6500 - val_accuracy: 0.6360\n",
            "Epoch 2/5\n",
            "20/20 [==============================] - 3s 155ms/step - loss: 0.3601 - accuracy: 0.8748 - val_loss: 0.6349 - val_accuracy: 0.7132\n",
            "Epoch 3/5\n",
            "20/20 [==============================] - 3s 155ms/step - loss: 0.3413 - accuracy: 0.8826 - val_loss: 0.6232 - val_accuracy: 0.6949\n",
            "Epoch 4/5\n",
            "20/20 [==============================] - 3s 155ms/step - loss: 0.3136 - accuracy: 0.8883 - val_loss: 0.6116 - val_accuracy: 0.7316\n",
            "Epoch 5/5\n",
            "20/20 [==============================] - 3s 158ms/step - loss: 0.3125 - accuracy: 0.8920 - val_loss: 0.6002 - val_accuracy: 0.7353\n",
            "8.579807634560692e-06 0.006314580863531755\n",
            "Epoch 1/5\n",
            "77/77 [==============================] - 3s 44ms/step - loss: 0.7269 - accuracy: 0.5900 - val_loss: 0.7061 - val_accuracy: 0.7096\n",
            "Epoch 2/5\n",
            "77/77 [==============================] - 3s 40ms/step - loss: 0.5489 - accuracy: 0.7774 - val_loss: 0.6714 - val_accuracy: 0.7831\n",
            "Epoch 3/5\n",
            "77/77 [==============================] - 3s 41ms/step - loss: 0.4908 - accuracy: 0.8069 - val_loss: 0.6285 - val_accuracy: 0.8272\n",
            "Epoch 4/5\n",
            "77/77 [==============================] - 3s 41ms/step - loss: 0.4554 - accuracy: 0.8273 - val_loss: 0.5764 - val_accuracy: 0.8456\n",
            "Epoch 5/5\n",
            "77/77 [==============================] - 3s 41ms/step - loss: 0.4367 - accuracy: 0.8376 - val_loss: 0.5194 - val_accuracy: 0.8603\n",
            "6.900677677118593e-06 0.00017045346751647862\n",
            "Epoch 1/5\n",
            "77/77 [==============================] - 3s 43ms/step - loss: 0.6750 - accuracy: 0.6289 - val_loss: 0.6615 - val_accuracy: 0.6838\n",
            "Epoch 2/5\n",
            "77/77 [==============================] - 3s 41ms/step - loss: 0.5575 - accuracy: 0.7594 - val_loss: 0.6331 - val_accuracy: 0.7206\n",
            "Epoch 3/5\n",
            "77/77 [==============================] - 3s 41ms/step - loss: 0.5099 - accuracy: 0.7979 - val_loss: 0.5976 - val_accuracy: 0.7684\n",
            "Epoch 4/5\n",
            "77/77 [==============================] - 3s 41ms/step - loss: 0.4835 - accuracy: 0.8089 - val_loss: 0.5561 - val_accuracy: 0.7794\n",
            "Epoch 5/5\n",
            "77/77 [==============================] - 3s 40ms/step - loss: 0.4610 - accuracy: 0.8261 - val_loss: 0.5124 - val_accuracy: 0.8015\n",
            "0.00018968131442836583 2.8844031523885113e-05\n",
            "Epoch 1/5\n",
            "77/77 [==============================] - 3s 43ms/step - loss: 0.3937 - accuracy: 0.8421 - val_loss: 0.6059 - val_accuracy: 0.7463\n",
            "Epoch 2/5\n",
            "77/77 [==============================] - 3s 40ms/step - loss: 0.3016 - accuracy: 0.8838 - val_loss: 0.5613 - val_accuracy: 0.7684\n",
            "Epoch 3/5\n",
            "77/77 [==============================] - 3s 40ms/step - loss: 0.2784 - accuracy: 0.8977 - val_loss: 0.5019 - val_accuracy: 0.8051\n",
            "Epoch 4/5\n",
            "77/77 [==============================] - 3s 40ms/step - loss: 0.2576 - accuracy: 0.9030 - val_loss: 0.4402 - val_accuracy: 0.8382\n",
            "Epoch 5/5\n",
            "77/77 [==============================] - 3s 40ms/step - loss: 0.2441 - accuracy: 0.9079 - val_loss: 0.3718 - val_accuracy: 0.8456\n",
            "0.00018455900617092235 4.237142420529752e-06\n",
            "Epoch 1/5\n",
            "20/20 [==============================] - 3s 162ms/step - loss: 0.4664 - accuracy: 0.7938 - val_loss: 0.6520 - val_accuracy: 0.6066\n",
            "Epoch 2/5\n",
            "20/20 [==============================] - 3s 153ms/step - loss: 0.3402 - accuracy: 0.8662 - val_loss: 0.6327 - val_accuracy: 0.6654\n",
            "Epoch 3/5\n",
            "20/20 [==============================] - 3s 152ms/step - loss: 0.3078 - accuracy: 0.8867 - val_loss: 0.6178 - val_accuracy: 0.7243\n",
            "Epoch 4/5\n",
            "20/20 [==============================] - 3s 154ms/step - loss: 0.2867 - accuracy: 0.8981 - val_loss: 0.6041 - val_accuracy: 0.7574\n",
            "Epoch 5/5\n",
            "20/20 [==============================] - 3s 157ms/step - loss: 0.2736 - accuracy: 0.8989 - val_loss: 0.5910 - val_accuracy: 0.7574\n",
            "1.6787148553873555e-05 0.00026548632080084937\n",
            "Epoch 1/5\n",
            "77/77 [==============================] - 3s 43ms/step - loss: 0.7018 - accuracy: 0.6346 - val_loss: 0.6636 - val_accuracy: 0.7390\n",
            "Epoch 2/5\n",
            "77/77 [==============================] - 3s 41ms/step - loss: 0.4287 - accuracy: 0.8367 - val_loss: 0.6200 - val_accuracy: 0.8162\n",
            "Epoch 3/5\n",
            "77/77 [==============================] - 3s 41ms/step - loss: 0.3917 - accuracy: 0.8613 - val_loss: 0.5700 - val_accuracy: 0.8382\n",
            "Epoch 4/5\n",
            "77/77 [==============================] - 3s 40ms/step - loss: 0.3686 - accuracy: 0.8740 - val_loss: 0.5136 - val_accuracy: 0.8566\n",
            "Epoch 5/5\n",
            "77/77 [==============================] - 3s 40ms/step - loss: 0.3544 - accuracy: 0.8781 - val_loss: 0.4571 - val_accuracy: 0.8713\n",
            "4.767148951643905e-05 0.0009721297589022327\n",
            "Epoch 1/5\n",
            "77/77 [==============================] - 3s 43ms/step - loss: 0.4707 - accuracy: 0.7881 - val_loss: 0.6235 - val_accuracy: 0.7169\n",
            "Epoch 2/5\n",
            "77/77 [==============================] - 3s 40ms/step - loss: 0.3567 - accuracy: 0.8650 - val_loss: 0.5723 - val_accuracy: 0.7574\n",
            "Epoch 3/5\n",
            "77/77 [==============================] - 3s 41ms/step - loss: 0.3227 - accuracy: 0.8789 - val_loss: 0.5156 - val_accuracy: 0.7978\n",
            "Epoch 4/5\n",
            "77/77 [==============================] - 3s 40ms/step - loss: 0.3014 - accuracy: 0.8903 - val_loss: 0.4532 - val_accuracy: 0.8456\n",
            "Epoch 5/5\n",
            "77/77 [==============================] - 3s 40ms/step - loss: 0.2866 - accuracy: 0.8908 - val_loss: 0.3958 - val_accuracy: 0.8676\n",
            "1.8353717717706293e-05 8.173386526746356e-06\n",
            "Epoch 1/5\n",
            "77/77 [==============================] - 3s 42ms/step - loss: 0.5095 - accuracy: 0.7750 - val_loss: 0.6546 - val_accuracy: 0.7096\n",
            "Epoch 2/5\n",
            "77/77 [==============================] - 3s 41ms/step - loss: 0.4248 - accuracy: 0.8273 - val_loss: 0.6196 - val_accuracy: 0.7647\n",
            "Epoch 3/5\n",
            "77/77 [==============================] - 3s 41ms/step - loss: 0.3827 - accuracy: 0.8535 - val_loss: 0.5754 - val_accuracy: 0.7941\n",
            "Epoch 4/5\n",
            "77/77 [==============================] - 3s 41ms/step - loss: 0.3680 - accuracy: 0.8646 - val_loss: 0.5226 - val_accuracy: 0.8199\n",
            "Epoch 5/5\n",
            "77/77 [==============================] - 3s 40ms/step - loss: 0.3430 - accuracy: 0.8785 - val_loss: 0.4659 - val_accuracy: 0.8272\n",
            "1.8765448633038126e-05 0.0037533547911942993\n",
            "Epoch 1/5\n",
            "20/20 [==============================] - 3s 164ms/step - loss: 0.7284 - accuracy: 0.6125 - val_loss: 0.7048 - val_accuracy: 0.5441\n",
            "Epoch 2/5\n",
            "20/20 [==============================] - 3s 155ms/step - loss: 0.6096 - accuracy: 0.7324 - val_loss: 0.6931 - val_accuracy: 0.6471\n",
            "Epoch 3/5\n",
            "20/20 [==============================] - 3s 156ms/step - loss: 0.5516 - accuracy: 0.7758 - val_loss: 0.6830 - val_accuracy: 0.6912\n",
            "Epoch 4/5\n",
            "20/20 [==============================] - 3s 156ms/step - loss: 0.5103 - accuracy: 0.7975 - val_loss: 0.6738 - val_accuracy: 0.7132\n",
            "Epoch 5/5\n",
            "20/20 [==============================] - 3s 156ms/step - loss: 0.4855 - accuracy: 0.8089 - val_loss: 0.6636 - val_accuracy: 0.7500\n",
            "1.0179010096499476e-06 5.16589027983451e-05\n",
            "Epoch 1/5\n",
            "39/39 [==============================] - 3s 84ms/step - loss: 0.7473 - accuracy: 0.6461 - val_loss: 0.6807 - val_accuracy: 0.6397\n",
            "Epoch 2/5\n",
            "39/39 [==============================] - 3s 80ms/step - loss: 0.7266 - accuracy: 0.6543 - val_loss: 0.6767 - val_accuracy: 0.6765\n",
            "Epoch 3/5\n",
            "39/39 [==============================] - 3s 78ms/step - loss: 0.7103 - accuracy: 0.6694 - val_loss: 0.6722 - val_accuracy: 0.6985\n",
            "Epoch 4/5\n",
            "39/39 [==============================] - 3s 77ms/step - loss: 0.6906 - accuracy: 0.6755 - val_loss: 0.6668 - val_accuracy: 0.7169\n",
            "Epoch 5/5\n",
            "39/39 [==============================] - 3s 79ms/step - loss: 0.6823 - accuracy: 0.6772 - val_loss: 0.6605 - val_accuracy: 0.7206\n",
            "0.0007418477644251722 0.0004192533366127941\n",
            "Epoch 1/5\n",
            "77/77 [==============================] - 3s 42ms/step - loss: 0.3364 - accuracy: 0.8613 - val_loss: 0.5664 - val_accuracy: 0.8750\n",
            "Epoch 2/5\n",
            "77/77 [==============================] - 3s 40ms/step - loss: 0.2615 - accuracy: 0.8985 - val_loss: 0.5061 - val_accuracy: 0.9118\n",
            "Epoch 3/5\n",
            "77/77 [==============================] - 3s 39ms/step - loss: 0.2228 - accuracy: 0.9145 - val_loss: 0.4371 - val_accuracy: 0.9007\n",
            "Epoch 4/5\n",
            "77/77 [==============================] - 3s 39ms/step - loss: 0.1892 - accuracy: 0.9321 - val_loss: 0.3646 - val_accuracy: 0.8713\n",
            "Epoch 5/5\n",
            "77/77 [==============================] - 3s 39ms/step - loss: 0.1703 - accuracy: 0.9468 - val_loss: 0.2874 - val_accuracy: 0.9449\n",
            "1.5838909515742908e-05 1.2834167177850342e-06\n",
            "Epoch 1/5\n",
            "77/77 [==============================] - 3s 45ms/step - loss: 0.6514 - accuracy: 0.6498 - val_loss: 0.6645 - val_accuracy: 0.6838\n",
            "Epoch 2/5\n",
            "77/77 [==============================] - 3s 42ms/step - loss: 0.4736 - accuracy: 0.7946 - val_loss: 0.6271 - val_accuracy: 0.7426\n",
            "Epoch 3/5\n",
            "77/77 [==============================] - 3s 40ms/step - loss: 0.4221 - accuracy: 0.8355 - val_loss: 0.5836 - val_accuracy: 0.7757\n",
            "Epoch 4/5\n",
            "77/77 [==============================] - 3s 40ms/step - loss: 0.3978 - accuracy: 0.8511 - val_loss: 0.5341 - val_accuracy: 0.7978\n",
            "Epoch 5/5\n",
            "77/77 [==============================] - 3s 39ms/step - loss: 0.3829 - accuracy: 0.8556 - val_loss: 0.4844 - val_accuracy: 0.8125\n",
            "0.00029142619349389605 0.0018442248165944763\n",
            "Epoch 1/5\n",
            "77/77 [==============================] - 3s 41ms/step - loss: 0.3705 - accuracy: 0.8527 - val_loss: 0.6035 - val_accuracy: 0.7132\n",
            "Epoch 2/5\n",
            "77/77 [==============================] - 3s 39ms/step - loss: 0.2946 - accuracy: 0.8920 - val_loss: 0.5499 - val_accuracy: 0.7610\n",
            "Epoch 3/5\n",
            "77/77 [==============================] - 3s 39ms/step - loss: 0.2606 - accuracy: 0.9047 - val_loss: 0.4858 - val_accuracy: 0.7941\n",
            "Epoch 4/5\n",
            "77/77 [==============================] - 3s 39ms/step - loss: 0.2494 - accuracy: 0.9088 - val_loss: 0.4598 - val_accuracy: 0.7794\n",
            "Epoch 5/5\n",
            "77/77 [==============================] - 3s 39ms/step - loss: 0.2267 - accuracy: 0.9206 - val_loss: 0.3874 - val_accuracy: 0.8309\n",
            "6.241537156603125e-06 0.0016386274359413652\n",
            "Epoch 1/5\n",
            "77/77 [==============================] - 3s 41ms/step - loss: 0.6716 - accuracy: 0.6162 - val_loss: 0.6816 - val_accuracy: 0.6507\n",
            "Epoch 2/5\n",
            "77/77 [==============================] - 3s 39ms/step - loss: 0.5362 - accuracy: 0.7709 - val_loss: 0.6569 - val_accuracy: 0.7169\n",
            "Epoch 3/5\n",
            "77/77 [==============================] - 3s 40ms/step - loss: 0.4800 - accuracy: 0.8003 - val_loss: 0.6257 - val_accuracy: 0.7353\n",
            "Epoch 4/5\n",
            "77/77 [==============================] - 3s 39ms/step - loss: 0.4485 - accuracy: 0.8265 - val_loss: 0.5880 - val_accuracy: 0.7390\n",
            "Epoch 5/5\n",
            "77/77 [==============================] - 3s 39ms/step - loss: 0.4271 - accuracy: 0.8310 - val_loss: 0.5460 - val_accuracy: 0.7574\n",
            "1.016355823977235e-06 6.640941781571168e-05\n",
            "Epoch 1/5\n",
            "20/20 [==============================] - 3s 163ms/step - loss: 0.6580 - accuracy: 0.6800 - val_loss: 0.6807 - val_accuracy: 0.5588\n",
            "Epoch 2/5\n",
            "20/20 [==============================] - 3s 153ms/step - loss: 0.6651 - accuracy: 0.6878 - val_loss: 0.6776 - val_accuracy: 0.6140\n",
            "Epoch 3/5\n",
            "20/20 [==============================] - 3s 154ms/step - loss: 0.6526 - accuracy: 0.6903 - val_loss: 0.6747 - val_accuracy: 0.6544\n",
            "Epoch 4/5\n",
            "20/20 [==============================] - 3s 152ms/step - loss: 0.6491 - accuracy: 0.6886 - val_loss: 0.6717 - val_accuracy: 0.6765\n",
            "Epoch 5/5\n",
            "20/20 [==============================] - 3s 156ms/step - loss: 0.6335 - accuracy: 0.6972 - val_loss: 0.6686 - val_accuracy: 0.6728\n",
            "7.760358503821004e-06 0.0004168057705258193\n",
            "Epoch 1/5\n",
            "20/20 [==============================] - 3s 167ms/step - loss: 0.7425 - accuracy: 0.5479 - val_loss: 0.6774 - val_accuracy: 0.5662\n",
            "Epoch 2/5\n",
            "20/20 [==============================] - 3s 158ms/step - loss: 0.6662 - accuracy: 0.6592 - val_loss: 0.6720 - val_accuracy: 0.6250\n",
            "Epoch 3/5\n",
            "20/20 [==============================] - 3s 158ms/step - loss: 0.6364 - accuracy: 0.6944 - val_loss: 0.6658 - val_accuracy: 0.6471\n",
            "Epoch 4/5\n",
            "20/20 [==============================] - 3s 157ms/step - loss: 0.6003 - accuracy: 0.7185 - val_loss: 0.6590 - val_accuracy: 0.6397\n",
            "Epoch 5/5\n",
            "20/20 [==============================] - 3s 153ms/step - loss: 0.5775 - accuracy: 0.7316 - val_loss: 0.6520 - val_accuracy: 0.6507\n",
            "8.317167059446469e-05 5.629076513780854e-06\n",
            "Epoch 1/5\n",
            "39/39 [==============================] - 3s 84ms/step - loss: 0.4525 - accuracy: 0.8085 - val_loss: 0.6403 - val_accuracy: 0.7059\n",
            "Epoch 2/5\n",
            "39/39 [==============================] - 3s 80ms/step - loss: 0.3675 - accuracy: 0.8629 - val_loss: 0.6188 - val_accuracy: 0.7978\n",
            "Epoch 3/5\n",
            "39/39 [==============================] - 3s 80ms/step - loss: 0.3527 - accuracy: 0.8719 - val_loss: 0.5986 - val_accuracy: 0.8382\n",
            "Epoch 4/5\n",
            "39/39 [==============================] - 3s 81ms/step - loss: 0.3316 - accuracy: 0.8781 - val_loss: 0.5784 - val_accuracy: 0.8529\n",
            "Epoch 5/5\n",
            "39/39 [==============================] - 3s 80ms/step - loss: 0.3243 - accuracy: 0.8838 - val_loss: 0.5556 - val_accuracy: 0.8640\n",
            "1.3751784967794424e-06 1.0017813523262212e-06\n",
            "Epoch 1/5\n",
            "39/39 [==============================] - 3s 85ms/step - loss: 0.7455 - accuracy: 0.5683 - val_loss: 0.6880 - val_accuracy: 0.6103\n",
            "Epoch 2/5\n",
            "39/39 [==============================] - 3s 80ms/step - loss: 0.7168 - accuracy: 0.5929 - val_loss: 0.6839 - val_accuracy: 0.6471\n",
            "Epoch 3/5\n",
            "39/39 [==============================] - 3s 80ms/step - loss: 0.6906 - accuracy: 0.6154 - val_loss: 0.6792 - val_accuracy: 0.6618\n",
            "Epoch 4/5\n",
            "39/39 [==============================] - 3s 79ms/step - loss: 0.6698 - accuracy: 0.6367 - val_loss: 0.6736 - val_accuracy: 0.6581\n",
            "Epoch 5/5\n",
            "39/39 [==============================] - 3s 79ms/step - loss: 0.6480 - accuracy: 0.6583 - val_loss: 0.6671 - val_accuracy: 0.6434\n",
            "0.0001743103835235868 0.002260304550024058\n",
            "Epoch 1/5\n",
            "39/39 [==============================] - 3s 85ms/step - loss: 0.4586 - accuracy: 0.7991 - val_loss: 0.6354 - val_accuracy: 0.6765\n",
            "Epoch 2/5\n",
            "39/39 [==============================] - 3s 79ms/step - loss: 0.3362 - accuracy: 0.8842 - val_loss: 0.6060 - val_accuracy: 0.7316\n",
            "Epoch 3/5\n",
            "39/39 [==============================] - 3s 80ms/step - loss: 0.3082 - accuracy: 0.8916 - val_loss: 0.5728 - val_accuracy: 0.7647\n",
            "Epoch 4/5\n",
            "39/39 [==============================] - 3s 79ms/step - loss: 0.2917 - accuracy: 0.8985 - val_loss: 0.5391 - val_accuracy: 0.8051\n",
            "Epoch 5/5\n",
            "39/39 [==============================] - 3s 80ms/step - loss: 0.2738 - accuracy: 0.9079 - val_loss: 0.5083 - val_accuracy: 0.8088\n",
            "6.644192032985693e-05 0.0002464510570087266\n",
            "Epoch 1/5\n",
            "20/20 [==============================] - 3s 164ms/step - loss: 0.5367 - accuracy: 0.7565 - val_loss: 0.6683 - val_accuracy: 0.5772\n",
            "Epoch 2/5\n",
            "20/20 [==============================] - 3s 158ms/step - loss: 0.4416 - accuracy: 0.8286 - val_loss: 0.6557 - val_accuracy: 0.6324\n",
            "Epoch 3/5\n",
            "20/20 [==============================] - 3s 158ms/step - loss: 0.4021 - accuracy: 0.8482 - val_loss: 0.6450 - val_accuracy: 0.6691\n",
            "Epoch 4/5\n",
            "20/20 [==============================] - 3s 161ms/step - loss: 0.3916 - accuracy: 0.8597 - val_loss: 0.6348 - val_accuracy: 0.6838\n",
            "Epoch 5/5\n",
            "20/20 [==============================] - 3s 158ms/step - loss: 0.3665 - accuracy: 0.8670 - val_loss: 0.6260 - val_accuracy: 0.6949\n",
            "1.3347205161341342e-06 1.7134130792760725e-06\n",
            "Epoch 1/5\n",
            "39/39 [==============================] - 3s 89ms/step - loss: 0.7750 - accuracy: 0.4734 - val_loss: 0.6853 - val_accuracy: 0.5882\n",
            "Epoch 2/5\n",
            "39/39 [==============================] - 3s 82ms/step - loss: 0.7225 - accuracy: 0.5708 - val_loss: 0.6792 - val_accuracy: 0.6507\n",
            "Epoch 3/5\n",
            "39/39 [==============================] - 3s 80ms/step - loss: 0.6744 - accuracy: 0.6473 - val_loss: 0.6721 - val_accuracy: 0.6471\n",
            "Epoch 4/5\n",
            "39/39 [==============================] - 3s 82ms/step - loss: 0.6440 - accuracy: 0.6764 - val_loss: 0.6640 - val_accuracy: 0.6581\n",
            "Epoch 5/5\n",
            "39/39 [==============================] - 3s 82ms/step - loss: 0.6201 - accuracy: 0.7021 - val_loss: 0.6544 - val_accuracy: 0.6801\n",
            "5.599046542170087e-05 0.001738843303299553\n",
            "Epoch 1/5\n",
            "77/77 [==============================] - 3s 43ms/step - loss: 0.4874 - accuracy: 0.7856 - val_loss: 0.6247 - val_accuracy: 0.7500\n",
            "Epoch 2/5\n",
            "77/77 [==============================] - 3s 41ms/step - loss: 0.3631 - accuracy: 0.8715 - val_loss: 0.5733 - val_accuracy: 0.7978\n",
            "Epoch 3/5\n",
            "77/77 [==============================] - 3s 41ms/step - loss: 0.3373 - accuracy: 0.8801 - val_loss: 0.5160 - val_accuracy: 0.8346\n",
            "Epoch 4/5\n",
            "77/77 [==============================] - 3s 42ms/step - loss: 0.3187 - accuracy: 0.8867 - val_loss: 0.4538 - val_accuracy: 0.8676\n",
            "Epoch 5/5\n",
            "77/77 [==============================] - 3s 40ms/step - loss: 0.3056 - accuracy: 0.8944 - val_loss: 0.3980 - val_accuracy: 0.8824\n",
            "0.00020705548524343537 3.9955510849050025e-05\n",
            "Epoch 1/5\n",
            "39/39 [==============================] - 3s 84ms/step - loss: 0.4215 - accuracy: 0.8126 - val_loss: 0.6280 - val_accuracy: 0.7537\n",
            "Epoch 2/5\n",
            "39/39 [==============================] - 3s 82ms/step - loss: 0.3384 - accuracy: 0.8691 - val_loss: 0.6027 - val_accuracy: 0.7831\n",
            "Epoch 3/5\n",
            "39/39 [==============================] - 3s 81ms/step - loss: 0.3058 - accuracy: 0.8801 - val_loss: 0.5761 - val_accuracy: 0.8088\n",
            "Epoch 4/5\n",
            "39/39 [==============================] - 3s 83ms/step - loss: 0.2887 - accuracy: 0.8916 - val_loss: 0.5471 - val_accuracy: 0.8051\n",
            "Epoch 5/5\n",
            "39/39 [==============================] - 3s 81ms/step - loss: 0.2789 - accuracy: 0.8965 - val_loss: 0.5158 - val_accuracy: 0.8125\n",
            "0.0009126464837823222 5.1680081047070015e-06\n",
            "Epoch 1/5\n",
            "20/20 [==============================] - 3s 170ms/step - loss: 0.4570 - accuracy: 0.8134 - val_loss: 0.6172 - val_accuracy: 0.6324\n",
            "Epoch 2/5\n",
            "20/20 [==============================] - 3s 160ms/step - loss: 0.2834 - accuracy: 0.8842 - val_loss: 0.6127 - val_accuracy: 0.6618\n",
            "Epoch 3/5\n",
            "20/20 [==============================] - 3s 159ms/step - loss: 0.2951 - accuracy: 0.8822 - val_loss: 0.6009 - val_accuracy: 0.6838\n",
            "Epoch 4/5\n",
            "20/20 [==============================] - 3s 163ms/step - loss: 0.2395 - accuracy: 0.9018 - val_loss: 0.5507 - val_accuracy: 0.8493\n",
            "Epoch 5/5\n",
            "20/20 [==============================] - 3s 159ms/step - loss: 0.2258 - accuracy: 0.9157 - val_loss: 0.5421 - val_accuracy: 0.8088\n",
            "1.9231311642723086e-06 3.26947242483865e-06\n",
            "Epoch 1/5\n",
            "39/39 [==============================] - 3s 86ms/step - loss: 0.8388 - accuracy: 0.4664 - val_loss: 0.7142 - val_accuracy: 0.3971\n",
            "Epoch 2/5\n",
            "39/39 [==============================] - 3s 81ms/step - loss: 0.7540 - accuracy: 0.5041 - val_loss: 0.7053 - val_accuracy: 0.3860\n",
            "Epoch 3/5\n",
            "39/39 [==============================] - 3s 81ms/step - loss: 0.6962 - accuracy: 0.5626 - val_loss: 0.6983 - val_accuracy: 0.4375\n",
            "Epoch 4/5\n",
            "39/39 [==============================] - 3s 83ms/step - loss: 0.6468 - accuracy: 0.6260 - val_loss: 0.6915 - val_accuracy: 0.4926\n",
            "Epoch 5/5\n",
            "39/39 [==============================] - 3s 83ms/step - loss: 0.6144 - accuracy: 0.6862 - val_loss: 0.6841 - val_accuracy: 0.5404\n",
            "2.716526163094731e-06 1.0686751870573723e-05\n",
            "Epoch 1/5\n",
            "77/77 [==============================] - 4s 46ms/step - loss: 0.5896 - accuracy: 0.7230 - val_loss: 0.6697 - val_accuracy: 0.6618\n",
            "Epoch 2/5\n",
            "77/77 [==============================] - 3s 44ms/step - loss: 0.5435 - accuracy: 0.7484 - val_loss: 0.6533 - val_accuracy: 0.6728\n",
            "Epoch 3/5\n",
            "77/77 [==============================] - 3s 44ms/step - loss: 0.5142 - accuracy: 0.7627 - val_loss: 0.6313 - val_accuracy: 0.6875\n",
            "Epoch 4/5\n",
            "77/77 [==============================] - 3s 45ms/step - loss: 0.4953 - accuracy: 0.7766 - val_loss: 0.6041 - val_accuracy: 0.6875\n",
            "Epoch 5/5\n",
            "77/77 [==============================] - 3s 43ms/step - loss: 0.4770 - accuracy: 0.7876 - val_loss: 0.5727 - val_accuracy: 0.7022\n",
            "4.514942025568668e-06 0.0004746684722307846\n",
            "Epoch 1/5\n",
            "20/20 [==============================] - 3s 169ms/step - loss: 0.7900 - accuracy: 0.5626 - val_loss: 0.6826 - val_accuracy: 0.6213\n",
            "Epoch 2/5\n",
            "20/20 [==============================] - 3s 160ms/step - loss: 0.7331 - accuracy: 0.6027 - val_loss: 0.6774 - val_accuracy: 0.6765\n",
            "Epoch 3/5\n",
            "20/20 [==============================] - 3s 162ms/step - loss: 0.7014 - accuracy: 0.6371 - val_loss: 0.6718 - val_accuracy: 0.6875\n",
            "Epoch 4/5\n",
            "20/20 [==============================] - 3s 160ms/step - loss: 0.6616 - accuracy: 0.6620 - val_loss: 0.6657 - val_accuracy: 0.7132\n",
            "Epoch 5/5\n",
            "20/20 [==============================] - 3s 160ms/step - loss: 0.6276 - accuracy: 0.6915 - val_loss: 0.6592 - val_accuracy: 0.7169\n",
            "0.00020853430847723417 0.0012946183310620445\n",
            "Epoch 1/5\n",
            "77/77 [==============================] - 4s 46ms/step - loss: 0.3738 - accuracy: 0.8576 - val_loss: 0.6042 - val_accuracy: 0.7721\n",
            "Epoch 2/5\n",
            "77/77 [==============================] - 3s 43ms/step - loss: 0.2997 - accuracy: 0.8850 - val_loss: 0.5507 - val_accuracy: 0.8382\n",
            "Epoch 3/5\n",
            "77/77 [==============================] - 3s 44ms/step - loss: 0.2697 - accuracy: 0.8948 - val_loss: 0.4907 - val_accuracy: 0.8456\n",
            "Epoch 4/5\n",
            "77/77 [==============================] - 3s 44ms/step - loss: 0.2523 - accuracy: 0.9059 - val_loss: 0.4254 - val_accuracy: 0.8934\n",
            "Epoch 5/5\n",
            "77/77 [==============================] - 3s 45ms/step - loss: 0.2434 - accuracy: 0.9120 - val_loss: 0.3594 - val_accuracy: 0.8934\n",
            "0.0001208949312030794 0.00023619103180488258\n",
            "Epoch 1/5\n",
            "39/39 [==============================] - 3s 86ms/step - loss: 0.4867 - accuracy: 0.7893 - val_loss: 0.6369 - val_accuracy: 0.6691\n",
            "Epoch 2/5\n",
            "39/39 [==============================] - 3s 80ms/step - loss: 0.3782 - accuracy: 0.8523 - val_loss: 0.6093 - val_accuracy: 0.7390\n",
            "Epoch 3/5\n",
            "39/39 [==============================] - 3s 80ms/step - loss: 0.3447 - accuracy: 0.8691 - val_loss: 0.5848 - val_accuracy: 0.7537\n",
            "Epoch 4/5\n",
            "39/39 [==============================] - 3s 82ms/step - loss: 0.3261 - accuracy: 0.8748 - val_loss: 0.5563 - val_accuracy: 0.7978\n",
            "Epoch 5/5\n",
            "39/39 [==============================] - 3s 82ms/step - loss: 0.3062 - accuracy: 0.8875 - val_loss: 0.5248 - val_accuracy: 0.8199\n",
            "1.0255324999229498e-06 0.007296803757829498\n",
            "Epoch 1/5\n",
            "77/77 [==============================] - 3s 45ms/step - loss: 1.1294 - accuracy: 0.3020 - val_loss: 0.7576 - val_accuracy: 0.3640\n",
            "Epoch 2/5\n",
            "77/77 [==============================] - 3s 45ms/step - loss: 0.9827 - accuracy: 0.3523 - val_loss: 0.7528 - val_accuracy: 0.4007\n",
            "Epoch 3/5\n",
            "77/77 [==============================] - 3s 44ms/step - loss: 0.8732 - accuracy: 0.4288 - val_loss: 0.7455 - val_accuracy: 0.4743\n",
            "Epoch 4/5\n",
            "77/77 [==============================] - 3s 44ms/step - loss: 0.7971 - accuracy: 0.5389 - val_loss: 0.7335 - val_accuracy: 0.5294\n",
            "Epoch 5/5\n",
            "77/77 [==============================] - 3s 43ms/step - loss: 0.7393 - accuracy: 0.6076 - val_loss: 0.7162 - val_accuracy: 0.6029\n",
            "5.939561361707228e-05 6.446324385756203e-05\n",
            "Epoch 1/5\n",
            "39/39 [==============================] - 3s 86ms/step - loss: 0.5121 - accuracy: 0.7754 - val_loss: 0.6359 - val_accuracy: 0.6949\n",
            "Epoch 2/5\n",
            "39/39 [==============================] - 3s 80ms/step - loss: 0.3955 - accuracy: 0.8498 - val_loss: 0.6103 - val_accuracy: 0.7537\n",
            "Epoch 3/5\n",
            "39/39 [==============================] - 3s 81ms/step - loss: 0.3606 - accuracy: 0.8703 - val_loss: 0.5849 - val_accuracy: 0.7610\n",
            "Epoch 4/5\n",
            "39/39 [==============================] - 3s 82ms/step - loss: 0.3464 - accuracy: 0.8748 - val_loss: 0.5595 - val_accuracy: 0.7794\n",
            "Epoch 5/5\n",
            "39/39 [==============================] - 3s 81ms/step - loss: 0.3341 - accuracy: 0.8756 - val_loss: 0.5330 - val_accuracy: 0.7831\n",
            "4.180486388927058e-06 1.87727411240086e-06\n",
            "Epoch 1/5\n",
            "39/39 [==============================] - 3s 86ms/step - loss: 0.9420 - accuracy: 0.4276 - val_loss: 0.7005 - val_accuracy: 0.5184\n",
            "Epoch 2/5\n",
            "39/39 [==============================] - 3s 82ms/step - loss: 0.8612 - accuracy: 0.4967 - val_loss: 0.6943 - val_accuracy: 0.5625\n",
            "Epoch 3/5\n",
            "39/39 [==============================] - 3s 81ms/step - loss: 0.7773 - accuracy: 0.5769 - val_loss: 0.6868 - val_accuracy: 0.5956\n",
            "Epoch 4/5\n",
            "39/39 [==============================] - 3s 81ms/step - loss: 0.7212 - accuracy: 0.6289 - val_loss: 0.6779 - val_accuracy: 0.6250\n",
            "Epoch 5/5\n",
            "39/39 [==============================] - 3s 82ms/step - loss: 0.6788 - accuracy: 0.6608 - val_loss: 0.6672 - val_accuracy: 0.6581\n",
            "9.208208215414841e-05 3.3440441811017e-05\n",
            "Epoch 1/5\n",
            "20/20 [==============================] - 3s 168ms/step - loss: 0.6027 - accuracy: 0.6993 - val_loss: 0.6571 - val_accuracy: 0.6176\n",
            "Epoch 2/5\n",
            "20/20 [==============================] - 3s 158ms/step - loss: 0.4464 - accuracy: 0.8339 - val_loss: 0.6377 - val_accuracy: 0.6765\n",
            "Epoch 3/5\n",
            "20/20 [==============================] - 3s 156ms/step - loss: 0.3826 - accuracy: 0.8547 - val_loss: 0.6223 - val_accuracy: 0.6912\n",
            "Epoch 4/5\n",
            "20/20 [==============================] - 3s 158ms/step - loss: 0.3556 - accuracy: 0.8654 - val_loss: 0.6080 - val_accuracy: 0.7206\n",
            "Epoch 5/5\n",
            "20/20 [==============================] - 3s 155ms/step - loss: 0.3464 - accuracy: 0.8711 - val_loss: 0.5939 - val_accuracy: 0.7353\n",
            "1.9842174452004733e-06 3.6420568656624936e-05\n",
            "Epoch 1/5\n",
            "39/39 [==============================] - 3s 86ms/step - loss: 0.7943 - accuracy: 0.4321 - val_loss: 0.6928 - val_accuracy: 0.5331\n",
            "Epoch 2/5\n",
            "39/39 [==============================] - 3s 79ms/step - loss: 0.7409 - accuracy: 0.4926 - val_loss: 0.6883 - val_accuracy: 0.5478\n",
            "Epoch 3/5\n",
            "39/39 [==============================] - 3s 79ms/step - loss: 0.7018 - accuracy: 0.5855 - val_loss: 0.6832 - val_accuracy: 0.5846\n",
            "Epoch 4/5\n",
            "39/39 [==============================] - 3s 81ms/step - loss: 0.6681 - accuracy: 0.6346 - val_loss: 0.6772 - val_accuracy: 0.6324\n",
            "Epoch 5/5\n",
            "39/39 [==============================] - 3s 81ms/step - loss: 0.6449 - accuracy: 0.6637 - val_loss: 0.6699 - val_accuracy: 0.6544\n",
            "0.00012968363029852335 0.00010040746079293375\n",
            "Epoch 1/5\n",
            "39/39 [==============================] - 3s 86ms/step - loss: 0.4951 - accuracy: 0.7778 - val_loss: 0.6496 - val_accuracy: 0.6838\n",
            "Epoch 2/5\n",
            "39/39 [==============================] - 3s 80ms/step - loss: 0.3428 - accuracy: 0.8727 - val_loss: 0.6252 - val_accuracy: 0.7426\n",
            "Epoch 3/5\n",
            "39/39 [==============================] - 3s 79ms/step - loss: 0.3101 - accuracy: 0.8867 - val_loss: 0.5988 - val_accuracy: 0.8199\n",
            "Epoch 4/5\n",
            "39/39 [==============================] - 3s 80ms/step - loss: 0.2927 - accuracy: 0.8936 - val_loss: 0.5731 - val_accuracy: 0.8309\n",
            "Epoch 5/5\n",
            "39/39 [==============================] - 3s 81ms/step - loss: 0.2754 - accuracy: 0.8961 - val_loss: 0.5435 - val_accuracy: 0.8493\n",
            "0.00035067451469899006 0.00021455742937212145\n",
            "Epoch 1/5\n",
            "39/39 [==============================] - 3s 84ms/step - loss: 0.3481 - accuracy: 0.8646 - val_loss: 0.6161 - val_accuracy: 0.6728\n",
            "Epoch 2/5\n",
            "39/39 [==============================] - 3s 78ms/step - loss: 0.2815 - accuracy: 0.8912 - val_loss: 0.5875 - val_accuracy: 0.7463\n",
            "Epoch 3/5\n",
            "39/39 [==============================] - 3s 79ms/step - loss: 0.2559 - accuracy: 0.9063 - val_loss: 0.5533 - val_accuracy: 0.7757\n",
            "Epoch 4/5\n",
            "39/39 [==============================] - 3s 79ms/step - loss: 0.2518 - accuracy: 0.9051 - val_loss: 0.5272 - val_accuracy: 0.8162\n",
            "Epoch 5/5\n",
            "39/39 [==============================] - 3s 80ms/step - loss: 0.2426 - accuracy: 0.9124 - val_loss: 0.4939 - val_accuracy: 0.8199\n",
            "3.701995912579923e-05 7.483171094236089e-06\n",
            "Epoch 1/5\n",
            "20/20 [==============================] - 3s 166ms/step - loss: 0.6304 - accuracy: 0.6714 - val_loss: 0.6597 - val_accuracy: 0.7206\n",
            "Epoch 2/5\n",
            "20/20 [==============================] - 3s 155ms/step - loss: 0.4797 - accuracy: 0.7872 - val_loss: 0.6436 - val_accuracy: 0.7500\n",
            "Epoch 3/5\n",
            "20/20 [==============================] - 3s 158ms/step - loss: 0.4303 - accuracy: 0.8167 - val_loss: 0.6309 - val_accuracy: 0.7647\n",
            "Epoch 4/5\n",
            "20/20 [==============================] - 3s 157ms/step - loss: 0.3963 - accuracy: 0.8421 - val_loss: 0.6191 - val_accuracy: 0.7721\n",
            "Epoch 5/5\n",
            "20/20 [==============================] - 3s 157ms/step - loss: 0.3795 - accuracy: 0.8502 - val_loss: 0.6078 - val_accuracy: 0.7831\n",
            "0.0006788908614458456 9.842546192197756e-05\n",
            "Epoch 1/5\n",
            "39/39 [==============================] - 3s 87ms/step - loss: 0.3590 - accuracy: 0.8547 - val_loss: 0.6129 - val_accuracy: 0.7059\n",
            "Epoch 2/5\n",
            "39/39 [==============================] - 4s 101ms/step - loss: 0.2717 - accuracy: 0.8998 - val_loss: 0.5898 - val_accuracy: 0.7463\n",
            "Epoch 3/5\n",
            "39/39 [==============================] - 5s 127ms/step - loss: 0.2426 - accuracy: 0.9120 - val_loss: 0.5542 - val_accuracy: 0.8051\n",
            "Epoch 4/5\n",
            "39/39 [==============================] - 4s 107ms/step - loss: 0.2254 - accuracy: 0.9190 - val_loss: 0.5173 - val_accuracy: 0.8529\n",
            "Epoch 5/5\n",
            "39/39 [==============================] - 3s 81ms/step - loss: 0.2189 - accuracy: 0.9206 - val_loss: 0.4939 - val_accuracy: 0.8676\n",
            "7.746379780030956e-06 1.9572990585902495e-05\n",
            "Epoch 1/5\n",
            "39/39 [==============================] - 3s 85ms/step - loss: 0.7291 - accuracy: 0.5728 - val_loss: 0.6931 - val_accuracy: 0.4743\n",
            "Epoch 2/5\n",
            "39/39 [==============================] - 3s 79ms/step - loss: 0.6353 - accuracy: 0.6731 - val_loss: 0.6798 - val_accuracy: 0.5882\n",
            "Epoch 3/5\n",
            "39/39 [==============================] - 3s 80ms/step - loss: 0.5749 - accuracy: 0.7381 - val_loss: 0.6652 - val_accuracy: 0.6654\n",
            "Epoch 4/5\n",
            "39/39 [==============================] - 3s 81ms/step - loss: 0.5366 - accuracy: 0.7668 - val_loss: 0.6493 - val_accuracy: 0.7059\n",
            "Epoch 5/5\n",
            "39/39 [==============================] - 3s 81ms/step - loss: 0.4986 - accuracy: 0.7860 - val_loss: 0.6303 - val_accuracy: 0.7390\n",
            "1.0789604412675677e-05 0.00011005340240660181\n",
            "Epoch 1/5\n",
            "20/20 [==============================] - 3s 160ms/step - loss: 0.6962 - accuracy: 0.6588 - val_loss: 0.6843 - val_accuracy: 0.5699\n",
            "Epoch 2/5\n",
            "20/20 [==============================] - 3s 154ms/step - loss: 0.6525 - accuracy: 0.6944 - val_loss: 0.6788 - val_accuracy: 0.6360\n",
            "Epoch 3/5\n",
            "20/20 [==============================] - 3s 158ms/step - loss: 0.6052 - accuracy: 0.7115 - val_loss: 0.6733 - val_accuracy: 0.6618\n",
            "Epoch 4/5\n",
            "20/20 [==============================] - 3s 158ms/step - loss: 0.5800 - accuracy: 0.7324 - val_loss: 0.6677 - val_accuracy: 0.6985\n",
            "Epoch 5/5\n",
            "20/20 [==============================] - 3s 156ms/step - loss: 0.5533 - accuracy: 0.7471 - val_loss: 0.6615 - val_accuracy: 0.7059\n",
            "4.9696746098166505e-06 0.002515496610476109\n",
            "Epoch 1/5\n",
            "77/77 [==============================] - 3s 43ms/step - loss: 0.8122 - accuracy: 0.6755 - val_loss: 0.6951 - val_accuracy: 0.6250\n",
            "Epoch 2/5\n",
            "77/77 [==============================] - 3s 40ms/step - loss: 0.6491 - accuracy: 0.7218 - val_loss: 0.6651 - val_accuracy: 0.6801\n",
            "Epoch 3/5\n",
            "77/77 [==============================] - 3s 40ms/step - loss: 0.5594 - accuracy: 0.7549 - val_loss: 0.6338 - val_accuracy: 0.7096\n",
            "Epoch 4/5\n",
            "77/77 [==============================] - 3s 41ms/step - loss: 0.5107 - accuracy: 0.7770 - val_loss: 0.5979 - val_accuracy: 0.7096\n",
            "Epoch 5/5\n",
            "77/77 [==============================] - 3s 42ms/step - loss: 0.4833 - accuracy: 0.7897 - val_loss: 0.5592 - val_accuracy: 0.7206\n",
            "1.4113954529602067e-06 1.7593715640404441e-06\n",
            "Epoch 1/5\n",
            "77/77 [==============================] - 3s 42ms/step - loss: 0.6912 - accuracy: 0.6199 - val_loss: 0.6782 - val_accuracy: 0.6324\n",
            "Epoch 2/5\n",
            "77/77 [==============================] - 3s 41ms/step - loss: 0.6468 - accuracy: 0.6641 - val_loss: 0.6666 - val_accuracy: 0.6654\n",
            "Epoch 3/5\n",
            "77/77 [==============================] - 3s 41ms/step - loss: 0.6111 - accuracy: 0.6976 - val_loss: 0.6501 - val_accuracy: 0.6838\n",
            "Epoch 4/5\n",
            "77/77 [==============================] - 3s 40ms/step - loss: 0.5792 - accuracy: 0.7250 - val_loss: 0.6281 - val_accuracy: 0.7022\n",
            "Epoch 5/5\n",
            "77/77 [==============================] - 3s 42ms/step - loss: 0.5534 - accuracy: 0.7525 - val_loss: 0.6008 - val_accuracy: 0.7169\n",
            "0.0002458239046118962 0.0004545158699776079\n",
            "Epoch 1/5\n",
            "39/39 [==============================] - 3s 85ms/step - loss: 0.4093 - accuracy: 0.8535 - val_loss: 0.6203 - val_accuracy: 0.7096\n",
            "Epoch 2/5\n",
            "39/39 [==============================] - 3s 80ms/step - loss: 0.3291 - accuracy: 0.8834 - val_loss: 0.5932 - val_accuracy: 0.8088\n",
            "Epoch 3/5\n",
            "39/39 [==============================] - 3s 80ms/step - loss: 0.2943 - accuracy: 0.8993 - val_loss: 0.5647 - val_accuracy: 0.8235\n",
            "Epoch 4/5\n",
            "39/39 [==============================] - 3s 80ms/step - loss: 0.2640 - accuracy: 0.9067 - val_loss: 0.5349 - val_accuracy: 0.8640\n",
            "Epoch 5/5\n",
            "39/39 [==============================] - 3s 81ms/step - loss: 0.2580 - accuracy: 0.9141 - val_loss: 0.5062 - val_accuracy: 0.8860\n",
            "0.00047130778613061586 4.541808883668654e-05\n",
            "Epoch 1/5\n",
            "20/20 [==============================] - 3s 165ms/step - loss: 0.4229 - accuracy: 0.8155 - val_loss: 0.6382 - val_accuracy: 0.6103\n",
            "Epoch 2/5\n",
            "20/20 [==============================] - 3s 156ms/step - loss: 0.2974 - accuracy: 0.8854 - val_loss: 0.6158 - val_accuracy: 0.6838\n",
            "Epoch 3/5\n",
            "20/20 [==============================] - 3s 154ms/step - loss: 0.2841 - accuracy: 0.8891 - val_loss: 0.5974 - val_accuracy: 0.7353\n",
            "Epoch 4/5\n",
            "20/20 [==============================] - 3s 154ms/step - loss: 0.2548 - accuracy: 0.9010 - val_loss: 0.5822 - val_accuracy: 0.7537\n",
            "Epoch 5/5\n",
            "20/20 [==============================] - 3s 157ms/step - loss: 0.2427 - accuracy: 0.9047 - val_loss: 0.5663 - val_accuracy: 0.7574\n",
            "1.5756473466188845e-05 5.7500594454063475e-06\n",
            "Epoch 1/5\n",
            "20/20 [==============================] - 3s 165ms/step - loss: 0.9586 - accuracy: 0.4767 - val_loss: 0.6899 - val_accuracy: 0.5184\n",
            "Epoch 2/5\n",
            "20/20 [==============================] - 3s 156ms/step - loss: 0.6279 - accuracy: 0.7029 - val_loss: 0.6728 - val_accuracy: 0.6471\n",
            "Epoch 3/5\n",
            "20/20 [==============================] - 3s 159ms/step - loss: 0.5318 - accuracy: 0.7831 - val_loss: 0.6626 - val_accuracy: 0.6434\n",
            "Epoch 4/5\n",
            "20/20 [==============================] - 3s 156ms/step - loss: 0.4950 - accuracy: 0.8007 - val_loss: 0.6535 - val_accuracy: 0.6654\n",
            "Epoch 5/5\n",
            "20/20 [==============================] - 3s 155ms/step - loss: 0.4766 - accuracy: 0.8077 - val_loss: 0.6446 - val_accuracy: 0.6838\n",
            "0.0006959157919087281 2.755448752439067e-06\n",
            "Epoch 1/5\n",
            "77/77 [==============================] - 3s 43ms/step - loss: 0.3141 - accuracy: 0.8793 - val_loss: 0.5734 - val_accuracy: 0.7868\n",
            "Epoch 2/5\n",
            "77/77 [==============================] - 3s 40ms/step - loss: 0.2441 - accuracy: 0.9083 - val_loss: 0.5115 - val_accuracy: 0.8199\n",
            "Epoch 3/5\n",
            "77/77 [==============================] - 3s 40ms/step - loss: 0.2218 - accuracy: 0.9206 - val_loss: 0.4378 - val_accuracy: 0.8346\n",
            "Epoch 4/5\n",
            "77/77 [==============================] - 3s 40ms/step - loss: 0.1930 - accuracy: 0.9268 - val_loss: 0.3691 - val_accuracy: 0.8566\n",
            "Epoch 5/5\n",
            "77/77 [==============================] - 3s 40ms/step - loss: 0.1730 - accuracy: 0.9382 - val_loss: 0.3068 - val_accuracy: 0.8713\n",
            "0.0005148184461001097 0.004094689998317514\n",
            "Epoch 1/5\n",
            "20/20 [==============================] - 3s 163ms/step - loss: 0.4297 - accuracy: 0.8212 - val_loss: 0.6543 - val_accuracy: 0.5993\n",
            "Epoch 2/5\n",
            "20/20 [==============================] - 3s 154ms/step - loss: 0.3174 - accuracy: 0.8867 - val_loss: 0.6344 - val_accuracy: 0.6507\n",
            "Epoch 3/5\n",
            "20/20 [==============================] - 3s 155ms/step - loss: 0.3052 - accuracy: 0.8961 - val_loss: 0.6210 - val_accuracy: 0.6838\n",
            "Epoch 4/5\n",
            "20/20 [==============================] - 3s 154ms/step - loss: 0.2691 - accuracy: 0.9063 - val_loss: 0.6029 - val_accuracy: 0.7279\n",
            "Epoch 5/5\n",
            "20/20 [==============================] - 3s 155ms/step - loss: 0.2628 - accuracy: 0.9116 - val_loss: 0.5846 - val_accuracy: 0.7684\n",
            "2.1071234330777313e-06 0.002518758073075564\n",
            "Epoch 1/5\n",
            "20/20 [==============================] - 3s 163ms/step - loss: 0.8294 - accuracy: 0.4652 - val_loss: 0.7087 - val_accuracy: 0.4853\n",
            "Epoch 2/5\n",
            "20/20 [==============================] - 3s 155ms/step - loss: 0.7915 - accuracy: 0.4890 - val_loss: 0.7047 - val_accuracy: 0.5147\n",
            "Epoch 3/5\n",
            "20/20 [==============================] - 3s 154ms/step - loss: 0.7530 - accuracy: 0.5176 - val_loss: 0.7010 - val_accuracy: 0.5735\n",
            "Epoch 4/5\n",
            "20/20 [==============================] - 3s 155ms/step - loss: 0.7193 - accuracy: 0.5597 - val_loss: 0.6975 - val_accuracy: 0.6066\n",
            "Epoch 5/5\n",
            "20/20 [==============================] - 3s 152ms/step - loss: 0.6999 - accuracy: 0.6039 - val_loss: 0.6938 - val_accuracy: 0.6287\n",
            "3.290349031539987e-05 0.0002923310075442375\n",
            "Epoch 1/5\n",
            "20/20 [==============================] - 3s 159ms/step - loss: 0.6264 - accuracy: 0.6919 - val_loss: 0.6752 - val_accuracy: 0.5846\n",
            "Epoch 2/5\n",
            "20/20 [==============================] - 3s 153ms/step - loss: 0.5046 - accuracy: 0.7885 - val_loss: 0.6619 - val_accuracy: 0.6287\n",
            "Epoch 3/5\n",
            "20/20 [==============================] - 3s 155ms/step - loss: 0.4704 - accuracy: 0.8126 - val_loss: 0.6491 - val_accuracy: 0.6728\n",
            "Epoch 4/5\n",
            "20/20 [==============================] - 3s 156ms/step - loss: 0.4334 - accuracy: 0.8322 - val_loss: 0.6383 - val_accuracy: 0.6875\n",
            "Epoch 5/5\n",
            "20/20 [==============================] - 3s 154ms/step - loss: 0.4250 - accuracy: 0.8359 - val_loss: 0.6280 - val_accuracy: 0.6912\n",
            "3.342992512365823e-05 1.517920907506151e-06\n",
            "Epoch 1/5\n",
            "20/20 [==============================] - 3s 162ms/step - loss: 0.7428 - accuracy: 0.5741 - val_loss: 0.6779 - val_accuracy: 0.5846\n",
            "Epoch 2/5\n",
            "20/20 [==============================] - 3s 154ms/step - loss: 0.5644 - accuracy: 0.7406 - val_loss: 0.6622 - val_accuracy: 0.6507\n",
            "Epoch 3/5\n",
            "20/20 [==============================] - 3s 154ms/step - loss: 0.4918 - accuracy: 0.7926 - val_loss: 0.6486 - val_accuracy: 0.6875\n",
            "Epoch 4/5\n",
            "20/20 [==============================] - 3s 150ms/step - loss: 0.4605 - accuracy: 0.8175 - val_loss: 0.6362 - val_accuracy: 0.7096\n",
            "Epoch 5/5\n",
            "20/20 [==============================] - 3s 153ms/step - loss: 0.4241 - accuracy: 0.8302 - val_loss: 0.6244 - val_accuracy: 0.7353\n",
            "8.786877590916243e-06 9.699478381365175e-05\n",
            "Epoch 1/5\n",
            "39/39 [==============================] - 3s 83ms/step - loss: 0.6431 - accuracy: 0.6567 - val_loss: 0.6741 - val_accuracy: 0.6140\n",
            "Epoch 2/5\n",
            "39/39 [==============================] - 3s 79ms/step - loss: 0.5630 - accuracy: 0.7349 - val_loss: 0.6582 - val_accuracy: 0.6728\n",
            "Epoch 3/5\n",
            "39/39 [==============================] - 3s 80ms/step - loss: 0.5144 - accuracy: 0.7795 - val_loss: 0.6416 - val_accuracy: 0.6985\n",
            "Epoch 4/5\n",
            "39/39 [==============================] - 3s 79ms/step - loss: 0.4866 - accuracy: 0.8032 - val_loss: 0.6239 - val_accuracy: 0.7169\n",
            "Epoch 5/5\n",
            "39/39 [==============================] - 3s 79ms/step - loss: 0.4640 - accuracy: 0.8163 - val_loss: 0.6051 - val_accuracy: 0.7132\n",
            "7.5793629508896636e-06 4.206369662083323e-06\n",
            "Epoch 1/5\n",
            "77/77 [==============================] - 3s 43ms/step - loss: 0.6344 - accuracy: 0.6813 - val_loss: 0.6631 - val_accuracy: 0.6360\n",
            "Epoch 2/5\n",
            "77/77 [==============================] - 3s 41ms/step - loss: 0.5409 - accuracy: 0.7316 - val_loss: 0.6364 - val_accuracy: 0.6985\n",
            "Epoch 3/5\n",
            "77/77 [==============================] - 3s 41ms/step - loss: 0.4932 - accuracy: 0.7672 - val_loss: 0.6035 - val_accuracy: 0.7132\n",
            "Epoch 4/5\n",
            "77/77 [==============================] - 3s 41ms/step - loss: 0.4617 - accuracy: 0.7954 - val_loss: 0.5649 - val_accuracy: 0.7537\n",
            "Epoch 5/5\n",
            "77/77 [==============================] - 3s 42ms/step - loss: 0.4430 - accuracy: 0.8118 - val_loss: 0.5239 - val_accuracy: 0.7721\n",
            "2.6184541024193696e-06 3.7941758407193356e-06\n",
            "Epoch 1/5\n",
            "77/77 [==============================] - 3s 44ms/step - loss: 1.2009 - accuracy: 0.4493 - val_loss: 0.7026 - val_accuracy: 0.4007\n",
            "Epoch 2/5\n",
            "77/77 [==============================] - 3s 43ms/step - loss: 0.7652 - accuracy: 0.5839 - val_loss: 0.6623 - val_accuracy: 0.6434\n",
            "Epoch 3/5\n",
            "77/77 [==============================] - 3s 43ms/step - loss: 0.6010 - accuracy: 0.7353 - val_loss: 0.6284 - val_accuracy: 0.7316\n",
            "Epoch 4/5\n",
            "77/77 [==============================] - 3s 43ms/step - loss: 0.5367 - accuracy: 0.7762 - val_loss: 0.5938 - val_accuracy: 0.7684\n",
            "Epoch 5/5\n",
            "77/77 [==============================] - 3s 42ms/step - loss: 0.5062 - accuracy: 0.7901 - val_loss: 0.5593 - val_accuracy: 0.7574\n",
            "0.00048660703782061964 0.0009774175142747764\n",
            "Epoch 1/5\n",
            "20/20 [==============================] - 3s 173ms/step - loss: 0.4086 - accuracy: 0.8429 - val_loss: 0.6321 - val_accuracy: 0.7757\n",
            "Epoch 2/5\n",
            "20/20 [==============================] - 3s 158ms/step - loss: 0.3096 - accuracy: 0.8887 - val_loss: 0.6149 - val_accuracy: 0.6875\n",
            "Epoch 3/5\n",
            "20/20 [==============================] - 3s 160ms/step - loss: 0.2812 - accuracy: 0.8948 - val_loss: 0.5977 - val_accuracy: 0.7610\n",
            "Epoch 4/5\n",
            "20/20 [==============================] - 3s 157ms/step - loss: 0.2571 - accuracy: 0.9043 - val_loss: 0.5802 - val_accuracy: 0.7574\n",
            "Epoch 5/5\n",
            "20/20 [==============================] - 3s 160ms/step - loss: 0.2518 - accuracy: 0.9112 - val_loss: 0.5656 - val_accuracy: 0.7684\n",
            "0.00017078121193107835 0.00019651412197069625\n",
            "Epoch 1/5\n",
            "20/20 [==============================] - 3s 164ms/step - loss: 0.4877 - accuracy: 0.7975 - val_loss: 0.6461 - val_accuracy: 0.7022\n",
            "Epoch 2/5\n",
            "20/20 [==============================] - 3s 156ms/step - loss: 0.3934 - accuracy: 0.8531 - val_loss: 0.6290 - val_accuracy: 0.7794\n",
            "Epoch 3/5\n",
            "20/20 [==============================] - 3s 156ms/step - loss: 0.3379 - accuracy: 0.8695 - val_loss: 0.6146 - val_accuracy: 0.8051\n",
            "Epoch 4/5\n",
            "20/20 [==============================] - 3s 162ms/step - loss: 0.3182 - accuracy: 0.8813 - val_loss: 0.6014 - val_accuracy: 0.7978\n",
            "Epoch 5/5\n",
            "20/20 [==============================] - 3s 159ms/step - loss: 0.3092 - accuracy: 0.8908 - val_loss: 0.5874 - val_accuracy: 0.8162\n",
            "4.6723160690760224e-05 0.0002983578405376808\n",
            "Epoch 1/5\n",
            "39/39 [==============================] - 3s 87ms/step - loss: 0.5694 - accuracy: 0.7500 - val_loss: 0.6491 - val_accuracy: 0.6985\n",
            "Epoch 2/5\n",
            "39/39 [==============================] - 3s 80ms/step - loss: 0.4285 - accuracy: 0.8335 - val_loss: 0.6249 - val_accuracy: 0.7390\n",
            "Epoch 3/5\n",
            "39/39 [==============================] - 3s 81ms/step - loss: 0.3775 - accuracy: 0.8588 - val_loss: 0.6016 - val_accuracy: 0.7537\n",
            "Epoch 4/5\n",
            "39/39 [==============================] - 3s 81ms/step - loss: 0.3484 - accuracy: 0.8678 - val_loss: 0.5776 - val_accuracy: 0.7978\n",
            "Epoch 5/5\n",
            "39/39 [==============================] - 3s 79ms/step - loss: 0.3351 - accuracy: 0.8781 - val_loss: 0.5501 - val_accuracy: 0.8235\n",
            "4.350588624493494e-06 5.5822034195761655e-05\n",
            "Epoch 1/5\n",
            "77/77 [==============================] - 3s 44ms/step - loss: 0.7878 - accuracy: 0.5209 - val_loss: 0.6802 - val_accuracy: 0.6287\n",
            "Epoch 2/5\n",
            "77/77 [==============================] - 3s 40ms/step - loss: 0.6390 - accuracy: 0.6628 - val_loss: 0.6582 - val_accuracy: 0.7169\n",
            "Epoch 3/5\n",
            "77/77 [==============================] - 3s 41ms/step - loss: 0.5663 - accuracy: 0.7377 - val_loss: 0.6289 - val_accuracy: 0.7316\n",
            "Epoch 4/5\n",
            "77/77 [==============================] - 3s 42ms/step - loss: 0.5254 - accuracy: 0.7684 - val_loss: 0.5912 - val_accuracy: 0.7684\n",
            "Epoch 5/5\n",
            "77/77 [==============================] - 3s 41ms/step - loss: 0.4950 - accuracy: 0.7958 - val_loss: 0.5483 - val_accuracy: 0.7868\n",
            "0.00036458142442429096 3.080590303658148e-05\n",
            "Epoch 1/5\n",
            "39/39 [==============================] - 3s 86ms/step - loss: 0.4061 - accuracy: 0.8318 - val_loss: 0.6307 - val_accuracy: 0.8529\n",
            "Epoch 2/5\n",
            "39/39 [==============================] - 3s 81ms/step - loss: 0.2998 - accuracy: 0.8940 - val_loss: 0.6025 - val_accuracy: 0.8934\n",
            "Epoch 3/5\n",
            "39/39 [==============================] - 3s 81ms/step - loss: 0.2684 - accuracy: 0.9079 - val_loss: 0.5739 - val_accuracy: 0.9081\n",
            "Epoch 4/5\n",
            "39/39 [==============================] - 3s 79ms/step - loss: 0.2589 - accuracy: 0.9133 - val_loss: 0.5489 - val_accuracy: 0.9081\n",
            "Epoch 5/5\n",
            "39/39 [==============================] - 3s 81ms/step - loss: 0.2507 - accuracy: 0.9149 - val_loss: 0.5187 - val_accuracy: 0.9044\n",
            "2.1047940040696096e-05 0.0001300788118102566\n",
            "Epoch 1/5\n",
            "77/77 [==============================] - 3s 44ms/step - loss: 0.5759 - accuracy: 0.7164 - val_loss: 0.6488 - val_accuracy: 0.7022\n",
            "Epoch 2/5\n",
            "77/77 [==============================] - 3s 41ms/step - loss: 0.4177 - accuracy: 0.8388 - val_loss: 0.6105 - val_accuracy: 0.7537\n",
            "Epoch 3/5\n",
            "77/77 [==============================] - 3s 42ms/step - loss: 0.3820 - accuracy: 0.8482 - val_loss: 0.5655 - val_accuracy: 0.7757\n",
            "Epoch 4/5\n",
            "77/77 [==============================] - 3s 42ms/step - loss: 0.3639 - accuracy: 0.8642 - val_loss: 0.5153 - val_accuracy: 0.7868\n",
            "Epoch 5/5\n",
            "77/77 [==============================] - 3s 41ms/step - loss: 0.3452 - accuracy: 0.8674 - val_loss: 0.4613 - val_accuracy: 0.8125\n",
            "5.850269698335309e-05 8.224768897944637e-05\n",
            "Epoch 1/5\n",
            "77/77 [==============================] - 3s 44ms/step - loss: 0.4193 - accuracy: 0.8318 - val_loss: 0.6152 - val_accuracy: 0.8088\n",
            "Epoch 2/5\n",
            "77/77 [==============================] - 3s 42ms/step - loss: 0.3449 - accuracy: 0.8727 - val_loss: 0.5648 - val_accuracy: 0.8419\n",
            "Epoch 3/5\n",
            "77/77 [==============================] - 3s 42ms/step - loss: 0.3103 - accuracy: 0.8908 - val_loss: 0.5087 - val_accuracy: 0.8603\n",
            "Epoch 4/5\n",
            "77/77 [==============================] - 3s 42ms/step - loss: 0.2968 - accuracy: 0.8899 - val_loss: 0.4470 - val_accuracy: 0.8640\n",
            "Epoch 5/5\n",
            "77/77 [==============================] - 3s 42ms/step - loss: 0.2824 - accuracy: 0.8965 - val_loss: 0.3877 - val_accuracy: 0.8860\n",
            "4.628855557945946e-06 2.471826160057653e-05\n",
            "Epoch 1/5\n",
            "20/20 [==============================] - 3s 166ms/step - loss: 1.0665 - accuracy: 0.5033 - val_loss: 0.6972 - val_accuracy: 0.4706\n",
            "Epoch 2/5\n",
            "20/20 [==============================] - 3s 161ms/step - loss: 0.8427 - accuracy: 0.5520 - val_loss: 0.6821 - val_accuracy: 0.5368\n",
            "Epoch 3/5\n",
            "20/20 [==============================] - 3s 161ms/step - loss: 0.6870 - accuracy: 0.5921 - val_loss: 0.6713 - val_accuracy: 0.6360\n",
            "Epoch 4/5\n",
            "20/20 [==============================] - 3s 160ms/step - loss: 0.6138 - accuracy: 0.6612 - val_loss: 0.6626 - val_accuracy: 0.7316\n",
            "Epoch 5/5\n",
            "20/20 [==============================] - 3s 157ms/step - loss: 0.5494 - accuracy: 0.7451 - val_loss: 0.6548 - val_accuracy: 0.7610\n",
            "2.867378833668252e-06 0.0005329282449490426\n",
            "Epoch 1/5\n",
            "39/39 [==============================] - 3s 86ms/step - loss: 0.5684 - accuracy: 0.7549 - val_loss: 0.6781 - val_accuracy: 0.6507\n",
            "Epoch 2/5\n",
            "39/39 [==============================] - 3s 80ms/step - loss: 0.5506 - accuracy: 0.7713 - val_loss: 0.6705 - val_accuracy: 0.6581\n",
            "Epoch 3/5\n",
            "39/39 [==============================] - 3s 80ms/step - loss: 0.5241 - accuracy: 0.7852 - val_loss: 0.6616 - val_accuracy: 0.6691\n",
            "Epoch 4/5\n",
            "39/39 [==============================] - 3s 81ms/step - loss: 0.5069 - accuracy: 0.7917 - val_loss: 0.6514 - val_accuracy: 0.6949\n",
            "Epoch 5/5\n",
            "39/39 [==============================] - 3s 80ms/step - loss: 0.4959 - accuracy: 0.7979 - val_loss: 0.6395 - val_accuracy: 0.7022\n",
            "0.00088372721454196 1.2162503464797059e-06\n",
            "Epoch 1/5\n",
            "20/20 [==============================] - 3s 167ms/step - loss: 0.4003 - accuracy: 0.8249 - val_loss: 0.6142 - val_accuracy: 0.6765\n",
            "Epoch 2/5\n",
            "20/20 [==============================] - 3s 157ms/step - loss: 0.2790 - accuracy: 0.8920 - val_loss: 0.5965 - val_accuracy: 0.7206\n",
            "Epoch 3/5\n",
            "20/20 [==============================] - 3s 158ms/step - loss: 0.2527 - accuracy: 0.9018 - val_loss: 0.5773 - val_accuracy: 0.8860\n",
            "Epoch 4/5\n",
            "20/20 [==============================] - 3s 152ms/step - loss: 0.2376 - accuracy: 0.9063 - val_loss: 0.5590 - val_accuracy: 0.8015\n",
            "Epoch 5/5\n",
            "20/20 [==============================] - 3s 155ms/step - loss: 0.2530 - accuracy: 0.9043 - val_loss: 0.5459 - val_accuracy: 0.8603\n",
            "1.534966645215634e-05 0.0003138536978721347\n",
            "Epoch 1/5\n",
            "20/20 [==============================] - 3s 164ms/step - loss: 0.7418 - accuracy: 0.5245 - val_loss: 0.6812 - val_accuracy: 0.6213\n",
            "Epoch 2/5\n",
            "20/20 [==============================] - 3s 156ms/step - loss: 0.5856 - accuracy: 0.7226 - val_loss: 0.6706 - val_accuracy: 0.6691\n",
            "Epoch 3/5\n",
            "20/20 [==============================] - 3s 158ms/step - loss: 0.5296 - accuracy: 0.7664 - val_loss: 0.6615 - val_accuracy: 0.6985\n",
            "Epoch 4/5\n",
            "20/20 [==============================] - 3s 161ms/step - loss: 0.5119 - accuracy: 0.7807 - val_loss: 0.6529 - val_accuracy: 0.7132\n",
            "Epoch 5/5\n",
            "20/20 [==============================] - 3s 160ms/step - loss: 0.4737 - accuracy: 0.7983 - val_loss: 0.6437 - val_accuracy: 0.7610\n",
            "0.000250729133655925 2.3699273830356193e-06\n",
            "Epoch 1/5\n",
            "39/39 [==============================] - 3s 83ms/step - loss: 0.4152 - accuracy: 0.8343 - val_loss: 0.6240 - val_accuracy: 0.7022\n",
            "Epoch 2/5\n",
            "39/39 [==============================] - 3s 81ms/step - loss: 0.2954 - accuracy: 0.8924 - val_loss: 0.5980 - val_accuracy: 0.7463\n",
            "Epoch 3/5\n",
            "39/39 [==============================] - 3s 79ms/step - loss: 0.2685 - accuracy: 0.8981 - val_loss: 0.5695 - val_accuracy: 0.7904\n",
            "Epoch 4/5\n",
            "39/39 [==============================] - 3s 81ms/step - loss: 0.2533 - accuracy: 0.9051 - val_loss: 0.5373 - val_accuracy: 0.8235\n",
            "Epoch 5/5\n",
            "39/39 [==============================] - 3s 80ms/step - loss: 0.2420 - accuracy: 0.9075 - val_loss: 0.5052 - val_accuracy: 0.8382\n",
            "8.023394282296846e-05 0.004670571021933619\n",
            "Epoch 1/5\n",
            "77/77 [==============================] - 3s 43ms/step - loss: 0.5264 - accuracy: 0.7733 - val_loss: 0.6410 - val_accuracy: 0.7279\n",
            "Epoch 2/5\n",
            "77/77 [==============================] - 3s 41ms/step - loss: 0.3925 - accuracy: 0.8580 - val_loss: 0.5904 - val_accuracy: 0.7610\n",
            "Epoch 3/5\n",
            "77/77 [==============================] - 3s 42ms/step - loss: 0.3525 - accuracy: 0.8818 - val_loss: 0.5420 - val_accuracy: 0.7684\n",
            "Epoch 4/5\n",
            "77/77 [==============================] - 3s 41ms/step - loss: 0.3280 - accuracy: 0.8883 - val_loss: 0.4802 - val_accuracy: 0.8162\n",
            "Epoch 5/5\n",
            "77/77 [==============================] - 3s 42ms/step - loss: 0.3104 - accuracy: 0.8977 - val_loss: 0.4337 - val_accuracy: 0.8346\n",
            "2.311631129525599e-05 2.601557147943356e-06\n",
            "Epoch 1/5\n",
            "77/77 [==============================] - 3s 44ms/step - loss: 0.5866 - accuracy: 0.7005 - val_loss: 0.6449 - val_accuracy: 0.7794\n",
            "Epoch 2/5\n",
            "77/77 [==============================] - 3s 41ms/step - loss: 0.3947 - accuracy: 0.8527 - val_loss: 0.6051 - val_accuracy: 0.8493\n",
            "Epoch 3/5\n",
            "77/77 [==============================] - 3s 40ms/step - loss: 0.3526 - accuracy: 0.8711 - val_loss: 0.5567 - val_accuracy: 0.8603\n",
            "Epoch 4/5\n",
            "77/77 [==============================] - 3s 42ms/step - loss: 0.3409 - accuracy: 0.8715 - val_loss: 0.5005 - val_accuracy: 0.8787\n",
            "Epoch 5/5\n",
            "77/77 [==============================] - 3s 42ms/step - loss: 0.3224 - accuracy: 0.8752 - val_loss: 0.4379 - val_accuracy: 0.8934\n",
            "1.1349173945652652e-06 0.004377499320516001\n",
            "Epoch 1/5\n",
            "20/20 [==============================] - 3s 160ms/step - loss: 0.7321 - accuracy: 0.5970 - val_loss: 0.7237 - val_accuracy: 0.4743\n",
            "Epoch 2/5\n",
            "20/20 [==============================] - 3s 151ms/step - loss: 0.7203 - accuracy: 0.5957 - val_loss: 0.7237 - val_accuracy: 0.4743\n",
            "Epoch 3/5\n",
            "20/20 [==============================] - 3s 154ms/step - loss: 0.7240 - accuracy: 0.6068 - val_loss: 0.7237 - val_accuracy: 0.5147\n",
            "Epoch 4/5\n",
            "20/20 [==============================] - 3s 152ms/step - loss: 0.7186 - accuracy: 0.6117 - val_loss: 0.7237 - val_accuracy: 0.4963\n",
            "Epoch 5/5\n",
            "20/20 [==============================] - 3s 154ms/step - loss: 0.7225 - accuracy: 0.6174 - val_loss: 0.7236 - val_accuracy: 0.4816\n",
            "0.0001218012712025221 1.3091588421130015e-06\n",
            "Epoch 1/5\n",
            "39/39 [==============================] - 3s 82ms/step - loss: 0.5485 - accuracy: 0.7443 - val_loss: 0.6346 - val_accuracy: 0.6691\n",
            "Epoch 2/5\n",
            "39/39 [==============================] - 3s 78ms/step - loss: 0.4021 - accuracy: 0.8404 - val_loss: 0.6052 - val_accuracy: 0.7059\n",
            "Epoch 3/5\n",
            "39/39 [==============================] - 3s 76ms/step - loss: 0.3628 - accuracy: 0.8629 - val_loss: 0.5783 - val_accuracy: 0.7574\n",
            "Epoch 4/5\n",
            "39/39 [==============================] - 3s 76ms/step - loss: 0.3332 - accuracy: 0.8760 - val_loss: 0.5492 - val_accuracy: 0.7831\n",
            "Epoch 5/5\n",
            "39/39 [==============================] - 3s 76ms/step - loss: 0.3110 - accuracy: 0.8830 - val_loss: 0.5189 - val_accuracy: 0.7904\n",
            "0.00018776410273205356 2.2677019006256536e-05\n",
            "Epoch 1/5\n",
            "20/20 [==============================] - 3s 158ms/step - loss: 0.4822 - accuracy: 0.7893 - val_loss: 0.6362 - val_accuracy: 0.6507\n",
            "Epoch 2/5\n",
            "20/20 [==============================] - 3s 151ms/step - loss: 0.3587 - accuracy: 0.8801 - val_loss: 0.6202 - val_accuracy: 0.6654\n",
            "Epoch 3/5\n",
            "20/20 [==============================] - 3s 150ms/step - loss: 0.3188 - accuracy: 0.8822 - val_loss: 0.6052 - val_accuracy: 0.6985\n",
            "Epoch 4/5\n",
            "20/20 [==============================] - 3s 150ms/step - loss: 0.3047 - accuracy: 0.8903 - val_loss: 0.5916 - val_accuracy: 0.7316\n",
            "Epoch 5/5\n",
            "20/20 [==============================] - 3s 151ms/step - loss: 0.2919 - accuracy: 0.8928 - val_loss: 0.5756 - val_accuracy: 0.7537\n",
            "0.0009890448647124938 0.003222156009929326\n",
            "Epoch 1/5\n",
            "39/39 [==============================] - 3s 80ms/step - loss: 0.3988 - accuracy: 0.8564 - val_loss: 0.6372 - val_accuracy: 0.6507\n",
            "Epoch 2/5\n",
            "39/39 [==============================] - 3s 76ms/step - loss: 0.3098 - accuracy: 0.8822 - val_loss: 0.5620 - val_accuracy: 0.9228\n",
            "Epoch 3/5\n",
            "39/39 [==============================] - 3s 77ms/step - loss: 0.2524 - accuracy: 0.9059 - val_loss: 0.5247 - val_accuracy: 0.9191\n",
            "Epoch 4/5\n",
            "39/39 [==============================] - 3s 77ms/step - loss: 0.2411 - accuracy: 0.9149 - val_loss: 0.4944 - val_accuracy: 0.8750\n",
            "Epoch 5/5\n",
            "39/39 [==============================] - 3s 77ms/step - loss: 0.2276 - accuracy: 0.9190 - val_loss: 0.4672 - val_accuracy: 0.9228\n",
            "5.7817780834048555e-05 0.0037726926585739764\n",
            "Epoch 1/5\n",
            "77/77 [==============================] - 3s 43ms/step - loss: 0.5179 - accuracy: 0.7897 - val_loss: 0.6512 - val_accuracy: 0.8051\n",
            "Epoch 2/5\n",
            "77/77 [==============================] - 3s 40ms/step - loss: 0.3995 - accuracy: 0.8650 - val_loss: 0.6043 - val_accuracy: 0.8566\n",
            "Epoch 3/5\n",
            "77/77 [==============================] - 3s 40ms/step - loss: 0.3656 - accuracy: 0.8797 - val_loss: 0.5501 - val_accuracy: 0.8676\n",
            "Epoch 4/5\n",
            "77/77 [==============================] - 3s 39ms/step - loss: 0.3422 - accuracy: 0.8834 - val_loss: 0.4876 - val_accuracy: 0.8640\n",
            "Epoch 5/5\n",
            "77/77 [==============================] - 3s 40ms/step - loss: 0.3259 - accuracy: 0.8953 - val_loss: 0.4249 - val_accuracy: 0.8713\n",
            "0.0003645215035864487 2.039730365603027e-05\n",
            "Epoch 1/5\n",
            "20/20 [==============================] - 3s 163ms/step - loss: 0.4221 - accuracy: 0.8187 - val_loss: 0.6245 - val_accuracy: 0.6103\n",
            "Epoch 2/5\n",
            "20/20 [==============================] - 3s 152ms/step - loss: 0.3175 - accuracy: 0.8777 - val_loss: 0.6177 - val_accuracy: 0.6324\n",
            "Epoch 3/5\n",
            "20/20 [==============================] - 3s 152ms/step - loss: 0.2758 - accuracy: 0.8969 - val_loss: 0.5932 - val_accuracy: 0.6912\n",
            "Epoch 4/5\n",
            "20/20 [==============================] - 3s 153ms/step - loss: 0.2699 - accuracy: 0.8993 - val_loss: 0.5732 - val_accuracy: 0.7206\n",
            "Epoch 5/5\n",
            "20/20 [==============================] - 3s 148ms/step - loss: 0.2546 - accuracy: 0.9002 - val_loss: 0.5634 - val_accuracy: 0.7206\n",
            "4.546912032220063e-05 0.00019033225935539196\n",
            "Epoch 1/5\n",
            "20/20 [==============================] - 3s 162ms/step - loss: 0.7224 - accuracy: 0.5524 - val_loss: 0.6824 - val_accuracy: 0.5993\n",
            "Epoch 2/5\n",
            "20/20 [==============================] - 3s 152ms/step - loss: 0.5200 - accuracy: 0.7574 - val_loss: 0.6681 - val_accuracy: 0.6618\n",
            "Epoch 3/5\n",
            "20/20 [==============================] - 3s 153ms/step - loss: 0.4652 - accuracy: 0.8126 - val_loss: 0.6571 - val_accuracy: 0.6985\n",
            "Epoch 4/5\n",
            "20/20 [==============================] - 3s 153ms/step - loss: 0.4051 - accuracy: 0.8322 - val_loss: 0.6465 - val_accuracy: 0.7316\n",
            "Epoch 5/5\n",
            "20/20 [==============================] - 3s 153ms/step - loss: 0.3937 - accuracy: 0.8490 - val_loss: 0.6366 - val_accuracy: 0.7610\n",
            "2.929497566241169e-06 0.00026439542103303505\n",
            "Epoch 1/5\n",
            "20/20 [==============================] - 5s 261ms/step - loss: 0.5492 - accuracy: 0.7565 - val_loss: 0.6767 - val_accuracy: 0.5809\n",
            "Epoch 2/5\n",
            "20/20 [==============================] - 5s 248ms/step - loss: 0.5207 - accuracy: 0.7660 - val_loss: 0.6730 - val_accuracy: 0.6213\n",
            "Epoch 3/5\n",
            "20/20 [==============================] - 4s 178ms/step - loss: 0.5169 - accuracy: 0.7696 - val_loss: 0.6690 - val_accuracy: 0.6397\n",
            "Epoch 4/5\n",
            "20/20 [==============================] - 3s 149ms/step - loss: 0.5089 - accuracy: 0.7774 - val_loss: 0.6647 - val_accuracy: 0.6618\n",
            "Epoch 5/5\n",
            "20/20 [==============================] - 3s 151ms/step - loss: 0.5004 - accuracy: 0.7791 - val_loss: 0.6599 - val_accuracy: 0.6654\n",
            "1.0118028860313238e-05 4.0475508385374056e-05\n",
            "Epoch 1/5\n",
            "77/77 [==============================] - 3s 41ms/step - loss: 0.6303 - accuracy: 0.6608 - val_loss: 0.6586 - val_accuracy: 0.6801\n",
            "Epoch 2/5\n",
            "77/77 [==============================] - 3s 39ms/step - loss: 0.4933 - accuracy: 0.7754 - val_loss: 0.6256 - val_accuracy: 0.7243\n",
            "Epoch 3/5\n",
            "77/77 [==============================] - 3s 40ms/step - loss: 0.4537 - accuracy: 0.7975 - val_loss: 0.5860 - val_accuracy: 0.7426\n",
            "Epoch 4/5\n",
            "77/77 [==============================] - 3s 40ms/step - loss: 0.4253 - accuracy: 0.8151 - val_loss: 0.5412 - val_accuracy: 0.7537\n",
            "Epoch 5/5\n",
            "77/77 [==============================] - 3s 40ms/step - loss: 0.4168 - accuracy: 0.8269 - val_loss: 0.4961 - val_accuracy: 0.7647\n",
            "1.1634945888337395e-05 1.3439360084043854e-05\n",
            "Epoch 1/5\n",
            "77/77 [==============================] - 3s 41ms/step - loss: 0.6823 - accuracy: 0.6510 - val_loss: 0.6696 - val_accuracy: 0.6507\n",
            "Epoch 2/5\n",
            "77/77 [==============================] - 3s 39ms/step - loss: 0.5559 - accuracy: 0.7512 - val_loss: 0.6393 - val_accuracy: 0.6912\n",
            "Epoch 3/5\n",
            "77/77 [==============================] - 3s 40ms/step - loss: 0.4976 - accuracy: 0.7782 - val_loss: 0.6035 - val_accuracy: 0.7059\n",
            "Epoch 4/5\n",
            "77/77 [==============================] - 3s 39ms/step - loss: 0.4672 - accuracy: 0.7999 - val_loss: 0.5642 - val_accuracy: 0.7206\n",
            "Epoch 5/5\n",
            "77/77 [==============================] - 3s 39ms/step - loss: 0.4380 - accuracy: 0.8196 - val_loss: 0.5242 - val_accuracy: 0.7426\n",
            "0.0001362991336823048 0.0002357148409080934\n",
            "Epoch 1/5\n",
            "39/39 [==============================] - 3s 80ms/step - loss: 0.4657 - accuracy: 0.8200 - val_loss: 0.6477 - val_accuracy: 0.7096\n",
            "Epoch 2/5\n",
            "39/39 [==============================] - 3s 75ms/step - loss: 0.3678 - accuracy: 0.8834 - val_loss: 0.6243 - val_accuracy: 0.7610\n",
            "Epoch 3/5\n",
            "39/39 [==============================] - 3s 76ms/step - loss: 0.3537 - accuracy: 0.8846 - val_loss: 0.6030 - val_accuracy: 0.7794\n",
            "Epoch 4/5\n",
            "39/39 [==============================] - 3s 77ms/step - loss: 0.3396 - accuracy: 0.8912 - val_loss: 0.5801 - val_accuracy: 0.8015\n",
            "Epoch 5/5\n",
            "39/39 [==============================] - 3s 75ms/step - loss: 0.3222 - accuracy: 0.8895 - val_loss: 0.5555 - val_accuracy: 0.8088\n",
            "0.0005384135346447607 0.005462457637452986\n",
            "Epoch 1/5\n",
            "39/39 [==============================] - 3s 81ms/step - loss: 0.4342 - accuracy: 0.8204 - val_loss: 0.6325 - val_accuracy: 0.7904\n",
            "Epoch 2/5\n",
            "39/39 [==============================] - 3s 76ms/step - loss: 0.3078 - accuracy: 0.8981 - val_loss: 0.6005 - val_accuracy: 0.7831\n",
            "Epoch 3/5\n",
            "39/39 [==============================] - 3s 76ms/step - loss: 0.2813 - accuracy: 0.9092 - val_loss: 0.5643 - val_accuracy: 0.7868\n",
            "Epoch 4/5\n",
            "39/39 [==============================] - 3s 78ms/step - loss: 0.2735 - accuracy: 0.9104 - val_loss: 0.5364 - val_accuracy: 0.8125\n",
            "Epoch 5/5\n",
            "39/39 [==============================] - 3s 77ms/step - loss: 0.2714 - accuracy: 0.9186 - val_loss: 0.5005 - val_accuracy: 0.8382\n",
            "0.000988678032406174 4.095757791450617e-06\n",
            "Epoch 1/5\n",
            "39/39 [==============================] - 3s 82ms/step - loss: 0.3534 - accuracy: 0.8490 - val_loss: 0.5957 - val_accuracy: 0.7868\n",
            "Epoch 2/5\n",
            "39/39 [==============================] - 3s 77ms/step - loss: 0.2900 - accuracy: 0.8834 - val_loss: 0.5701 - val_accuracy: 0.8676\n",
            "Epoch 3/5\n",
            "39/39 [==============================] - 3s 78ms/step - loss: 0.2346 - accuracy: 0.9104 - val_loss: 0.5403 - val_accuracy: 0.8051\n",
            "Epoch 4/5\n",
            "39/39 [==============================] - 3s 77ms/step - loss: 0.2113 - accuracy: 0.9178 - val_loss: 0.5015 - val_accuracy: 0.8493\n",
            "Epoch 5/5\n",
            "39/39 [==============================] - 3s 78ms/step - loss: 0.1870 - accuracy: 0.9313 - val_loss: 0.4687 - val_accuracy: 0.8456\n",
            "0.00013968271604496477 0.00029892922656413765\n",
            "Epoch 1/5\n",
            "77/77 [==============================] - 3s 42ms/step - loss: 0.4302 - accuracy: 0.8232 - val_loss: 0.6153 - val_accuracy: 0.7279\n",
            "Epoch 2/5\n",
            "77/77 [==============================] - 3s 39ms/step - loss: 0.3353 - accuracy: 0.8764 - val_loss: 0.5645 - val_accuracy: 0.7978\n",
            "Epoch 3/5\n",
            "77/77 [==============================] - 3s 39ms/step - loss: 0.3063 - accuracy: 0.8903 - val_loss: 0.5132 - val_accuracy: 0.7978\n",
            "Epoch 4/5\n",
            "77/77 [==============================] - 3s 39ms/step - loss: 0.2782 - accuracy: 0.8969 - val_loss: 0.4408 - val_accuracy: 0.8529\n",
            "Epoch 5/5\n",
            "77/77 [==============================] - 3s 40ms/step - loss: 0.2629 - accuracy: 0.9034 - val_loss: 0.3827 - val_accuracy: 0.8603\n",
            "5.308751978323339e-06 0.000502896778918545\n",
            "Epoch 1/5\n",
            "20/20 [==============================] - 3s 161ms/step - loss: 0.7546 - accuracy: 0.6101 - val_loss: 0.6906 - val_accuracy: 0.5478\n",
            "Epoch 2/5\n",
            "20/20 [==============================] - 3s 153ms/step - loss: 0.7057 - accuracy: 0.6448 - val_loss: 0.6861 - val_accuracy: 0.5993\n",
            "Epoch 3/5\n",
            "20/20 [==============================] - 3s 151ms/step - loss: 0.6786 - accuracy: 0.6678 - val_loss: 0.6814 - val_accuracy: 0.6066\n",
            "Epoch 4/5\n",
            "20/20 [==============================] - 3s 153ms/step - loss: 0.6344 - accuracy: 0.6890 - val_loss: 0.6764 - val_accuracy: 0.5993\n",
            "Epoch 5/5\n",
            "20/20 [==============================] - 3s 152ms/step - loss: 0.6041 - accuracy: 0.7091 - val_loss: 0.6712 - val_accuracy: 0.6066\n",
            "3.0297644548852466e-06 0.0001319328551146752\n",
            "Epoch 1/5\n",
            "77/77 [==============================] - 3s 41ms/step - loss: 0.8445 - accuracy: 0.3993 - val_loss: 0.6833 - val_accuracy: 0.6544\n",
            "Epoch 2/5\n",
            "77/77 [==============================] - 3s 39ms/step - loss: 0.7036 - accuracy: 0.5806 - val_loss: 0.6672 - val_accuracy: 0.6949\n",
            "Epoch 3/5\n",
            "77/77 [==============================] - 3s 39ms/step - loss: 0.6187 - accuracy: 0.6784 - val_loss: 0.6447 - val_accuracy: 0.7059\n",
            "Epoch 4/5\n",
            "77/77 [==============================] - 3s 40ms/step - loss: 0.5700 - accuracy: 0.7201 - val_loss: 0.6154 - val_accuracy: 0.7279\n",
            "Epoch 5/5\n",
            "77/77 [==============================] - 3s 39ms/step - loss: 0.5319 - accuracy: 0.7557 - val_loss: 0.5804 - val_accuracy: 0.7610\n",
            "3.787486129100769e-05 5.54562818501587e-06\n",
            "Epoch 1/5\n",
            "39/39 [==============================] - 3s 81ms/step - loss: 0.5793 - accuracy: 0.7119 - val_loss: 0.6608 - val_accuracy: 0.6434\n",
            "Epoch 2/5\n",
            "39/39 [==============================] - 3s 78ms/step - loss: 0.4355 - accuracy: 0.8322 - val_loss: 0.6384 - val_accuracy: 0.7206\n",
            "Epoch 3/5\n",
            "39/39 [==============================] - 3s 77ms/step - loss: 0.3959 - accuracy: 0.8531 - val_loss: 0.6166 - val_accuracy: 0.7390\n",
            "Epoch 4/5\n",
            "39/39 [==============================] - 3s 77ms/step - loss: 0.3798 - accuracy: 0.8637 - val_loss: 0.5942 - val_accuracy: 0.7721\n",
            "Epoch 5/5\n",
            "39/39 [==============================] - 3s 77ms/step - loss: 0.3660 - accuracy: 0.8666 - val_loss: 0.5701 - val_accuracy: 0.7941\n",
            "5.959864312142834e-06 0.0013346708675077892\n",
            "Epoch 1/5\n",
            "20/20 [==============================] - 3s 159ms/step - loss: 0.7718 - accuracy: 0.6113 - val_loss: 0.6979 - val_accuracy: 0.5882\n",
            "Epoch 2/5\n",
            "20/20 [==============================] - 3s 150ms/step - loss: 0.6880 - accuracy: 0.6682 - val_loss: 0.6927 - val_accuracy: 0.6103\n",
            "Epoch 3/5\n",
            "20/20 [==============================] - 3s 150ms/step - loss: 0.6320 - accuracy: 0.7103 - val_loss: 0.6872 - val_accuracy: 0.6434\n",
            "Epoch 4/5\n",
            "20/20 [==============================] - 3s 152ms/step - loss: 0.5910 - accuracy: 0.7353 - val_loss: 0.6816 - val_accuracy: 0.6654\n",
            "Epoch 5/5\n",
            "20/20 [==============================] - 3s 152ms/step - loss: 0.5842 - accuracy: 0.7467 - val_loss: 0.6756 - val_accuracy: 0.6654\n",
            "0.0005819827586770385 8.861212635506938e-05\n",
            "Epoch 1/5\n",
            "39/39 [==============================] - 3s 80ms/step - loss: 0.3612 - accuracy: 0.8552 - val_loss: 0.6069 - val_accuracy: 0.8199\n",
            "Epoch 2/5\n",
            "39/39 [==============================] - 3s 76ms/step - loss: 0.2825 - accuracy: 0.8822 - val_loss: 0.5856 - val_accuracy: 0.9154\n",
            "Epoch 3/5\n",
            "39/39 [==============================] - 3s 76ms/step - loss: 0.2584 - accuracy: 0.8985 - val_loss: 0.5543 - val_accuracy: 0.8346\n",
            "Epoch 4/5\n",
            "39/39 [==============================] - 3s 78ms/step - loss: 0.2391 - accuracy: 0.9075 - val_loss: 0.5219 - val_accuracy: 0.8456\n",
            "Epoch 5/5\n",
            "39/39 [==============================] - 3s 78ms/step - loss: 0.2213 - accuracy: 0.9169 - val_loss: 0.4865 - val_accuracy: 0.8971\n",
            "0.0007309370844550731 3.036826417571738e-06\n",
            "Epoch 1/5\n",
            "77/77 [==============================] - 3s 42ms/step - loss: 0.3868 - accuracy: 0.8359 - val_loss: 0.5697 - val_accuracy: 0.7132\n",
            "Epoch 2/5\n",
            "77/77 [==============================] - 3s 39ms/step - loss: 0.2591 - accuracy: 0.8948 - val_loss: 0.4922 - val_accuracy: 0.8125\n",
            "Epoch 3/5\n",
            "77/77 [==============================] - 3s 39ms/step - loss: 0.2168 - accuracy: 0.9182 - val_loss: 0.4232 - val_accuracy: 0.8493\n",
            "Epoch 4/5\n",
            "77/77 [==============================] - 3s 39ms/step - loss: 0.1815 - accuracy: 0.9349 - val_loss: 0.3616 - val_accuracy: 0.9118\n",
            "Epoch 5/5\n",
            "77/77 [==============================] - 3s 39ms/step - loss: 0.1643 - accuracy: 0.9423 - val_loss: 0.3430 - val_accuracy: 0.8456\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kuFrOduLEJZp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "1f715137-6866-48dc-b773-b714fa7d1739"
      },
      "source": [
        "for i in range(100):\n",
        "  print('learning rate = ',lr_list[i],'regularization = ',reg_list[i],'batch_size = ',batch_list[i],'val_loss = ',val_loss[i],'val_acc = ',val_acc[i])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "learning rate =  1.8898016998022086e-06 regularization =  3.992904866907762e-06 batch_size =  64 val_loss =  0.6455645596279818 val_acc =  0.7095588445663452\n",
            "learning rate =  5.2903970618390755e-06 regularization =  0.00021102421646554262 batch_size =  32 val_loss =  0.5314821390544667 val_acc =  0.7941176295280457\n",
            "learning rate =  0.0005591712028316839 regularization =  0.00019822251481817741 batch_size =  128 val_loss =  0.5800658008631538 val_acc =  0.7757353186607361\n",
            "learning rate =  1.0250306811939426e-05 regularization =  3.2936980699089447e-06 batch_size =  128 val_loss =  0.6622513672884773 val_acc =  0.7022058963775635\n",
            "learning rate =  0.0005945193822826684 regularization =  0.0021324263714795973 batch_size =  64 val_loss =  0.5159362344180837 val_acc =  0.8786764740943909\n",
            "learning rate =  9.117349644590024e-06 regularization =  0.0014741861344500142 batch_size =  64 val_loss =  0.6247115836423986 val_acc =  0.7389705777168274\n",
            "learning rate =  7.099113978525928e-05 regularization =  1.163591207319732e-05 batch_size =  128 val_loss =  0.6073970899862402 val_acc =  0.7463235259056091\n",
            "learning rate =  2.043818937958818e-06 regularization =  1.7393678768865614e-06 batch_size =  32 val_loss =  0.6361416683477514 val_acc =  0.6764705777168274\n",
            "learning rate =  2.218086001210683e-06 regularization =  7.303696810720234e-05 batch_size =  128 val_loss =  0.6867158132440904 val_acc =  0.5404411554336548\n",
            "learning rate =  6.872938386606285e-05 regularization =  5.715722292671221e-06 batch_size =  128 val_loss =  0.6186472528121051 val_acc =  0.8051470518112183\n",
            "learning rate =  0.0005392361986559832 regularization =  4.690984478614728e-05 batch_size =  32 val_loss =  0.30117834140272703 val_acc =  0.9117646813392639\n",
            "learning rate =  4.865500379965463e-06 regularization =  0.005132605062355772 batch_size =  32 val_loss =  0.5915603567572201 val_acc =  0.8014705777168274\n",
            "learning rate =  0.00037154228289365304 regularization =  0.0001489882237442482 batch_size =  64 val_loss =  0.47323625929215374 val_acc =  0.8088235259056091\n",
            "learning rate =  0.00023064186770426138 regularization =  0.0004171602956692113 batch_size =  128 val_loss =  0.6002425761783824 val_acc =  0.7352941036224365\n",
            "learning rate =  8.579807634560692e-06 regularization =  0.006314580863531755 batch_size =  32 val_loss =  0.5193910388385549 val_acc =  0.8602941036224365\n",
            "learning rate =  6.900677677118593e-06 regularization =  0.00017045346751647862 batch_size =  32 val_loss =  0.5124025660402635 val_acc =  0.8014705777168274\n",
            "learning rate =  0.00018968131442836583 regularization =  2.8844031523885113e-05 batch_size =  32 val_loss =  0.37184417598387776 val_acc =  0.845588207244873\n",
            "learning rate =  0.00018455900617092235 regularization =  4.237142420529752e-06 batch_size =  128 val_loss =  0.5909899964052088 val_acc =  0.7573529481887817\n",
            "learning rate =  1.6787148553873555e-05 regularization =  0.00026548632080084937 batch_size =  32 val_loss =  0.4571033873978783 val_acc =  0.8713235259056091\n",
            "learning rate =  4.767148951643905e-05 regularization =  0.0009721297589022327 batch_size =  32 val_loss =  0.39584393185727734 val_acc =  0.8676470518112183\n",
            "learning rate =  1.8353717717706293e-05 regularization =  8.173386526746356e-06 batch_size =  32 val_loss =  0.4659067427410799 val_acc =  0.8272058963775635\n",
            "learning rate =  1.8765448633038126e-05 regularization =  0.0037533547911942993 batch_size =  128 val_loss =  0.6635739242329317 val_acc =  0.75\n",
            "learning rate =  1.0179010096499476e-06 regularization =  5.16589027983451e-05 batch_size =  64 val_loss =  0.6605063466464772 val_acc =  0.720588207244873\n",
            "learning rate =  0.0007418477644251722 regularization =  0.0004192533366127941 batch_size =  32 val_loss =  0.2873818050412571 val_acc =  0.9448529481887817\n",
            "learning rate =  1.5838909515742908e-05 regularization =  1.2834167177850342e-06 batch_size =  32 val_loss =  0.4844074985560249 val_acc =  0.8125\n",
            "learning rate =  0.00029142619349389605 regularization =  0.0018442248165944763 batch_size =  32 val_loss =  0.38743316601304445 val_acc =  0.8308823704719543\n",
            "learning rate =  6.241537156603125e-06 regularization =  0.0016386274359413652 batch_size =  32 val_loss =  0.5459747630007127 val_acc =  0.7573529481887817\n",
            "learning rate =  1.016355823977235e-06 regularization =  6.640941781571168e-05 batch_size =  128 val_loss =  0.6685865836984971 val_acc =  0.6727941036224365\n",
            "learning rate =  7.760358503821004e-06 regularization =  0.0004168057705258193 batch_size =  128 val_loss =  0.6519995349294999 val_acc =  0.6507353186607361\n",
            "learning rate =  8.317167059446469e-05 regularization =  5.629076513780854e-06 batch_size =  64 val_loss =  0.5555612655246959 val_acc =  0.8639705777168274\n",
            "learning rate =  1.3751784967794424e-06 regularization =  1.0017813523262212e-06 batch_size =  64 val_loss =  0.6671066669856801 val_acc =  0.6433823704719543\n",
            "learning rate =  0.0001743103835235868 regularization =  0.002260304550024058 batch_size =  64 val_loss =  0.5083075656610376 val_acc =  0.8088235259056091\n",
            "learning rate =  6.644192032985693e-05 regularization =  0.0002464510570087266 batch_size =  128 val_loss =  0.6260096886578728 val_acc =  0.6948529481887817\n",
            "learning rate =  1.3347205161341342e-06 regularization =  1.7134130792760725e-06 batch_size =  64 val_loss =  0.654383427956525 val_acc =  0.6801470518112183\n",
            "learning rate =  5.599046542170087e-05 regularization =  0.001738843303299553 batch_size =  32 val_loss =  0.3979504020775066 val_acc =  0.8823529481887817\n",
            "learning rate =  0.00020705548524343537 regularization =  3.9955510849050025e-05 batch_size =  64 val_loss =  0.5158456669134253 val_acc =  0.8125\n",
            "learning rate =  0.0009126464837823222 regularization =  5.1680081047070015e-06 batch_size =  128 val_loss =  0.5420630118426155 val_acc =  0.8088235259056091\n",
            "learning rate =  1.9231311642723086e-06 regularization =  3.26947242483865e-06 batch_size =  64 val_loss =  0.6840896115583532 val_acc =  0.5404411554336548\n",
            "learning rate =  2.716526163094731e-06 regularization =  1.0686751870573723e-05 batch_size =  32 val_loss =  0.5726857781410217 val_acc =  0.7022058963775635\n",
            "learning rate =  4.514942025568668e-06 regularization =  0.0004746684722307846 batch_size =  128 val_loss =  0.659178663702572 val_acc =  0.716911792755127\n",
            "learning rate =  0.00020853430847723417 regularization =  0.0012946183310620445 batch_size =  32 val_loss =  0.35943519367891197 val_acc =  0.8933823704719543\n",
            "learning rate =  0.0001208949312030794 regularization =  0.00023619103180488258 batch_size =  64 val_loss =  0.5248175333527958 val_acc =  0.8198529481887817\n",
            "learning rate =  1.0255324999229498e-06 regularization =  0.007296803757829498 batch_size =  32 val_loss =  0.7161648343591129 val_acc =  0.6029411554336548\n",
            "learning rate =  5.939561361707228e-05 regularization =  6.446324385756203e-05 batch_size =  64 val_loss =  0.5330076533205369 val_acc =  0.783088207244873\n",
            "learning rate =  4.180486388927058e-06 regularization =  1.87727411240086e-06 batch_size =  64 val_loss =  0.6672488731496474 val_acc =  0.658088207244873\n",
            "learning rate =  9.208208215414841e-05 regularization =  3.3440441811017e-05 batch_size =  128 val_loss =  0.5939347673864925 val_acc =  0.7352941036224365\n",
            "learning rate =  1.9842174452004733e-06 regularization =  3.6420568656624936e-05 batch_size =  64 val_loss =  0.6699281895861906 val_acc =  0.654411792755127\n",
            "learning rate =  0.00012968363029852335 regularization =  0.00010040746079293375 batch_size =  64 val_loss =  0.5434651970863342 val_acc =  0.8492646813392639\n",
            "learning rate =  0.00035067451469899006 regularization =  0.00021455742937212145 batch_size =  64 val_loss =  0.4939078408129075 val_acc =  0.8198529481887817\n",
            "learning rate =  3.701995912579923e-05 regularization =  7.483171094236089e-06 batch_size =  128 val_loss =  0.6078060865402222 val_acc =  0.783088207244873\n",
            "learning rate =  0.0006788908614458456 regularization =  9.842546192197756e-05 batch_size =  64 val_loss =  0.4938819653847638 val_acc =  0.8676470518112183\n",
            "learning rate =  7.746379780030956e-06 regularization =  1.9572990585902495e-05 batch_size =  64 val_loss =  0.6303424169035519 val_acc =  0.7389705777168274\n",
            "learning rate =  1.0789604412675677e-05 regularization =  0.00011005340240660181 batch_size =  128 val_loss =  0.6614723030258628 val_acc =  0.7058823704719543\n",
            "learning rate =  4.9696746098166505e-06 regularization =  0.002515496610476109 batch_size =  32 val_loss =  0.5592205980244804 val_acc =  0.720588207244873\n",
            "learning rate =  1.4113954529602067e-06 regularization =  1.7593715640404441e-06 batch_size =  32 val_loss =  0.6008115551050972 val_acc =  0.716911792755127\n",
            "learning rate =  0.0002458239046118962 regularization =  0.0004545158699776079 batch_size =  64 val_loss =  0.5062172342749203 val_acc =  0.8860294222831726\n",
            "learning rate =  0.00047130778613061586 regularization =  4.541808883668654e-05 batch_size =  128 val_loss =  0.5662785347770242 val_acc =  0.7573529481887817\n",
            "learning rate =  1.5756473466188845e-05 regularization =  5.7500594454063475e-06 batch_size =  128 val_loss =  0.6445746456875521 val_acc =  0.6838235259056091\n",
            "learning rate =  0.0006959157919087281 regularization =  2.755448752439067e-06 batch_size =  32 val_loss =  0.3067505412241992 val_acc =  0.8713235259056091\n",
            "learning rate =  0.0005148184461001097 regularization =  0.004094689998317514 batch_size =  128 val_loss =  0.5845885114634738 val_acc =  0.7683823704719543\n",
            "learning rate =  2.1071234330777313e-06 regularization =  0.002518758073075564 batch_size =  128 val_loss =  0.6937916901181725 val_acc =  0.6286764740943909\n",
            "learning rate =  3.290349031539987e-05 regularization =  0.0002923310075442375 batch_size =  128 val_loss =  0.6280005223610822 val_acc =  0.6911764740943909\n",
            "learning rate =  3.342992512365823e-05 regularization =  1.517920907506151e-06 batch_size =  128 val_loss =  0.6244184830609489 val_acc =  0.7352941036224365\n",
            "learning rate =  8.786877590916243e-06 regularization =  9.699478381365175e-05 batch_size =  64 val_loss =  0.6051249433966244 val_acc =  0.7132353186607361\n",
            "learning rate =  7.5793629508896636e-06 regularization =  4.206369662083323e-06 batch_size =  32 val_loss =  0.5239385787178489 val_acc =  0.7720588445663452\n",
            "learning rate =  2.6184541024193696e-06 regularization =  3.7941758407193356e-06 batch_size =  32 val_loss =  0.5592538381324095 val_acc =  0.7573529481887817\n",
            "learning rate =  0.00048660703782061964 regularization =  0.0009774175142747764 batch_size =  128 val_loss =  0.5656177050927106 val_acc =  0.7683823704719543\n",
            "learning rate =  0.00017078121193107835 regularization =  0.00019651412197069625 batch_size =  128 val_loss =  0.5873717420241412 val_acc =  0.8161764740943909\n",
            "learning rate =  4.6723160690760224e-05 regularization =  0.0002983578405376808 batch_size =  64 val_loss =  0.5500820033690509 val_acc =  0.8235294222831726\n",
            "learning rate =  4.350588624493494e-06 regularization =  5.5822034195761655e-05 batch_size =  32 val_loss =  0.5483192731352413 val_acc =  0.7867646813392639\n",
            "learning rate =  0.00036458142442429096 regularization =  3.080590303658148e-05 batch_size =  64 val_loss =  0.5187055117943707 val_acc =  0.904411792755127\n",
            "learning rate =  2.1047940040696096e-05 regularization =  0.0001300788118102566 batch_size =  32 val_loss =  0.4613388776779175 val_acc =  0.8125\n",
            "learning rate =  5.850269698335309e-05 regularization =  8.224768897944637e-05 batch_size =  32 val_loss =  0.3876697929466472 val_acc =  0.8860294222831726\n",
            "learning rate =  4.628855557945946e-06 regularization =  2.471826160057653e-05 batch_size =  128 val_loss =  0.6548444593653959 val_acc =  0.7610294222831726\n",
            "learning rate =  2.867378833668252e-06 regularization =  0.0005329282449490426 batch_size =  64 val_loss =  0.6395154981052175 val_acc =  0.7022058963775635\n",
            "learning rate =  0.00088372721454196 regularization =  1.2162503464797059e-06 batch_size =  128 val_loss =  0.5458809523021474 val_acc =  0.8602941036224365\n",
            "learning rate =  1.534966645215634e-05 regularization =  0.0003138536978721347 batch_size =  128 val_loss =  0.6436778903007507 val_acc =  0.7610294222831726\n",
            "learning rate =  0.000250729133655925 regularization =  2.3699273830356193e-06 batch_size =  64 val_loss =  0.505178318304174 val_acc =  0.8382353186607361\n",
            "learning rate =  8.023394282296846e-05 regularization =  0.004670571021933619 batch_size =  32 val_loss =  0.4337146106888266 val_acc =  0.8345588445663452\n",
            "learning rate =  2.311631129525599e-05 regularization =  2.601557147943356e-06 batch_size =  32 val_loss =  0.4378911887898165 val_acc =  0.8933823704719543\n",
            "learning rate =  1.1349173945652652e-06 regularization =  0.004377499320516001 batch_size =  128 val_loss =  0.72358918540618 val_acc =  0.48161765933036804\n",
            "learning rate =  0.0001218012712025221 regularization =  1.3091588421130015e-06 batch_size =  64 val_loss =  0.5189147381221547 val_acc =  0.7904411554336548\n",
            "learning rate =  0.00018776410273205356 regularization =  2.2677019006256536e-05 batch_size =  128 val_loss =  0.5756459902314579 val_acc =  0.7536764740943909\n",
            "learning rate =  0.0009890448647124938 regularization =  0.003222156009929326 batch_size =  64 val_loss =  0.4672105557778302 val_acc =  0.9227941036224365\n",
            "learning rate =  5.7817780834048555e-05 regularization =  0.0037726926585739764 batch_size =  32 val_loss =  0.42493125796318054 val_acc =  0.8713235259056091\n",
            "learning rate =  0.0003645215035864487 regularization =  2.039730365603027e-05 batch_size =  128 val_loss =  0.5633843681391548 val_acc =  0.720588207244873\n",
            "learning rate =  4.546912032220063e-05 regularization =  0.00019033225935539196 batch_size =  128 val_loss =  0.6366143016254201 val_acc =  0.7610294222831726\n",
            "learning rate =  2.929497566241169e-06 regularization =  0.00026439542103303505 batch_size =  128 val_loss =  0.6599110925898832 val_acc =  0.6654411554336548\n",
            "learning rate =  1.0118028860313238e-05 regularization =  4.0475508385374056e-05 batch_size =  32 val_loss =  0.4960807071012609 val_acc =  0.7647058963775635\n",
            "learning rate =  1.1634945888337395e-05 regularization =  1.3439360084043854e-05 batch_size =  32 val_loss =  0.5242110666106728 val_acc =  0.7426470518112183\n",
            "learning rate =  0.0001362991336823048 regularization =  0.0002357148409080934 batch_size =  64 val_loss =  0.555458128452301 val_acc =  0.8088235259056091\n",
            "learning rate =  0.0005384135346447607 regularization =  0.005462457637452986 batch_size =  64 val_loss =  0.5004994904293734 val_acc =  0.8382353186607361\n",
            "learning rate =  0.000988678032406174 regularization =  4.095757791450617e-06 batch_size =  64 val_loss =  0.46866078236523795 val_acc =  0.845588207244873\n",
            "learning rate =  0.00013968271604496477 regularization =  0.00029892922656413765 batch_size =  32 val_loss =  0.38268614516538735 val_acc =  0.8602941036224365\n",
            "learning rate =  5.308751978323339e-06 regularization =  0.000502896778918545 batch_size =  128 val_loss =  0.6712136198492611 val_acc =  0.6066176295280457\n",
            "learning rate =  3.0297644548852466e-06 regularization =  0.0001319328551146752 batch_size =  32 val_loss =  0.5804422708118663 val_acc =  0.7610294222831726\n",
            "learning rate =  3.787486129100769e-05 regularization =  5.54562818501587e-06 batch_size =  64 val_loss =  0.5700535458676955 val_acc =  0.7941176295280457\n",
            "learning rate =  5.959864312142834e-06 regularization =  0.0013346708675077892 batch_size =  128 val_loss =  0.6756478898665484 val_acc =  0.6654411554336548\n",
            "learning rate =  0.0005819827586770385 regularization =  8.861212635506938e-05 batch_size =  64 val_loss =  0.48651743285796223 val_acc =  0.8970588445663452\n",
            "learning rate =  0.0007309370844550731 regularization =  3.036826417571738e-06 batch_size =  32 val_loss =  0.3430080729372361 val_acc =  0.845588207244873\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5eU8kfPcEmaU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "59a56aa7-5915-4c5e-9cc6-84dd8c11e47d"
      },
      "source": [
        "i = np.argmin(val_loss)\n",
        "lr = lr_list[i]\n",
        "reg = reg_list[i]\n",
        "batch_size = batch_list[i]\n",
        "print('learning rate = ',lr_list[i],'regularization = ',reg_list[i],'batch_size = ',batch_list[i],'val_loss = ',val_loss[i],'val_acc = ',val_acc[i])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "learning rate =  0.0007418477644251722 regularization =  0.0004192533366127941 batch_size =  32 val_loss =  0.2873818050412571 val_acc =  0.9448529481887817\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "45tck6pgEUjj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 697
        },
        "outputId": "b4dfba01-f00e-4c22-e8ea-9ca9682365df"
      },
      "source": [
        "epochs = 20\n",
        "weight_decay = reg\n",
        "model = Sequential()\n",
        "model.add(Dense(50,input_shape=x_train.shape[1:],kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Flatten())\n",
        "\n",
        "model.add(Dense(num_classes))\n",
        "model.add(Activation('softmax'))\n",
        "\n",
        "opt = keras.optimizers.SGD(learning_rate=lr)\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=opt,\n",
        "              metrics=['accuracy'])\n",
        "history = model.fit_generator(datagen.flow(x_train, y_train,\n",
        "                                batch_size=batch_size),\n",
        "                  epochs=epochs,\n",
        "                  validation_data=(x_test, y_test),\n",
        "                  workers=4)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "77/77 [==============================] - 3s 41ms/step - loss: 0.3452 - accuracy: 0.8637 - val_loss: 0.5713 - val_accuracy: 0.8235\n",
            "Epoch 2/20\n",
            "77/77 [==============================] - 3s 39ms/step - loss: 0.2531 - accuracy: 0.9018 - val_loss: 0.5198 - val_accuracy: 0.8824\n",
            "Epoch 3/20\n",
            "77/77 [==============================] - 3s 39ms/step - loss: 0.2141 - accuracy: 0.9231 - val_loss: 0.4665 - val_accuracy: 0.9044\n",
            "Epoch 4/20\n",
            "77/77 [==============================] - 3s 39ms/step - loss: 0.1982 - accuracy: 0.9239 - val_loss: 0.3601 - val_accuracy: 0.9081\n",
            "Epoch 5/20\n",
            "77/77 [==============================] - 3s 39ms/step - loss: 0.1775 - accuracy: 0.9415 - val_loss: 0.2937 - val_accuracy: 0.9265\n",
            "Epoch 6/20\n",
            "77/77 [==============================] - 3s 39ms/step - loss: 0.1615 - accuracy: 0.9448 - val_loss: 0.2557 - val_accuracy: 0.9265\n",
            "Epoch 7/20\n",
            "77/77 [==============================] - 3s 39ms/step - loss: 0.1431 - accuracy: 0.9509 - val_loss: 0.2150 - val_accuracy: 0.9301\n",
            "Epoch 8/20\n",
            "77/77 [==============================] - 3s 40ms/step - loss: 0.1361 - accuracy: 0.9521 - val_loss: 0.2012 - val_accuracy: 0.9191\n",
            "Epoch 9/20\n",
            "77/77 [==============================] - 3s 40ms/step - loss: 0.1190 - accuracy: 0.9619 - val_loss: 0.1825 - val_accuracy: 0.9338\n",
            "Epoch 10/20\n",
            "77/77 [==============================] - 3s 39ms/step - loss: 0.1094 - accuracy: 0.9636 - val_loss: 0.1859 - val_accuracy: 0.9301\n",
            "Epoch 11/20\n",
            "77/77 [==============================] - 3s 39ms/step - loss: 0.0998 - accuracy: 0.9714 - val_loss: 0.1754 - val_accuracy: 0.9338\n",
            "Epoch 12/20\n",
            "77/77 [==============================] - 3s 39ms/step - loss: 0.0945 - accuracy: 0.9742 - val_loss: 0.1726 - val_accuracy: 0.9265\n",
            "Epoch 13/20\n",
            "77/77 [==============================] - 3s 39ms/step - loss: 0.0840 - accuracy: 0.9734 - val_loss: 0.1659 - val_accuracy: 0.9301\n",
            "Epoch 14/20\n",
            "77/77 [==============================] - 3s 39ms/step - loss: 0.0794 - accuracy: 0.9763 - val_loss: 0.1631 - val_accuracy: 0.9338\n",
            "Epoch 15/20\n",
            "77/77 [==============================] - 3s 39ms/step - loss: 0.0687 - accuracy: 0.9820 - val_loss: 0.1645 - val_accuracy: 0.9301\n",
            "Epoch 16/20\n",
            "77/77 [==============================] - 3s 38ms/step - loss: 0.0663 - accuracy: 0.9820 - val_loss: 0.1570 - val_accuracy: 0.9301\n",
            "Epoch 17/20\n",
            "77/77 [==============================] - 3s 40ms/step - loss: 0.0619 - accuracy: 0.9832 - val_loss: 0.1541 - val_accuracy: 0.9412\n",
            "Epoch 18/20\n",
            "77/77 [==============================] - 3s 41ms/step - loss: 0.0607 - accuracy: 0.9853 - val_loss: 0.1529 - val_accuracy: 0.9375\n",
            "Epoch 19/20\n",
            "77/77 [==============================] - 3s 40ms/step - loss: 0.0567 - accuracy: 0.9849 - val_loss: 0.1496 - val_accuracy: 0.9449\n",
            "Epoch 20/20\n",
            "77/77 [==============================] - 3s 40ms/step - loss: 0.0526 - accuracy: 0.9849 - val_loss: 0.1533 - val_accuracy: 0.9375\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I7GnyltzExss",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "n,t,v,t1,v1 = history.epoch, history.history['accuracy'], history.history['val_accuracy'],history.history['loss'],history.history['val_loss']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kaIeOJF1Fil4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "0039cd84-f7b7-4e6c-8f7a-66780bdc0b43"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.figure(1)\n",
        "plt.plot(list(range(0,len(t))),t ,label='Training Accuracy')\n",
        "plt.figure(2)\n",
        "plt.plot(list(range(0,len(v))),v, label='Validation Accuracy')\n",
        "plt.figure(3)\n",
        "plt.plot(list(range(0,len(t1))),t1 ,label='Training Loss')\n",
        "plt.figure(4)\n",
        "plt.plot(list(range(0,len(v1))),v1, label='Validation Loss')\n",
        "plt.figure(1)\n",
        "\n",
        "legend = plt.legend(loc='lower right', shadow=True)\n",
        "plt.title(\"Training Accuracy: FaceData \")\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.savefig('TrainingaccuracyFaceData')\n",
        "plt.clf()\n",
        "\n",
        "plt.figure(2)\n",
        "\n",
        "legend = plt.legend(loc='lower right', shadow=True)\n",
        "plt.title(\"Validation Accuracy: FaceData \")\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.savefig('ValidationaccuracyFaceData')\n",
        "plt.clf()\n",
        "plt.figure(3)\n",
        "\n",
        "legend = plt.legend(loc='upper right', shadow=True)\n",
        "plt.title(\"Training Loss: FaceData \")\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.savefig('TraininglossFaceData')\n",
        "plt.clf()\n",
        "\n",
        "plt.figure(4)\n",
        "\n",
        "legend = plt.legend(loc='upper right', shadow=True)\n",
        "plt.title(\"Validation Loss: FaceData \")\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.savefig('ValidationlossFaceData')\n",
        "plt.clf()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6AeQ4zURRt-z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train = np.load(path+'x_train1.npy')\n",
        "y_train = np.load(path+'y_train1.npy')\n",
        "x_test = np.load(path+'x_test1.npy')\n",
        "y_test = np.load(path+'y_test1.npy')\n",
        "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mBjA48vqR3L0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "x_train /= 255\n",
        "x_test /= 255\n",
        "mean = np.mean(x_train,axis=(0,1,2,3))\n",
        "std = np.std(x_train,axis=(0,1,2,3))\n",
        "x_train = (x_train-mean)/(std+1e-7)\n",
        "x_test = (x_test-mean)/(std+1e-7)\n",
        "datagen = ImageDataGenerator(\n",
        "  )\n",
        "\n",
        "datagen.fit(x_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y_ipH-2rQtMJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 697
        },
        "outputId": "0b0084cf-75db-4960-dfc8-b270fda145d5"
      },
      "source": [
        "epochs = 20\n",
        "weight_decay = reg\n",
        "model = Sequential()\n",
        "model.add(Dense(50,input_shape=x_train.shape[1:],kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Flatten())\n",
        "\n",
        "model.add(Dense(num_classes))\n",
        "model.add(Activation('softmax'))\n",
        "\n",
        "opt = keras.optimizers.SGD(learning_rate=lr)\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=opt,\n",
        "              metrics=['accuracy'])\n",
        "history = model.fit_generator(datagen.flow(x_train, y_train,\n",
        "                                batch_size=batch_size),\n",
        "                  epochs=epochs,\n",
        "                  validation_data=(x_test, y_test),\n",
        "                  workers=4)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "77/77 [==============================] - 3s 42ms/step - loss: 0.3717 - accuracy: 0.8584 - val_loss: 0.4317 - val_accuracy: 0.9154\n",
            "Epoch 2/20\n",
            "77/77 [==============================] - 3s 40ms/step - loss: 0.2752 - accuracy: 0.8912 - val_loss: 0.3618 - val_accuracy: 0.9044\n",
            "Epoch 3/20\n",
            "77/77 [==============================] - 3s 40ms/step - loss: 0.2192 - accuracy: 0.9173 - val_loss: 0.3588 - val_accuracy: 0.8272\n",
            "Epoch 4/20\n",
            "77/77 [==============================] - 3s 40ms/step - loss: 0.1979 - accuracy: 0.9300 - val_loss: 0.3548 - val_accuracy: 0.8199\n",
            "Epoch 5/20\n",
            "77/77 [==============================] - 3s 40ms/step - loss: 0.1749 - accuracy: 0.9431 - val_loss: 0.2200 - val_accuracy: 0.9191\n",
            "Epoch 6/20\n",
            "77/77 [==============================] - 3s 40ms/step - loss: 0.1281 - accuracy: 0.9619 - val_loss: 0.2266 - val_accuracy: 0.9154\n",
            "Epoch 7/20\n",
            "77/77 [==============================] - 3s 41ms/step - loss: 0.1145 - accuracy: 0.9689 - val_loss: 0.2035 - val_accuracy: 0.9118\n",
            "Epoch 8/20\n",
            "77/77 [==============================] - 3s 40ms/step - loss: 0.1024 - accuracy: 0.9714 - val_loss: 0.1797 - val_accuracy: 0.9265\n",
            "Epoch 9/20\n",
            "77/77 [==============================] - 3s 39ms/step - loss: 0.0876 - accuracy: 0.9726 - val_loss: 0.1803 - val_accuracy: 0.9265\n",
            "Epoch 10/20\n",
            "77/77 [==============================] - 3s 40ms/step - loss: 0.0763 - accuracy: 0.9779 - val_loss: 0.1699 - val_accuracy: 0.9375\n",
            "Epoch 11/20\n",
            "77/77 [==============================] - 3s 40ms/step - loss: 0.0708 - accuracy: 0.9808 - val_loss: 0.1618 - val_accuracy: 0.9375\n",
            "Epoch 12/20\n",
            "77/77 [==============================] - 3s 41ms/step - loss: 0.0614 - accuracy: 0.9857 - val_loss: 0.1633 - val_accuracy: 0.9375\n",
            "Epoch 13/20\n",
            "77/77 [==============================] - 3s 40ms/step - loss: 0.0534 - accuracy: 0.9865 - val_loss: 0.1597 - val_accuracy: 0.9412\n",
            "Epoch 14/20\n",
            "77/77 [==============================] - 3s 40ms/step - loss: 0.0505 - accuracy: 0.9894 - val_loss: 0.1528 - val_accuracy: 0.9485\n",
            "Epoch 15/20\n",
            "77/77 [==============================] - 3s 41ms/step - loss: 0.0445 - accuracy: 0.9906 - val_loss: 0.1446 - val_accuracy: 0.9485\n",
            "Epoch 16/20\n",
            "77/77 [==============================] - 3s 40ms/step - loss: 0.0425 - accuracy: 0.9906 - val_loss: 0.1452 - val_accuracy: 0.9522\n",
            "Epoch 17/20\n",
            "77/77 [==============================] - 3s 40ms/step - loss: 0.0390 - accuracy: 0.9935 - val_loss: 0.1409 - val_accuracy: 0.9559\n",
            "Epoch 18/20\n",
            "77/77 [==============================] - 3s 40ms/step - loss: 0.0340 - accuracy: 0.9935 - val_loss: 0.1366 - val_accuracy: 0.9559\n",
            "Epoch 19/20\n",
            "77/77 [==============================] - 3s 41ms/step - loss: 0.0348 - accuracy: 0.9918 - val_loss: 0.1370 - val_accuracy: 0.9522\n",
            "Epoch 20/20\n",
            "77/77 [==============================] - 3s 42ms/step - loss: 0.0313 - accuracy: 0.9947 - val_loss: 0.1363 - val_accuracy: 0.9485\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6lJ0fzYVSAYJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train = np.load(path+'x_train1.npy')\n",
        "y_train = np.load(path+'y_train1.npy')\n",
        "x_test = np.load(path+'x_test1.npy')\n",
        "y_test = np.load(path+'y_test1.npy')\n",
        "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZYFaa8GFSCHZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "x_train /= 255\n",
        "x_test /= 255\n",
        "mean = np.mean(x_train,axis=(0,1,2,3))\n",
        "std = np.std(x_train,axis=(0,1,2,3))\n",
        "x_train = (x_train-mean)/(std+1e-7)\n",
        "x_test = (x_test-mean)/(std+1e-7)\n",
        "datagen = ImageDataGenerator(\n",
        "    rotation_range=8,  \n",
        "    width_shift_range=0.1,\n",
        "    height_shift_range=0.1,\n",
        "    fill_mode='nearest',\n",
        "    horizontal_flip=True, \n",
        "  )\n",
        "\n",
        "\n",
        "datagen.fit(x_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AUX6WjtMSGD2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 697
        },
        "outputId": "3165afd2-c320-4f11-a2c1-e6a3c9177d1e"
      },
      "source": [
        "epochs = 20\n",
        "weight_decay = reg\n",
        "model = Sequential()\n",
        "model.add(Dense(50,input_shape=x_train.shape[1:],kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Flatten())\n",
        "\n",
        "model.add(Dense(num_classes))\n",
        "model.add(Activation('softmax'))\n",
        "\n",
        "opt = keras.optimizers.SGD(learning_rate=lr)\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=opt,\n",
        "              metrics=['accuracy'])\n",
        "history = model.fit_generator(datagen.flow(x_train, y_train,\n",
        "                                batch_size=batch_size),\n",
        "                  epochs=epochs,\n",
        "                  validation_data=(x_test, y_test),\n",
        "                  workers=4)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "77/77 [==============================] - 4s 56ms/step - loss: 0.4807 - accuracy: 0.8208 - val_loss: 0.4160 - val_accuracy: 0.8824\n",
            "Epoch 2/20\n",
            "77/77 [==============================] - 4s 52ms/step - loss: 0.4120 - accuracy: 0.8494 - val_loss: 0.3600 - val_accuracy: 0.8860\n",
            "Epoch 3/20\n",
            "77/77 [==============================] - 4s 53ms/step - loss: 0.3693 - accuracy: 0.8670 - val_loss: 0.3448 - val_accuracy: 0.8676\n",
            "Epoch 4/20\n",
            "77/77 [==============================] - 4s 52ms/step - loss: 0.3139 - accuracy: 0.8895 - val_loss: 0.2789 - val_accuracy: 0.8971\n",
            "Epoch 5/20\n",
            "77/77 [==============================] - 4s 53ms/step - loss: 0.2850 - accuracy: 0.8912 - val_loss: 0.2637 - val_accuracy: 0.9044\n",
            "Epoch 6/20\n",
            "77/77 [==============================] - 4s 51ms/step - loss: 0.2475 - accuracy: 0.9006 - val_loss: 0.2357 - val_accuracy: 0.9044\n",
            "Epoch 7/20\n",
            "77/77 [==============================] - 4s 52ms/step - loss: 0.2265 - accuracy: 0.9194 - val_loss: 0.2086 - val_accuracy: 0.9118\n",
            "Epoch 8/20\n",
            "77/77 [==============================] - 4s 51ms/step - loss: 0.1865 - accuracy: 0.9313 - val_loss: 0.1803 - val_accuracy: 0.9191\n",
            "Epoch 9/20\n",
            "77/77 [==============================] - 4s 51ms/step - loss: 0.1815 - accuracy: 0.9309 - val_loss: 0.2303 - val_accuracy: 0.8971\n",
            "Epoch 10/20\n",
            "77/77 [==============================] - 4s 52ms/step - loss: 0.1687 - accuracy: 0.9354 - val_loss: 0.1638 - val_accuracy: 0.9338\n",
            "Epoch 11/20\n",
            "77/77 [==============================] - 4s 52ms/step - loss: 0.1531 - accuracy: 0.9456 - val_loss: 0.1583 - val_accuracy: 0.9301\n",
            "Epoch 12/20\n",
            "77/77 [==============================] - 4s 53ms/step - loss: 0.1349 - accuracy: 0.9472 - val_loss: 0.1494 - val_accuracy: 0.9412\n",
            "Epoch 13/20\n",
            "77/77 [==============================] - 4s 51ms/step - loss: 0.1342 - accuracy: 0.9489 - val_loss: 0.1441 - val_accuracy: 0.9412\n",
            "Epoch 14/20\n",
            "77/77 [==============================] - 4s 51ms/step - loss: 0.1307 - accuracy: 0.9521 - val_loss: 0.1572 - val_accuracy: 0.9412\n",
            "Epoch 15/20\n",
            "77/77 [==============================] - 4s 51ms/step - loss: 0.1357 - accuracy: 0.9517 - val_loss: 0.1358 - val_accuracy: 0.9412\n",
            "Epoch 16/20\n",
            "77/77 [==============================] - 4s 53ms/step - loss: 0.1234 - accuracy: 0.9513 - val_loss: 0.1232 - val_accuracy: 0.9522\n",
            "Epoch 17/20\n",
            "77/77 [==============================] - 4s 51ms/step - loss: 0.1396 - accuracy: 0.9468 - val_loss: 0.1267 - val_accuracy: 0.9485\n",
            "Epoch 18/20\n",
            "77/77 [==============================] - 4s 51ms/step - loss: 0.1312 - accuracy: 0.9550 - val_loss: 0.1377 - val_accuracy: 0.9449\n",
            "Epoch 19/20\n",
            "77/77 [==============================] - 4s 51ms/step - loss: 0.1175 - accuracy: 0.9497 - val_loss: 0.1198 - val_accuracy: 0.9522\n",
            "Epoch 20/20\n",
            "77/77 [==============================] - 4s 52ms/step - loss: 0.1251 - accuracy: 0.9534 - val_loss: 0.1183 - val_accuracy: 0.9412\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zZJ_5GgCPNcC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}